<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Multilevel models | New statistics for design researchers</title>
  <meta name="description" content="A statistics book for designers, human factors specialists, UX researchers, applied psychologists and everyone else who works to make this world an easier place." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Multilevel models | New statistics for design researchers" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A statistics book for designers, human factors specialists, UX researchers, applied psychologists and everyone else who works to make this world an easier place." />
  <meta name="github-repo" content="schmettow/New_Stats" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Multilevel models | New statistics for design researchers" />
  
  <meta name="twitter:description" content="A statistics book for designers, human factors specialists, UX researchers, applied psychologists and everyone else who works to make this world an easier place." />
  

<meta name="author" content="Martin Schmettow" />


<meta name="date" content="2021-03-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mpm.html"/>
<link rel="next" href="glm.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="NewStats.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="part"><span><b>I Preparations</b></span></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#whom-for"><i class="fa fa-check"></i><b>1.1</b> Whom this book is for</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#quant-design-research"><i class="fa fa-check"></i><b>1.2</b> Quantitative design research</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#what-new-stats"><i class="fa fa-check"></i><b>1.3</b> What is New Statistics?</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#how-to-use"><i class="fa fa-check"></i><b>1.4</b> How to use this book</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#routes"><i class="fa fa-check"></i><b>1.4.1</b> Routes</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#classroom"><i class="fa fa-check"></i><b>1.4.2</b> In the classroom</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#rosetta"><i class="fa fa-check"></i><b>1.4.3</b> The stone of Rosetta</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#thank-you-and-supplementary-readings"><i class="fa fa-check"></i><b>1.5</b> Thank you and supplementary readings</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="gsr.html"><a href="gsr.html"><i class="fa fa-check"></i><b>2</b> Getting started with R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="gsr.html"><a href="gsr.html#setting-up-r"><i class="fa fa-check"></i><b>2.1</b> Setting up the R environment</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="gsr.html"><a href="gsr.html#install-cran"><i class="fa fa-check"></i><b>2.1.1</b> Installing CRAN packages</a></li>
<li class="chapter" data-level="2.1.2" data-path="gsr.html"><a href="gsr.html#install-github"><i class="fa fa-check"></i><b>2.1.2</b> Installing packages from Github</a></li>
<li class="chapter" data-level="2.1.3" data-path="gsr.html"><a href="gsr.html#first-program"><i class="fa fa-check"></i><b>2.1.3</b> A first statistical program</a></li>
<li class="chapter" data-level="2.1.4" data-path="gsr.html"><a href="gsr.html#bibliographic-notes"><i class="fa fa-check"></i><b>2.1.4</b> Bibliographic notes</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="gsr.html"><a href="gsr.html#r-primer"><i class="fa fa-check"></i><b>2.2</b> Learning R: a primer</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="gsr.html"><a href="gsr.html#objects"><i class="fa fa-check"></i><b>2.2.1</b> Assigning and calling Objects</a></li>
<li class="chapter" data-level="2.2.2" data-path="gsr.html"><a href="gsr.html#vectors"><i class="fa fa-check"></i><b>2.2.2</b> Vectors</a></li>
<li class="chapter" data-level="2.2.3" data-path="gsr.html"><a href="gsr.html#object-types"><i class="fa fa-check"></i><b>2.2.3</b> Basic object types</a></li>
<li class="chapter" data-level="2.2.4" data-path="gsr.html"><a href="gsr.html#operators-functions"><i class="fa fa-check"></i><b>2.2.4</b> Operators and functions</a></li>
<li class="chapter" data-level="2.2.5" data-path="gsr.html"><a href="gsr.html#data-frames"><i class="fa fa-check"></i><b>2.2.5</b> Storing data in data frames</a></li>
<li class="chapter" data-level="2.2.6" data-path="gsr.html"><a href="gsr.html#import-export"><i class="fa fa-check"></i><b>2.2.6</b> Import, export and archiving</a></li>
<li class="chapter" data-level="2.2.7" data-path="gsr.html"><a href="gsr.html#case-env"><i class="fa fa-check"></i><b>2.2.7</b> Case environments</a></li>
<li class="chapter" data-level="2.2.8" data-path="gsr.html"><a href="gsr.html#structuring-data"><i class="fa fa-check"></i><b>2.2.8</b> Structuring data</a></li>
<li class="chapter" data-level="2.2.9" data-path="gsr.html"><a href="gsr.html#data-transformation"><i class="fa fa-check"></i><b>2.2.9</b> Data transformation</a></li>
<li class="chapter" data-level="2.2.10" data-path="gsr.html"><a href="gsr.html#plotting"><i class="fa fa-check"></i><b>2.2.10</b> Plotting data</a></li>
<li class="chapter" data-level="2.2.11" data-path="gsr.html"><a href="gsr.html#fitting"><i class="fa fa-check"></i><b>2.2.11</b> Fitting regression models</a></li>
<li class="chapter" data-level="2.2.12" data-path="gsr.html"><a href="gsr.html#knitting"><i class="fa fa-check"></i><b>2.2.12</b> Knitting statistical reports</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="gsr.html"><a href="gsr.html#lib_gsr"><i class="fa fa-check"></i><b>2.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ebs.html"><a href="ebs.html"><i class="fa fa-check"></i><b>3</b> Elements of Bayesian statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ebs.html"><a href="ebs.html#decision-making"><i class="fa fa-check"></i><b>3.1</b> Rational decision making in design research</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="ebs.html"><a href="ebs.html#measuring-uncertainty"><i class="fa fa-check"></i><b>3.1.1</b> Measuring uncertainty</a></li>
<li class="chapter" data-level="3.1.2" data-path="ebs.html"><a href="ebs.html#benchmarking-designs"><i class="fa fa-check"></i><b>3.1.2</b> Benchmarking designs</a></li>
<li class="chapter" data-level="3.1.3" data-path="ebs.html"><a href="ebs.html#comparing-designs"><i class="fa fa-check"></i><b>3.1.3</b> Comparison of designs</a></li>
<li class="chapter" data-level="3.1.4" data-path="ebs.html"><a href="ebs.html#prior-knowledge"><i class="fa fa-check"></i><b>3.1.4</b> Prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ebs.html"><a href="ebs.html#observations-measures"><i class="fa fa-check"></i><b>3.2</b> Observations and measures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ebs.html"><a href="ebs.html#interaction-seq"><i class="fa fa-check"></i><b>3.2.1</b> Interaction sequences</a></li>
<li class="chapter" data-level="3.2.2" data-path="ebs.html"><a href="ebs.html#perf-measures"><i class="fa fa-check"></i><b>3.2.2</b> Performance measures</a></li>
<li class="chapter" data-level="3.2.3" data-path="ebs.html"><a href="ebs.html#satisfaction-and-other-feelings"><i class="fa fa-check"></i><b>3.2.3</b> Satisfaction and other feelings</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ebs.html"><a href="ebs.html#descriptive-stats"><i class="fa fa-check"></i><b>3.3</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="ebs.html"><a href="ebs.html#frequencies"><i class="fa fa-check"></i><b>3.3.1</b> Frequencies</a></li>
<li class="chapter" data-level="3.3.2" data-path="ebs.html"><a href="ebs.html#central-tendency"><i class="fa fa-check"></i><b>3.3.2</b> Central tendency</a></li>
<li class="chapter" data-level="3.3.3" data-path="ebs.html"><a href="ebs.html#dispersion"><i class="fa fa-check"></i><b>3.3.3</b> Dispersion</a></li>
<li class="chapter" data-level="3.3.4" data-path="ebs.html"><a href="ebs.html#associations"><i class="fa fa-check"></i><b>3.3.4</b> Associations</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ebs.html"><a href="ebs.html#bayes-prob-theory"><i class="fa fa-check"></i><b>3.4</b> Bayesian probability theory</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ebs.html"><a href="ebs.html#set-theory"><i class="fa fa-check"></i><b>3.4.1</b> Some set theory</a></li>
<li class="chapter" data-level="3.4.2" data-path="ebs.html"><a href="ebs.html#probability"><i class="fa fa-check"></i><b>3.4.2</b> Probability</a></li>
<li class="chapter" data-level="3.4.3" data-path="ebs.html"><a href="ebs.html#likelihood"><i class="fa fa-check"></i><b>3.4.3</b> Likelihood</a></li>
<li class="chapter" data-level="3.4.4" data-path="ebs.html"><a href="ebs.html#bayes-freq-prob"><i class="fa fa-check"></i><b>3.4.4</b> Bayesian and frequentist probability</a></li>
<li class="chapter" data-level="3.4.5" data-path="ebs.html"><a href="ebs.html#bayes-theorem"><i class="fa fa-check"></i><b>3.4.5</b> Bayes theorem</a></li>
<li class="chapter" data-level="3.4.6" data-path="ebs.html"><a href="ebs.html#dynamics-belief"><i class="fa fa-check"></i><b>3.4.6</b> Bayesian dynamics of belief</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ebs.html"><a href="ebs.html#statmod"><i class="fa fa-check"></i><b>3.5</b> Statistical models</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ebs.html"><a href="ebs.html#structural-part"><i class="fa fa-check"></i><b>3.5.1</b> The structural part</a></li>
<li class="chapter" data-level="3.5.2" data-path="ebs.html"><a href="ebs.html#distributions"><i class="fa fa-check"></i><b>3.5.2</b> Distributions: shapes of randomness</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ebs.html"><a href="ebs.html#bayes-estimation"><i class="fa fa-check"></i><b>3.6</b> Towards Bayesian estimation</a></li>
<li class="chapter" data-level="3.7" data-path="ebs.html"><a href="ebs.html#priors-defaults"><i class="fa fa-check"></i><b>3.7</b> On priors and defaults</a></li>
<li class="chapter" data-level="3.8" data-path="ebs.html"><a href="ebs.html#further-readings"><i class="fa fa-check"></i><b>3.8</b> Further readings</a></li>
</ul></li>
<li class="part"><span><b>II Models</b></span></li>
<li class="chapter" data-level="4" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>4</b> Basic Linear models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="lm.html"><a href="lm.html#gmm"><i class="fa fa-check"></i><b>4.1</b> Quantification at work: grand mean models</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="lm.html"><a href="lm.html#random-walk"><i class="fa fa-check"></i><b>4.1.1</b> Do the random walk: Markov Chain Monte Carlo sampling</a></li>
<li class="chapter" data-level="4.1.2" data-path="lm.html"><a href="lm.html#likelihood-random-term"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood and random term</a></li>
<li class="chapter" data-level="4.1.3" data-path="lm.html"><a href="lm.html#posterior-dist"><i class="fa fa-check"></i><b>4.1.3</b> Working with the posterior distribution</a></li>
<li class="chapter" data-level="4.1.4" data-path="lm.html"><a href="lm.html#clu"><i class="fa fa-check"></i><b>4.1.4</b> Center and interval estimates</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="lm.html"><a href="lm.html#lrm"><i class="fa fa-check"></i><b>4.2</b> Walk the line: linear regression</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="lm.html"><a href="lm.html#transform-measures"><i class="fa fa-check"></i><b>4.2.1</b> Transforming measures</a></li>
<li class="chapter" data-level="4.2.2" data-path="lm.html"><a href="lm.html#correlations"><i class="fa fa-check"></i><b>4.2.2</b> Correlations</a></li>
<li class="chapter" data-level="4.2.3" data-path="lm.html"><a href="lm.html#endless-linear"><i class="fa fa-check"></i><b>4.2.3</b> Endlessly linear</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="lm.html"><a href="lm.html#factorial-models"><i class="fa fa-check"></i><b>4.3</b> Factorial Models</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="lm.html"><a href="lm.html#cgm"><i class="fa fa-check"></i><b>4.3.1</b> A versus B: Comparison of groups</a></li>
<li class="chapter" data-level="4.3.2" data-path="lm.html"><a href="lm.html#dummy"><i class="fa fa-check"></i><b>4.3.2</b> Not stupid: dummy variables</a></li>
<li class="chapter" data-level="4.3.3" data-path="lm.html"><a href="lm.html#treatment-contrasts"><i class="fa fa-check"></i><b>4.3.3</b> Treatment contrast coding</a></li>
<li class="chapter" data-level="4.3.4" data-path="lm.html"><a href="lm.html#amm"><i class="fa fa-check"></i><b>4.3.4</b> Absolute Means Model</a></li>
<li class="chapter" data-level="4.3.5" data-path="lm.html"><a href="lm.html#ofm"><i class="fa fa-check"></i><b>4.3.5</b> Ordered Factorial Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mpm.html"><a href="mpm.html"><i class="fa fa-check"></i><b>5</b> Multi-predictor models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mpm.html"><a href="mpm.html#mrm"><i class="fa fa-check"></i><b>5.1</b> On surface: multiple regression models</a></li>
<li class="chapter" data-level="5.2" data-path="mpm.html"><a href="mpm.html#mfm"><i class="fa fa-check"></i><b>5.2</b> Crossover: multifactorial models</a></li>
<li class="chapter" data-level="5.3" data-path="mpm.html"><a href="mpm.html#grm"><i class="fa fa-check"></i><b>5.3</b> Line-by-line: grouped regression models</a></li>
<li class="chapter" data-level="5.4" data-path="mpm.html"><a href="mpm.html#cfxm"><i class="fa fa-check"></i><b>5.4</b> Conditional effects models</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="mpm.html"><a href="mpm.html#cmrm"><i class="fa fa-check"></i><b>5.4.1</b> Conditional multiple regression</a></li>
<li class="chapter" data-level="5.4.2" data-path="mpm.html"><a href="mpm.html#cmfm"><i class="fa fa-check"></i><b>5.4.2</b> Conditional multifactorial models</a></li>
<li class="chapter" data-level="5.4.3" data-path="mpm.html"><a href="mpm.html#saturation"><i class="fa fa-check"></i><b>5.4.3</b> Saturation: hitting the boundaries</a></li>
<li class="chapter" data-level="5.4.4" data-path="mpm.html"><a href="mpm.html#amplification"><i class="fa fa-check"></i><b>5.4.4</b> Amplification: more than the sum</a></li>
<li class="chapter" data-level="5.4.5" data-path="mpm.html"><a href="mpm.html#cfx-theory"><i class="fa fa-check"></i><b>5.4.5</b> Conditional effects and design theory</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="mpm.html"><a href="mpm.html#prm"><i class="fa fa-check"></i><b>5.5</b> Doing the rollercoaster: polynomial regression models</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="mpm.html"><a href="mpm.html#test-stat"><i class="fa fa-check"></i><b>5.5.1</b> Make yourself a test statistic</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="mpm.html"><a href="mpm.html#further-readings-1"><i class="fa fa-check"></i><b>5.6</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mlm.html"><a href="mlm.html"><i class="fa fa-check"></i><b>6</b> Multilevel models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mlm.html"><a href="mlm.html#intercept-re"><i class="fa fa-check"></i><b>6.1</b> The Human Factor: Intercept random effects</a></li>
<li class="chapter" data-level="6.2" data-path="mlm.html"><a href="mlm.html#slope-re"><i class="fa fa-check"></i><b>6.2</b> Multi-level linear regression: variance in change</a></li>
<li class="chapter" data-level="6.3" data-path="mlm.html"><a href="mlm.html#thinking-multi-level"><i class="fa fa-check"></i><b>6.3</b> Thinking multi-level</a></li>
<li class="chapter" data-level="6.4" data-path="mlm.html"><a href="mlm.html#universality"><i class="fa fa-check"></i><b>6.4</b> Testing universality of theories</a></li>
<li class="chapter" data-level="6.5" data-path="mlm.html"><a href="mlm.html#non-human-populations"><i class="fa fa-check"></i><b>6.5</b> Non-human populations and cross-overs</a></li>
<li class="chapter" data-level="6.6" data-path="mlm.html"><a href="mlm.html#nested-re"><i class="fa fa-check"></i><b>6.6</b> Nested random effects</a></li>
<li class="chapter" data-level="6.7" data-path="mlm.html"><a href="mlm.html#pool-shrink"><i class="fa fa-check"></i><b>6.7</b> What are random effects? On pooling and shrinkage</a></li>
<li class="chapter" data-level="6.8" data-path="mlm.html"><a href="mlm.html#psychometrics"><i class="fa fa-check"></i><b>6.8</b> Psychometrics and design-o-metric models</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="mlm.html"><a href="mlm.html#coverage"><i class="fa fa-check"></i><b>6.8.1</b> Coverage</a></li>
<li class="chapter" data-level="6.8.2" data-path="mlm.html"><a href="mlm.html#reliability"><i class="fa fa-check"></i><b>6.8.2</b> Reliability</a></li>
<li class="chapter" data-level="6.8.3" data-path="mlm.html"><a href="mlm.html#validity"><i class="fa fa-check"></i><b>6.8.3</b> Validity</a></li>
<li class="chapter" data-level="6.8.4" data-path="mlm.html"><a href="mlm.html#designometrix"><i class="fa fa-check"></i><b>6.8.4</b> Towards Design-o-metrix</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="mlm.html"><a href="mlm.html#further-readings-2"><i class="fa fa-check"></i><b>6.9</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="glm.html"><a href="glm.html#elements-glm"><i class="fa fa-check"></i><b>7.1</b> Elements of Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="glm.html"><a href="glm.html#relinking-linearity"><i class="fa fa-check"></i><b>7.1.1</b> Re-linking linearity</a></li>
<li class="chapter" data-level="7.1.2" data-path="glm.html"><a href="glm.html#choosing-randomness"><i class="fa fa-check"></i><b>7.1.2</b> Choosing patterns of randomness</a></li>
<li class="chapter" data-level="7.1.3" data-path="glm.html"><a href="glm.html#mean-var-rel"><i class="fa fa-check"></i><b>7.1.3</b> Mean-variance relationship</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="glm.html"><a href="glm.html#count-data"><i class="fa fa-check"></i><b>7.2</b> Count data</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="glm.html"><a href="glm.html#pois-reg"><i class="fa fa-check"></i><b>7.2.1</b> Poisson regression</a></li>
<li class="chapter" data-level="7.2.2" data-path="glm.html"><a href="glm.html#logistic-reg"><i class="fa fa-check"></i><b>7.2.2</b> Logistic (aka Binomial) regression</a></li>
<li class="chapter" data-level="7.2.3" data-path="glm.html"><a href="glm.html#overdispersion"><i class="fa fa-check"></i><b>7.2.3</b> Modelling overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="glm.html"><a href="glm.html#duration-measures"><i class="fa fa-check"></i><b>7.3</b> Duration measures</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="glm.html"><a href="glm.html#exp-gam-reg"><i class="fa fa-check"></i><b>7.3.1</b> Exponential and Gamma regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="glm.html"><a href="glm.html#exgauss-reg"><i class="fa fa-check"></i><b>7.3.2</b> ExGaussian regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="glm.html"><a href="glm.html#rating-scales"><i class="fa fa-check"></i><b>7.4</b> Rating scales</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="glm.html"><a href="glm.html#ord-logist-reg"><i class="fa fa-check"></i><b>7.4.1</b> Ordered logistic regression</a></li>
<li class="chapter" data-level="7.4.2" data-path="glm.html"><a href="glm.html#beta-reg"><i class="fa fa-check"></i><b>7.4.2</b> Beta regression</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="glm.html"><a href="glm.html#distributional-models"><i class="fa fa-check"></i><b>7.5</b> Beyond mean: distributional models</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="glm.html"><a href="glm.html#item-anchoring"><i class="fa fa-check"></i><b>7.5.1</b> Item-level anchoring in rating scales</a></li>
<li class="chapter" data-level="7.5.2" data-path="glm.html"><a href="glm.html#part-employment"><i class="fa fa-check"></i><b>7.5.2</b> Participant-level employment of scale</a></li>
<li class="chapter" data-level="7.5.3" data-path="glm.html"><a href="glm.html#part-skew"><i class="fa fa-check"></i><b>7.5.3</b> Participant-level skew in reaction times</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="glm.html"><a href="glm.html#further-readings-3"><i class="fa fa-check"></i><b>7.6</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="wwm.html"><a href="wwm.html"><i class="fa fa-check"></i><b>8</b> Working with models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="wwm.html"><a href="wwm.html#model-criticism"><i class="fa fa-check"></i><b>8.1</b> Model criticism</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="wwm.html"><a href="wwm.html#residual-analysis"><i class="fa fa-check"></i><b>8.1.1</b> Residual analysis</a></li>
<li class="chapter" data-level="8.1.2" data-path="wwm.html"><a href="wwm.html#fitted-responses"><i class="fa fa-check"></i><b>8.1.2</b> Fitted responses analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="wwm.html"><a href="wwm.html#model-comp"><i class="fa fa-check"></i><b>8.2</b> Model comparison</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="wwm.html"><a href="wwm.html#overfitting"><i class="fa fa-check"></i><b>8.2.1</b> The problem of over-fitting</a></li>
<li class="chapter" data-level="8.2.2" data-path="wwm.html"><a href="wwm.html#cross-validation"><i class="fa fa-check"></i><b>8.2.2</b> Cross validation and LOO</a></li>
<li class="chapter" data-level="8.2.3" data-path="wwm.html"><a href="wwm.html#ic"><i class="fa fa-check"></i><b>8.2.3</b> Information Criteria</a></li>
<li class="chapter" data-level="8.2.4" data-path="wwm.html"><a href="wwm.html#model-selection"><i class="fa fa-check"></i><b>8.2.4</b> Model selection</a></li>
<li class="chapter" data-level="8.2.5" data-path="wwm.html"><a href="wwm.html#choose-dist"><i class="fa fa-check"></i><b>8.2.5</b> Comparing response distributions</a></li>
<li class="chapter" data-level="8.2.6" data-path="wwm.html"><a href="wwm.html#testing-theories"><i class="fa fa-check"></i><b>8.2.6</b> Testing hypotheses</a></li>
<li class="chapter" data-level="8.2.7" data-path="wwm.html"><a href="wwm.html#bayes-factor"><i class="fa fa-check"></i><b>8.2.7</b> A note on Bayes Factor</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="wwm.html"><a href="wwm.html#further-readings-4"><i class="fa fa-check"></i><b>8.3</b> Further readings</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="cases.html"><a href="cases.html"><i class="fa fa-check"></i><b>A</b> Cases</a>
<ul>
<li class="chapter" data-level="A.1" data-path="cases.html"><a href="cases.html#real-cases"><i class="fa fa-check"></i><b>A.1</b> Real cases</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="cases.html"><a href="cases.html#hugme"><i class="fa fa-check"></i><b>A.1.1</b> Hugme</a></li>
<li class="chapter" data-level="A.1.2" data-path="cases.html"><a href="cases.html#cue8"><i class="fa fa-check"></i><b>A.1.2</b> CUE8</a></li>
<li class="chapter" data-level="A.1.3" data-path="cases.html"><a href="cases.html#uncanny"><i class="fa fa-check"></i><b>A.1.3</b> Uncanny Valley</a></li>
<li class="chapter" data-level="A.1.4" data-path="cases.html"><a href="cases.html#ipump"><i class="fa fa-check"></i><b>A.1.4</b> IPump</a></li>
<li class="chapter" data-level="A.1.5" data-path="cases.html"><a href="cases.html#sleepstudy"><i class="fa fa-check"></i><b>A.1.5</b> Case Sleepstudy</a></li>
<li class="chapter" data-level="A.1.6" data-path="cases.html"><a href="cases.html#egan"><i class="fa fa-check"></i><b>A.1.6</b> Egan</a></li>
<li class="chapter" data-level="A.1.7" data-path="cases.html"><a href="cases.html#mmn"><i class="fa fa-check"></i><b>A.1.7</b> Case: Millers Magic Number</a></li>
<li class="chapter" data-level="A.1.8" data-path="cases.html"><a href="cases.html#aup"><i class="fa fa-check"></i><b>A.1.8</b> AUP</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="cases.html"><a href="cases.html#synthetic-data"><i class="fa fa-check"></i><b>A.2</b> Synthetic data sets</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="cases.html"><a href="cases.html#rainfall"><i class="fa fa-check"></i><b>A.2.1</b> Rainfall</a></li>
<li class="chapter" data-level="A.2.2" data-path="cases.html"><a href="cases.html#sec99"><i class="fa fa-check"></i><b>A.2.2</b> 99 seconds</a></li>
<li class="chapter" data-level="A.2.3" data-path="cases.html"><a href="cases.html#rational"><i class="fa fa-check"></i><b>A.2.3</b> Rational</a></li>
<li class="chapter" data-level="A.2.4" data-path="cases.html"><a href="cases.html#browsingab"><i class="fa fa-check"></i><b>A.2.4</b> BrowsingAB</a></li>
<li class="chapter" data-level="A.2.5" data-path="cases.html"><a href="cases.html#headache"><i class="fa fa-check"></i><b>A.2.5</b> Headache</a></li>
<li class="chapter" data-level="A.2.6" data-path="cases.html"><a href="cases.html#reading"><i class="fa fa-check"></i><b>A.2.6</b> Reading time</a></li>
<li class="chapter" data-level="A.2.7" data-path="cases.html"><a href="cases.html#argame"><i class="fa fa-check"></i><b>A.2.7</b> AR_game</a></li>
<li class="chapter" data-level="A.2.8" data-path="cases.html"><a href="cases.html#sleep"><i class="fa fa-check"></i><b>A.2.8</b> Sleep</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">New statistics for design researchers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mlm" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Multilevel models</h1>
<p>In the previous chapters we have seen several examples of conditional effects: groups of users responding differently to design conditions, such as font size, noise and emerging technology. Dealing with differential design effects seems straight forward: identify the relevant property, record it and add an conditional effect to the model.</p>
<!-- Identifying the relevant property is, in fact, a catch-22: how would you know what is relevant before you actually conducted the research. Researchers routinely record basic demographic properties such as age and gender, but these frequently show little effects, or the effects are obvious, i.e. not interesting. In addition, such predictors are rarely more than approximations of the properties that make the real difference. Older people have weaker vision *by tendency*, but the individual differences in any age group are immense. Boys tend to be more technophile, but there are some real geeky girls, too. -->
<p>Identifying user properties that matter requires careful review of past research or deep theorizing, and even then it remains guesswork. Presumably, hundreds of studies attempted to explain differences in usage patterns or performance by all sorts of psychological predictors, with often limited results. That is a big problem in design research, as variation in performance can be huge and good predictors are urgently needed. Identifying the mental origins of being fast versus slow, or motivated versus bored, is extremely useful to improve the design of systems to be more inclusive or engaging.</p>
<p>As we will see in this chapter, individual differences can be accounted for and measured accurately without any theory of individual differences. For researchers trained in experimental social sciences it may require a bit of getting used to theory-free reasoning about effects, as it is always tempting to ask for the <em>why</em>. But in applied evaluation studies, what we often really need to know is by <em>how much</em> users vary. The key to measuring variation in a population is to create models that operate on the level of participants, in addition to the population level, for example.</p>
<ul>
<li>on population level, users prefer design B over A on average (<span class="math inline">\(\beta_1 = 20\)</span>)</li>
<li>on the participant-level, participant <span class="math inline">\(i\)</span> preferred B over A (<span class="math inline">\(\beta_{1i} = 20\)</span>), <span class="math inline">\(j\)</span> preferred A over B (<span class="math inline">\(\beta_{1j} = -5\)</span>), +</li>
</ul>
<p>When adding a participant-level effects, we still operate with coefficients, but in contrast to single-level linear models, every participant gets their own coefficient (<span class="math inline">\(\beta_{1\cdot}\)</span>). The key to estimating individual parameters is simply to regard participant (<code>Part</code>) a grouping variable on its own, and introduce it as a factor.</p>
<!-- Multi-level analysis is not limited to estimating models, that is using a regression engine. Throughout this chapter you will see exploratory plots that are on  in this introduction we will use the participant factor for producing multi-level exploratory plots. That should get you started. -->
<p>The subsequent two sections introduce the basics of estimating multi-level linear models, first introducing intercept-only participant-level effects <a href="mlm.html#intercept-re">6.1</a> and then slope (or group difference) effects <a href="mlm.html#slope-re">6.2</a>. Typically, fixed and random effects appear together in a linear multi-level model. It depends on the research question whether the researcher capitalizes on the average outcome, the variation in the population or participant-level effects.</p>
<!-- Throughout the chapter you will see two kinds of interpretingIn section \@ref(reporting_re) we will see how to report multi-level results depending on the type of research question.  -->
<p>The participant-level is really just the factor and once it is regarded alongside the population level, a model is multi-level. However, in multi-level linear modelling we usually use a different type of factor, for the particpant level. The additional idea is that the levels of the factor, hence the individuals, are part of a <em>population</em>. The consequences of this perspective, will be discussed in <a href="mlm.html#pool-shrink">6.7</a>: a population is a set of entities that vary to some extent but also clump around a typical value. And that is precisely what <em>random effects</em> do: levels are drawn from an overarching distribution, usually the Gaussian. This distribution is estimated simultaneously to the individual parameters (<span class="math inline">\(\beta_{1\cdot}\)</span>), which has advantages. We will return to a more fundamental research case, the Uncanny Valley, and examine the <em>universality</em> of this strange effect <a href="mlm.html#universality">6.4</a>.</p>
<p>Once it is clear what the concept of random effects means for studying participant behaviour, we will see that it transfers with grace to <em>non-human populations</em>, such as designs, teams or questionnaire items. Three sections introduce multi-population multi-level models: In <a href="mlm.html#non-human-populations">6.5</a> we will use a random effects model with four populations and compare their relative contribution to overall variance in performance. Section @ref(re_nested) will show how multiple levels can form a hierarchy and in <a href="mlm.html#psychometrics">6.8</a> we will see that multi-level models can be employed the development of <em>psychometrics tests</em>, that apply for people. Finally, we will see how to treat tests to compare designs, for which I will coin the term <em>design-o-metrics</em> <a href="mlm.html#designometrix">6.8.4</a>.</p>
<div id="intercept-re" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> The Human Factor: Intercept random effects</h2>
<p>Design science fundamentally deals with interaction between systems and humans. Every measure we take in a design study is an encounter of an individual with a system. As people differ in many aspects, it is likely that people differ in how they use and perform with a system. In the previous chapter we have already dealt with differences between users: in the BrowsingAB case, we compared two designs in how inclusive they are with respect to elderly users. Such a research question seeks for a definitive answer on what truly causes variation in performance. Years of age is a standard demographic variable and in experimental studies it can be collected without hassle. If we start from deeper theoretical considerations than that, for example, we suspect a certain personality trait to play a significant role, this can become more effort. Perhaps, you need a 24-item scale to measure the construct, perhaps you first have to translate this particular questionnaire into three different languages, and perhaps you have to first invent and evaluate a scale. In my experience, personality scales rarely explain much of the variation we see in performance. It may be interesting to catch some small signals for the purpose of testing theories, but for applied design research it is more important to quantify the performance variation within a population, rather than explaining it.</p>
<!-- That is already quite fancy, as it is seeks to explain variation. In applied design research, we often observe massive variation in performance betwee. based on idea that age may be related to performance in such a convoluted way Imagine, you had a different look at the BrowsingAB data, but had gathered no predictors at all and observed a massive amount of variation in performance. It is reasonable to assume that much of this variation stems from individual differences. That, in turn would mean that a fraction of users perform extremely well, whereas others fail miserably.  If that were true,  you would give the advice to invest into redesign that is more inclusive, ironing out the differences, would you not? But, to really drive it home, you have to prove that individual differences are the main source of variation. -->
<p>At first, one might incorrectly think that a grand mean model would do, take <span class="math inline">\(\beta_0\)</span> as the population mean and <span class="math inline">\(\sigma_\epsilon\)</span> as a measure for individual variation. The mistake is that the residuals collect all random variations sources, not just variance between individuals, in particular residuals are themselves composed of:</p>
<ul>
<li>inter-individual variation</li>
<li>intra-individual variation, e.g. by different levels of energy over the day</li>
<li>variations in situations, e.g. responsiveness of the website</li>
<li>inaccuracy of measures, e.g. misunderstanding a questionnaire item</li>
</ul>
<p>What is needed, is a way to separate the variation of participants from the rest? Reconsider the principles of model formulations: the structural part captures what is repeatable, what does not repeat goes to the random term. This principle can be turned around: If you want to pull a factor from the random part to the structural part, you need repetition. For estimating users’ individual performance level, all that is needed is repeated measures.</p>
<p>In the IPump study we have collected performance data of 25 nurses, operating a novel interface for a syringe infusion pump. Altogether, every nurse completed a set of eight tasks three times. Medical devices are high-risk systems where a single fault can cost a life, which makes it a requirement that user performance is on a <em>uniformly</em> high level. We start the investigation with the global question (Table <a href="mlm.html#tab:pop-mean">6.1</a>):</p>
<blockquote>
<p>What is the average ToT in the population?</p>
</blockquote>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="mlm.html#cb456-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(IPump)</span></code></pre></div>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="mlm.html#cb457-1" aria-hidden="true" tabindex="-1"></a>D_Novel <span class="sc">%&gt;%</span></span>
<span id="cb457-2"><a href="mlm.html#cb457-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_Pop =</span> <span class="fu">mean</span>(ToT)) </span></code></pre></div>
<table>
<caption><span id="tab:pop-mean">Table 6.1: </span>Population mean of ToT</caption>
<thead>
<tr class="header">
<th align="right">mean_Pop</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">16</td>
</tr>
</tbody>
</table>
<p>The answer is just one number and does not refer to any individuals in the population. This is called the population-level estimate or fixed effect estimate. The following question is similar, but here one average is taken for every participant. We call such a summary <em>participant-level</em> (Table <a href="mlm.html#tab:part-mean">6.2</a>).</p>
<blockquote>
<p>What is the average ToT of individual participants?</p>
</blockquote>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="mlm.html#cb458-1" aria-hidden="true" tabindex="-1"></a>D_Novel <span class="sc">%&gt;%</span></span>
<span id="cb458-2"><a href="mlm.html#cb458-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part) <span class="sc">%&gt;%</span></span>
<span id="cb458-3"><a href="mlm.html#cb458-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_Part =</span> <span class="fu">mean</span>(ToT)) <span class="sc">%&gt;%</span></span>
<span id="cb458-4"><a href="mlm.html#cb458-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">5</span>) </span></code></pre></div>
<table>
<caption><span id="tab:part-mean">Table 6.2: </span>Participant-level mean ToT</caption>
<thead>
<tr class="header">
<th align="left">Part</th>
<th align="right">mean_Part</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">15</td>
<td align="right">17.2</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="right">16.0</td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="right">19.4</td>
</tr>
<tr class="even">
<td align="left">20</td>
<td align="right">19.1</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="right">16.7</td>
</tr>
</tbody>
</table>
<p>Such a grouped summary can be useful for situations where we want to directly compare individuals, like in performance tests. In experimental research, individual participants are of lesser interest, as they are exchangeable entities. What matters is the total variation within the sample, representing the population of users. Once we have participant-level effects, the amount of variation can be summarized by the standard deviation (Table <a href="mlm.html#tab:part-sd">6.3</a>):</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="mlm.html#cb459-1" aria-hidden="true" tabindex="-1"></a>D_Novel <span class="sc">%&gt;%</span></span>
<span id="cb459-2"><a href="mlm.html#cb459-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part) <span class="sc">%&gt;%</span></span>
<span id="cb459-3"><a href="mlm.html#cb459-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_Part =</span> <span class="fu">mean</span>(ToT)) <span class="sc">%&gt;%</span></span>
<span id="cb459-4"><a href="mlm.html#cb459-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb459-5"><a href="mlm.html#cb459-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">sd_Part =</span> <span class="fu">var</span>(mean_Part)) </span></code></pre></div>
<table>
<caption><span id="tab:part-sd">Table 6.3: </span>Variation of participant-level mean ToT</caption>
<thead>
<tr class="header">
<th align="right">sd_Part</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">13.8</td>
</tr>
</tbody>
</table>
<p>Generally, these are the three types of parameters in multi-level models: the population-level estimate (commonly called <em>fixed effects</em>), the participant-level estimates (<em>random effects</em>) and the <em>participant-level variation</em>.</p>
<!-- Now, that we have the individual means, we can plot the variation in task performance. For comparison, the overall variation is added to the plot. It is apparent that individual differences make only part of the overall variance. -->
<!-- #### IMPROVE FIG -->
<!-- ```{r re_variation} -->
<!-- D_Novel %>%  -->
<!--   group_by(Part) %>%  -->
<!--   summarize(mean_Part = mean(ToT)) %>%  -->
<!--   ungroup() %>%  -->
<!--   ggplot(aes(x = mean_Part)) + -->
<!--   geom_density(data = D_Novel, aes(x = ToT, y=..scaled..,  -->
<!--                                fill = "total"),alpha = 1/2) + -->
<!--   geom_density(aes(fill = "user", y=..scaled..),alpha = 1/2) + -->
<!--   labs(fill = "Variation") -->
<!-- ``` -->
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<p>Obviously, the variable <code>Part</code> is key to build such a model. This variable groups observations by participant identity and, formally, is a plain factor. A naive approach to multi-level modeling would be to estimate an AGM, like <code>ToT ~ 0 + Part</code>, grab the center estimates and compute the standard deviation. What sets a truly multi-level apart is that population-level effects, participant-level effects and variation are contained in one model and are estimated <em>simultaneously</em>. Random effects are really just factors with one level per participant. The only difference to a fixed effects factor is that the levels are assumed to follow a Gaussian distribution. This will further be explained in section <a href="mlm.html#pool-shrink">6.7</a>.</p>
<p>For the IPump study we can formulate a GMM model with participant-level random effect <span class="math inline">\(\beta_{p0}\)</span> as follows:
<!-- #84 --></p>
<p><span class="math display">\[
\begin{aligned}
\mu_i &amp;= \beta_0 + x_p\beta_{0p}\\
\beta_{p0} &amp;\sim \textrm{Gaus}(0, \sigma_{p0})\\
y_i &amp;\sim \textrm{Gaus}(\mu_i, \sigma_\epsilon)
\end{aligned}
\]</span></p>
<p>There will be as many parameters <span class="math inline">\(\beta_{0p}\)</span>, as there were participants in the sample, and they have all become part of the structural part. The second term describes the distribution of the participant-level group means. And finally, there is the usual random term. Before we examine further features of the model, let’s run it. In the package <code>rstanarm</code>, the command <code>stan_glmer</code> is dedicated to estimating multi-level models with the extended formula syntax.</p>
<p>However, I will now introduce another Bayesian engine and use it from here on. The Brms package provides the Brm engine, which is invoked by the command <code>brm()</code>. This engine covers all models that can be estimated with <code>stan_glm</code> or <code>stan_glmer</code> and it uses the precise same syntax. All models estimated in this chapter, should also work with <code>stan_glmer</code>. However, Brms supports an even broader set of models, some of which we will encounter in chapter <a href="glm.html#glm">7</a>.</p>
<!-- For multi-level models, the reason to switch Brms is a selfish one. It became to tedious, to support both Rstanarm and Brms with the Bayr package.  -->
<p>The only downside of Brms is that it has to compile the model, preceding the estimation. For simple models, as in the previous chapter, the chains are running very quickly, and the extra step of compilation creates much overhead. For the models in this chapter, the chains run much slower, such that compilation time becomes almost negligible.</p>
<p>Both engines Brms and Rstanarm differ a lot in how they present the results. The Bayr package provides a consistent interface to extract information from model objects of both engines.</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="mlm.html#cb461-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(IPump)</span></code></pre></div>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="mlm.html#cb462-1" aria-hidden="true" tabindex="-1"></a>M_hf <span class="ot">&lt;-</span> <span class="fu">brm</span>(ToT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Part), <span class="at">data =</span> D_Novel)</span>
<span id="cb462-2"><a href="mlm.html#cb462-2" aria-hidden="true" tabindex="-1"></a>P_hf <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_hf)</span></code></pre></div>
<p>The posterior of a multi-level model contains three types of variables (and the standard error)</p>
<ol style="list-style-type: decimal">
<li>the <em>fixed effect</em> captures the population average (Intercept)</li>
<li><em>random effects</em> capture how individual participants deviate from the population mean</li>
<li><em>random factor variation</em> (or group effects) captures the overall variation in the population.</li>
</ol>
<p>With the <code>bayr</code> package these parameters can be extracted using the respective commands (Table <a href="mlm.html#tab:ml-fixef">6.4</a>, <a href="mlm.html#tab:ml-ranef">6.5</a> and <a href="mlm.html#tab:ml-grpef">6.6</a>):</p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="mlm.html#cb463-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span>(P_hf)</span></code></pre></div>
<table>
<caption><span id="tab:ml-fixef">Table 6.4: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="left">type</th>
<th align="left">fixef</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">M_hf</td>
<td align="left">fixef</td>
<td align="left">Intercept</td>
<td align="right">16</td>
<td align="right">14.4</td>
<td align="right">17.5</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="mlm.html#cb464-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(P_hf) <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">5</span>)</span></code></pre></div>
<table>
<caption><span id="tab:ml-ranef">Table 6.5: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">re_entity</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">3</td>
<td align="right">-0.155</td>
<td align="right">-4.10</td>
<td align="right">2.85</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="right">-0.160</td>
<td align="right">-3.86</td>
<td align="right">2.77</td>
</tr>
<tr class="odd">
<td align="left">12</td>
<td align="right">0.304</td>
<td align="right">-2.29</td>
<td align="right">4.51</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="right">1.091</td>
<td align="right">-1.10</td>
<td align="right">6.38</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="right">0.782</td>
<td align="right">-1.38</td>
<td align="right">5.89</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="mlm.html#cb465-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grpef</span>(P_hf)</span></code></pre></div>
<table>
<caption><span id="tab:ml-grpef">Table 6.6: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="left">type</th>
<th align="left">fixef</th>
<th align="left">re_factor</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">M_hf</td>
<td align="left">grpef</td>
<td align="left">Intercept</td>
<td align="left">Part</td>
<td align="right">1.53</td>
<td align="right">0.079</td>
<td align="right">3.73</td>
</tr>
</tbody>
</table>
<p>Random effects are factors and enter the model formula just as linear terms. To indicate that to the regression engine, a dedicated syntax is used in the model formula (recall that <code>1</code> represents the intercept parameter):</p>
<p><code>(1|Part)</code></p>
<p>In probability theory expressions, such as the famous Bayes theorem, the <code>|</code> symbol means that something to the left is conditional on something to the right. Random effects can be read as such conditional effects. Left of the <code>|</code> is the fixed effect that is conditional on (i.e. varies by) the factor to the right. In the simplest form the varying effect is the intercept and in the case here could be spoken of as:</p>
<blockquote>
<p>Average ToT, conditional on the participant</p>
</blockquote>
<p>Speaking of factors: So far, we have used <em>treatment contrasts</em> as lot for population-level factors, which represent the difference towards a reference level. If random effects were coded as treatment effects, we would have one absolute score for the first participants (reference group). All other average scores, we would express as differences to the reference participant. This seems odd and, indeed, has two disadvantages: first, whom are we to select as the reference participant? The choice would be arbitrary, unless we wanted to compare brain sizes against the grey matter of Albert Einstein, perhaps. Second, most of the time the researcher is after the factor variation rather than differences between any two individuals, which is inconvenient to compute from treatment contrasts.</p>
<p>The solution is to use a different contrast coding for random factors: <em>deviation contrasts</em> represent the individual effects as <em>difference (<span class="math inline">\(\delta\)</span>) towards the population mean</em>. As the population mean is represented by the respective fixed effect, we can compute the absolute individual predictions by adding the fixed effect to the random effect. The results are shown in Figure <a href="mlm.html#fig:rescores-1">6.1</a>.</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="mlm.html#cb466-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">mu_i =</span> <span class="fu">ranef</span>(P_hf)<span class="sc">$</span>center <span class="sc">+</span></span>
<span id="cb466-2"><a href="mlm.html#cb466-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fixef</span>(P_hf)<span class="sc">$</span>center) <span class="sc">%&gt;%</span></span>
<span id="cb466-3"><a href="mlm.html#cb466-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu_i)) <span class="sc">+</span></span>
<span id="cb466-4"><a href="mlm.html#cb466-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span></code></pre></div>
<div class="figure"><span id="fig:rescores-1"></span>
<img src="Linear_mixed-effects_models_files/figure-html/rescores-1-1.png" alt="Absolute random effect scores" width="90%" />
<p class="caption">
Figure 6.1: Absolute random effect scores
</p>
</div>
<p>Note that first two lines in the above code only work correctly if there is just one population-level effect (i.e. a GMM). Package Bayr contains the general <code>re_score</code> to produce absolute random effects scores. This happens on the level of MCMC samples, from which CLUs can extracted, such as (Table <a href="mlm.html#tab:rescores-2">6.7</a>).</p>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="mlm.html#cb467-1" aria-hidden="true" tabindex="-1"></a><span class="fu">re_scores</span>(P_hf) <span class="sc">%&gt;%</span></span>
<span id="cb467-2"><a href="mlm.html#cb467-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu</span>() <span class="sc">%&gt;%</span></span>
<span id="cb467-3"><a href="mlm.html#cb467-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">8</span>)</span></code></pre></div>
<table>
<caption><span id="tab:rescores-2">Table 6.7: </span>Parameter estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="left">re_entity</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">r_Part[2,Intercept]</td>
<td align="left">2</td>
<td align="right">16.1</td>
<td align="right">13.0</td>
<td align="right">19.6</td>
</tr>
<tr class="even">
<td align="left">r_Part[23,Intercept]</td>
<td align="left">23</td>
<td align="right">15.4</td>
<td align="right">11.3</td>
<td align="right">18.2</td>
</tr>
<tr class="odd">
<td align="left">r_Part[19,Intercept]</td>
<td align="left">19</td>
<td align="right">16.1</td>
<td align="right">12.9</td>
<td align="right">19.4</td>
</tr>
<tr class="even">
<td align="left">r_Part[20,Intercept]</td>
<td align="left">20</td>
<td align="right">16.4</td>
<td align="right">13.7</td>
<td align="right">20.3</td>
</tr>
<tr class="odd">
<td align="left">r_Part[1,Intercept]</td>
<td align="left">1</td>
<td align="right">17.1</td>
<td align="right">14.5</td>
<td align="right">22.4</td>
</tr>
<tr class="even">
<td align="left">r_Part[5,Intercept]</td>
<td align="left">5</td>
<td align="right">16.0</td>
<td align="right">12.7</td>
<td align="right">19.3</td>
</tr>
<tr class="odd">
<td align="left">r_Part[15,Intercept]</td>
<td align="left">15</td>
<td align="right">16.2</td>
<td align="right">12.9</td>
<td align="right">19.7</td>
</tr>
<tr class="even">
<td align="left">r_Part[16,Intercept]</td>
<td align="left">16</td>
<td align="right">15.9</td>
<td align="right">12.5</td>
<td align="right">19.2</td>
</tr>
</tbody>
</table>
<p>Finally, we can assess the initial question: are individual differences a significant component of all variation in the experiment? Assessing the impact of variation is not as straight-forward as with fixed effects. Two useful heuristics are to compare group-level variation to the fixed effects estimate (Intercept) and against the standard error:</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="mlm.html#cb468-1" aria-hidden="true" tabindex="-1"></a>P_hf <span class="sc">%&gt;%</span></span>
<span id="cb468-2"><a href="mlm.html#cb468-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(type <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;grpef&quot;</span>, <span class="st">&quot;disp&quot;</span>, <span class="st">&quot;fixef&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb468-3"><a href="mlm.html#cb468-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu</span>()</span></code></pre></div>
<table>
<caption><span id="tab:rescores-3">Table 6.8: </span>Parameter estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="left">fixef</th>
<th align="left">re_factor</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b_Intercept</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="right">15.96</td>
<td align="right">14.423</td>
<td align="right">17.46</td>
</tr>
<tr class="even">
<td align="left">sd_Part__Intercept</td>
<td align="left">Intercept</td>
<td align="left">Part</td>
<td align="right">1.53</td>
<td align="right">0.079</td>
<td align="right">3.73</td>
</tr>
<tr class="odd">
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="right">16.39</td>
<td align="right">15.488</td>
<td align="right">17.39</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<p>The variation due to individual differences is an order of magnitude smaller than the Intercept, as well as the standard error. This lets us conclude that the novel interface works pretty much the same for every participant. If we are looking for relevant sources of variation, we have to look elsewhere. (As we have seen in <a href="lm.html#ofm">4.3.5</a>, the main source of variation is learning.)</p>
<!-- #### EATME -->
<!-- The variable `Part` is central for the model aboveA participant is just a group of observations, and fomrally, they there is one apparent, one practical and one subtle difference compared to factors as we know them so far. The apparent difference is that before we had just very few levels and many observations. With participants we would have to estimate dozens or hundreds of coefficients. In consequence, the posterior distribution will become spread out like butter on a toast and certainty would become will be abysmal. The practical difference is that, while we are interested in the overall variation, the ability of individual users is rather uninteresting. We actually have no use for dozens of user ability scores. The subtle difference is that users form a population. That sounds rather obviuous than subtle, but is key for the solution once we understand what being *member of a population* means. I will give a brief account here and return to the topic in section \@ref(random_effects). -->
<!-- Imagine the following situation: you are seated in a university bistro and you get the task to guess the intelligence quotient of every person entering the bistro. After every trial you are disclosed  the real IQ of the person. You know that the average IQ is 100 and you give a bonus of 5 owing to the fact it is at a university. The first five persons have the IQs: -->
<!-- ```{r} -->
<!-- IQ <- c(106, 108, 103, 115, 110) -->
<!-- ``` -->
<!-- It seems the bonus of five is an understatement and the average is closer to 110. You adjust your best guess accordingly. That sounds trivial, but for the specification of a regression model it is not. The crucial point is that any guess $k$ depends on the information you received on trials $1...(k-1)$. Review the model formulation for comparison of means models. There is nothing in the linear term  that transfers information between levels of factors. The group means are estimated in complete independence.   -->
<!-- The key is is that participants are *members of a population*. In a reasonably large population, extremes such as an IQ of 160 will eventually happen, but they are very unlikely. By far most people, roughly two thirds, are clumped together in the range 85 to 115. Imagine you are travelling to an African country you have never heard of before. Africa  has the richest gene pool of all and ethnicies differ a lot in tallness and skin tone. But, after you have seen a few people, you get an impression of how tall and dark people are in this place, and there is no more surprise. The same principle holds for human attributes or capabilities in design research. Having seen a bunch of participants completing a task between two and five minutes gives a best guess for the next particiant. It is not excluded that this person will need 25 minutes or 20 seconds  for the task, but it is less likely. -->
<!-- Factors where the individual levels vary, but are more or less clumped around a population mean are best modelled as *random factors* and the individual levels are called *random effects*. Random effects enter the likelihood of the linear model specification in a similar additive way as population-level linear effects. The difference is that the levels are assumed to stem from a normal distribution, which represents the clumping. The mean of this distribution is zero, similar to the distribution of residuals, but the standard deviation of this distribution, representing the amount of variation in the population, is *estimated alongside* the individual levels.  -->
</div>
<div id="slope-re" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Multi-level linear regression: variance in change</h2>
<p>So far, we have dealt with Intercept random effects that capture the gross differences between participants of a sample. We introduced these random effects as conditional effects like: “average performance depends on what person you are looking at.” However, most research questions rather regard differences between conditions.</p>
<p>With <em>slope random effects</em> we can represent individual <em>changes</em> in performance.
For an illustration of slope random effects, we take a look at a data set that ships with package Lme4 (which provides a non-Bayesian engine for multi-level models). 18 participants underwent sleep deprivation on ten successive days and the average reaction time on a set of tests has been recorded per day and participant. The research question is: what is the effect of sleep deprivation on reaction time and, again, this question can be asked on population level and participant level.</p>
<p>The participant-level plots in Figure <a href="mlm.html#fig:slpstd-1">6.2</a> shows the individual relationships between days of deprivation and reaction time. For most participants a positive linear association seems to be a good approximation, so we can go with a straight linear regression model, rather than an ordered factor model. One noticeable exception is the curve of participant 352, which is fairly linear, but reaction times get shorter with sleep deprivation. What would be the most likely explanation? Perhaps, 352 is a cheater, who slept secretly and improved by gaining experience with the task. That would explain the outstanding performance the participant reaches.</p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="mlm.html#cb470-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Sleepstudy)</span></code></pre></div>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="mlm.html#cb471-1" aria-hidden="true" tabindex="-1"></a>D_slpstd <span class="sc">%&gt;%</span></span>
<span id="cb471-2"><a href="mlm.html#cb471-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> days, <span class="at">y =</span> RT)) <span class="sc">+</span></span>
<span id="cb471-3"><a href="mlm.html#cb471-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Part) <span class="sc">+</span></span>
<span id="cb471-4"><a href="mlm.html#cb471-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb471-5"><a href="mlm.html#cb471-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> F, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">&quot;LOESS&quot;</span>)) <span class="sc">+</span></span>
<span id="cb471-6"><a href="mlm.html#cb471-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> F, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">&quot;Linear model&quot;</span>)) <span class="sc">+</span></span>
<span id="cb471-7"><a href="mlm.html#cb471-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">&quot;Smoothing function&quot;</span>) <span class="sc">+</span></span>
<span id="cb471-8"><a href="mlm.html#cb471-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.1</span>)) <span class="co"># !del+</span></span></code></pre></div>
<div class="figure"><span id="fig:slpstd-1"></span>
<img src="Linear_mixed-effects_models_files/figure-html/slpstd-1-1.png" alt="Participant-level association between sleep deprivation and RT" width="90%" />
<p class="caption">
Figure 6.2: Participant-level association between sleep deprivation and RT
</p>
</div>
<p>A more compact way of plotting multi-level slopes is the spaghetti plot below. By superimposing the population level effect, we can clearly see that participants vary in how sleep deprivation delays the reactions.</p>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb472-1"><a href="mlm.html#cb472-1" aria-hidden="true" tabindex="-1"></a>D_slpstd <span class="sc">%&gt;%</span></span>
<span id="cb472-2"><a href="mlm.html#cb472-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(</span>
<span id="cb472-3"><a href="mlm.html#cb472-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> days,</span>
<span id="cb472-4"><a href="mlm.html#cb472-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> RT,</span>
<span id="cb472-5"><a href="mlm.html#cb472-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">group =</span> Part</span>
<span id="cb472-6"><a href="mlm.html#cb472-6" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">+</span></span>
<span id="cb472-7"><a href="mlm.html#cb472-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">color =</span> <span class="st">&quot;participant&quot;</span>),</span>
<span id="cb472-8"><a href="mlm.html#cb472-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> .<span class="dv">5</span>, <span class="at">se =</span> F, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span></span>
<span id="cb472-9"><a href="mlm.html#cb472-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb472-10"><a href="mlm.html#cb472-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">group =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;population&quot;</span>),</span>
<span id="cb472-11"><a href="mlm.html#cb472-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">2</span>, <span class="at">se =</span> F, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span></span>
<span id="cb472-12"><a href="mlm.html#cb472-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb472-13"><a href="mlm.html#cb472-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">&quot;Level of Effect&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:slpstd-2"></span>
<img src="Linear_mixed-effects_models_files/figure-html/slpstd-2-1.png" alt="(Uncooked) Spaghetti plot showing population and participant-level effects" width="90%" />
<p class="caption">
Figure 6.3: (Uncooked) Spaghetti plot showing population and participant-level effects
</p>
</div>
<p>For a single level model, the formula would be <code>RT ~ 1 + days</code>, with the intercept being RT at day Zero and the coefficient <code>days</code> representing the change per day of sleep deprivation. The multi-level formula retains the population level and adds the participant-level term as a conditional statement: again, the effect depends on whom you are looking at.</p>
<p><code>RT ~ 1 + days + (1 + days|Part)</code></p>
<p>Remember to always put complex random effects into brackets, because the <code>+</code> operator has higher precedence than <code>|</code>. We estimate the multi-level model using the Rstanarm engine.</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="mlm.html#cb473-1" aria-hidden="true" tabindex="-1"></a>M_slpsty_1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(RT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> days <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> days <span class="sc">|</span> Part),</span>
<span id="cb473-2"><a href="mlm.html#cb473-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> D_slpstd,</span>
<span id="cb473-3"><a href="mlm.html#cb473-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span></span>
<span id="cb473-4"><a href="mlm.html#cb473-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Again, we could use the commands <code>fixef</code>, <code>ranef</code> and <code>grpef</code> to extract the parameters, but Bayr also provides a specialized command for multi-level tables, as Table <a href="mlm.html#tab:slpstd-4">6.9</a>: <code>fixef_ml</code> extracts the population-level estimates in CLU form and adds the participant-level standard deviation. The overall penalty for sleep deprivation is around ten milliseconds per day, with a 95% CI ranging from 7ms to 14ms. At the same time, the participant-level standard deviation is around 6.5ms, which is considerable. One can conclude that people vary a lot in how sleep deprivation effects their alertness. Figure <a href="mlm.html#fig:slpstd-5">6.4</a> shows a caterpillar plot of the slope random effects, ordered by the center estimate.</p>
<!-- Based on the assumption that the central two standard deviations of a Gaussian distribution contain two-thirds of the total mass, we can expect that roughly one third of the population has a penalty of smaller than 4ms *or* larger than 17ms. -->
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="mlm.html#cb474-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef_ml</span>(M_slpsty_1)</span></code></pre></div>
<table>
<caption><span id="tab:slpstd-4">Table 6.9: </span>Population-level coefficients with random effects standard deviations</caption>
<thead>
<tr class="header">
<th align="left">fixef</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
<th align="right">SD_Part</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">251.2</td>
<td align="right">237.17</td>
<td align="right">265.8</td>
<td align="right">26.1</td>
</tr>
<tr class="even">
<td align="left">days</td>
<td align="right">10.5</td>
<td align="right">7.01</td>
<td align="right">13.8</td>
<td align="right">6.4</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="mlm.html#cb475-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(M_slpsty_1) <span class="sc">%&gt;%</span></span>
<span id="cb475-2"><a href="mlm.html#cb475-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(fixef <span class="sc">==</span> <span class="st">&quot;days&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb475-3"><a href="mlm.html#cb475-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Part_ord =</span> <span class="fu">rank</span>(center)) <span class="sc">%&gt;%</span></span>
<span id="cb475-4"><a href="mlm.html#cb475-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Part_ord, <span class="at">ymin =</span> lower, <span class="at">y =</span> center, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb475-5"><a href="mlm.html#cb475-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_crossbar</span>() <span class="sc">+</span></span>
<span id="cb475-6"><a href="mlm.html#cb475-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;diff RT&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:slpstd-5"></span>
<img src="Linear_mixed-effects_models_files/figure-html/slpstd-5-1.png" alt="Caterpillar plot showing individual absolute scores for effect of one day of sleep deprivation" width="90%" />
<p class="caption">
Figure 6.4: Caterpillar plot showing individual absolute scores for effect of one day of sleep deprivation
</p>
</div>
<p>The multi-level regression model is mathematically specified as follows. Note how random coefficients <span class="math inline">\(\beta_{.(Part)}\)</span> are drawn from a Gaussian distribution with their own standard deviation, very similar to the errors <span class="math inline">\(\epsilon_i\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp;= \mu_i + \epsilon_i\\
\mu_i &amp;= \beta_0 + \beta_{0(Part)} + x_1 \beta_1 + x_{1}\beta_{1(Part)}\\
\beta_{0(Part))} &amp;\sim \textrm{Gaus}(0,\sigma_{0(Part)})\\
\beta_{1(Part))} &amp;\sim \textrm{Gaus}(0,\sigma_{1(Part)})\\
\epsilon_i &amp;= \textrm{Gaus}(0, \sigma_\epsilon)
\end{aligned}
\]</span></p>
<p>The second line can also be written as:</p>
<p><span class="math display">\[
 \mu_i = \beta_0 + \beta_{0(Part)} + x_1 (\beta_1 + \beta_{1(Part)})
 \]</span></p>
<p>This underlines that random coefficients are additive correction terms to the population-level effect, which is what <code>ranef</code> reports. Sometimes, it is useful to look at the total scores per participant. In package Bayr, the command <code>re_scores</code> computes absolute scores on the level of the posterior distribution. The following plot uses this command and plots two distributions: The participant-level variation in RT at Day 1 (Intercept) and after <em>twenty</em> nights* of sleep interruption, (assuming that the association is linear beyond the observed range). Figure <a href="mlm.html#fig:slpstd-6">6.5</a> shows the participant-level trajectories. We learn from it, that long-term sleep interruption creates a huge variance. If you design for a population where long-term sleep deprivation occurs, such as parents or doctors, and reaction time is critical, the worst case can be much, much worse than the average.</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="mlm.html#cb476-1" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior</span>(M_slpsty_1) <span class="sc">%&gt;%</span></span>
<span id="cb476-2"><a href="mlm.html#cb476-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">re_scores</span>() <span class="sc">%&gt;%</span></span>
<span id="cb476-3"><a href="mlm.html#cb476-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu</span>() <span class="sc">%&gt;%</span></span>
<span id="cb476-4"><a href="mlm.html#cb476-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(re_entity, fixef, center) <span class="sc">%&gt;%</span></span>
<span id="cb476-5"><a href="mlm.html#cb476-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> fixef, <span class="at">values_from =</span> center) <span class="sc">%&gt;%</span></span>
<span id="cb476-6"><a href="mlm.html#cb476-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb476-7"><a href="mlm.html#cb476-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="fu">aes</span>(</span>
<span id="cb476-8"><a href="mlm.html#cb476-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">intercept =</span> Intercept,</span>
<span id="cb476-9"><a href="mlm.html#cb476-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">slope =</span> days</span>
<span id="cb476-10"><a href="mlm.html#cb476-10" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">+</span></span>
<span id="cb476-11"><a href="mlm.html#cb476-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>, <span class="dv">20</span>) <span class="sc">+</span></span>
<span id="cb476-12"><a href="mlm.html#cb476-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">700</span>)</span></code></pre></div>
<div class="figure"><span id="fig:slpstd-6"></span>
<img src="Linear_mixed-effects_models_files/figure-html/slpstd-6-1.png" alt="Sleep deprivation projected " width="90%" />
<p class="caption">
Figure 6.5: Sleep deprivation projected
</p>
</div>
</div>
<div id="thinking-multi-level" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Thinking multi-level</h2>
<p>There is a lot of confusion about the type of models that we deal with in this chapter. They have also been called hierarchical models or mixed effects models. The “mixed” stands for a mixture of so called fixed effects and random effects. The problem is: if you start by understanding what fixed effects and random effects are, confusion is programmed, not only because there exist several very different definitions.</p>
<p>In fact, it does not matter so much whether an estimate is a fixed effect or random effect. As we will see, you can construct a multi-level model by using just plain descriptive summaries. What matters is that a model contains estimates on population level and on participant level. The benefit is, that a multi-level model can answer the same question for the population as a whole and for every single participant.</p>
<p>For entering the world of multi-level modeling, we do not need fancy tools. More important is to start thinking multi-level. In the following, I will introduce the basic ideas of multi-level modeling at the example of the IPump case. The idea is simple: A statistical model is developed on the population level and then we “pull it down” to the participant level.</p>
<p>In the IPump case, a novel syringe infusion pump design has been tested against a legacy design by letting trained nurses complete a series of eight tasks. Every nurse repeated the series three times on both designs. Time-on-task was measured and the primary research question is:</p>
<blockquote>
<blockquote>
<p>Does the novel design lead to faster execution of tasks?</p>
</blockquote>
</blockquote>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="mlm.html#cb477-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(IPump)</span></code></pre></div>
<p>To answer this question, we can compare the two group means using a basic CGM (Table <a href="mlm.html#tab:tml-1">6.10</a>)</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="mlm.html#cb478-1" aria-hidden="true" tabindex="-1"></a>M_cgm <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(ToT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> Design,</span>
<span id="cb478-2"><a href="mlm.html#cb478-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> D_pumps</span>
<span id="cb478-3"><a href="mlm.html#cb478-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="mlm.html#cb479-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span>(M_cgm)</span></code></pre></div>
<table>
<caption><span id="tab:tml-1">Table 6.10: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">fixef</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">27.9</td>
<td align="right">25.9</td>
<td align="right">29.76</td>
</tr>
<tr class="even">
<td align="left">DesignNovel</td>
<td align="right">-11.8</td>
<td align="right">-14.5</td>
<td align="right">-9.17</td>
</tr>
</tbody>
</table>
<p>This model is a single-level model. It takes all observations as “from the population” and estimates the means in both groups. It further predicts that with this population of users, the novel design is faster <em>on average</em>, that means taking the whole population into account, (and forgetting about individuals).</p>
<p>An average benefit sounds promising, but we should be clear what it precisely means, or better what it does not mean: That there is a benefit for the population does not imply, that every individual user has precisely that benefit. It does not even imply that every user has a benefit at all. In extreme case, a small subgroup could be negatively affected by the novel design, but this could still result in a positive result on average. In the evaluation of high-risk devices like infusion pumps concerns about individual performance are real and this is why we designed the study with within-subject conditions, which allows to estimate the same model on population level and participant level. The following code produces a <em>multi-level descriptive model</em>. First, a summary on participant level is calculated, then it is summarized to obtain the population level. By putting both summaries into one figure, we are doing a multi-level analysis.</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="mlm.html#cb480-1" aria-hidden="true" tabindex="-1"></a>T_Part <span class="ot">&lt;-</span></span>
<span id="cb480-2"><a href="mlm.html#cb480-2" aria-hidden="true" tabindex="-1"></a>  D_pumps <span class="sc">%&gt;%</span></span>
<span id="cb480-3"><a href="mlm.html#cb480-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part, Design) <span class="sc">%&gt;%</span></span>
<span id="cb480-4"><a href="mlm.html#cb480-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_Part =</span> <span class="fu">mean</span>(ToT))</span>
<span id="cb480-5"><a href="mlm.html#cb480-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb480-6"><a href="mlm.html#cb480-6" aria-hidden="true" tabindex="-1"></a>T_Pop <span class="ot">&lt;-</span></span>
<span id="cb480-7"><a href="mlm.html#cb480-7" aria-hidden="true" tabindex="-1"></a>  T_Part <span class="sc">%&gt;%</span></span>
<span id="cb480-8"><a href="mlm.html#cb480-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Design) <span class="sc">%&gt;%</span></span>
<span id="cb480-9"><a href="mlm.html#cb480-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_Pop =</span> <span class="fu">mean</span>(mean_Part))</span></code></pre></div>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="mlm.html#cb481-1" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(</span>
<span id="cb481-2"><a href="mlm.html#cb481-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb481-3"><a href="mlm.html#cb481-3" aria-hidden="true" tabindex="-1"></a>  T_Pop <span class="sc">%&gt;%</span></span>
<span id="cb481-4"><a href="mlm.html#cb481-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(</span>
<span id="cb481-5"><a href="mlm.html#cb481-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> Design, <span class="at">group =</span> <span class="cn">NA</span>,</span>
<span id="cb481-6"><a href="mlm.html#cb481-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> mean_Pop</span>
<span id="cb481-7"><a href="mlm.html#cb481-7" aria-hidden="true" tabindex="-1"></a>    )) <span class="sc">+</span></span>
<span id="cb481-8"><a href="mlm.html#cb481-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb481-9"><a href="mlm.html#cb481-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb481-10"><a href="mlm.html#cb481-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Population-level model (average benefits)&quot;</span>) <span class="sc">+</span></span>
<span id="cb481-11"><a href="mlm.html#cb481-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">60</span>),</span>
<span id="cb481-12"><a href="mlm.html#cb481-12" aria-hidden="true" tabindex="-1"></a>  T_Part <span class="sc">%&gt;%</span></span>
<span id="cb481-13"><a href="mlm.html#cb481-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(</span>
<span id="cb481-14"><a href="mlm.html#cb481-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> Design,</span>
<span id="cb481-15"><a href="mlm.html#cb481-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> mean_Part,</span>
<span id="cb481-16"><a href="mlm.html#cb481-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">group =</span> Part, <span class="at">label =</span> Part</span>
<span id="cb481-17"><a href="mlm.html#cb481-17" aria-hidden="true" tabindex="-1"></a>    )) <span class="sc">+</span></span>
<span id="cb481-18"><a href="mlm.html#cb481-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb481-19"><a href="mlm.html#cb481-19" aria-hidden="true" tabindex="-1"></a>    ggrepel<span class="sc">::</span><span class="fu">geom_label_repel</span>(<span class="at">size =</span> <span class="dv">3</span>, <span class="at">alpha =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb481-20"><a href="mlm.html#cb481-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Participant-level model (individual benefits)&quot;</span>) <span class="sc">+</span></span>
<span id="cb481-21"><a href="mlm.html#cb481-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">60</span>)</span>
<span id="cb481-22"><a href="mlm.html#cb481-22" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span id="fig:tml-2"></span>
<img src="Linear_mixed-effects_models_files/figure-html/tml-2-1.png" alt="Exploratory multi-level plot of population-level and participant-level change" width="90%" />
<p class="caption">
Figure 6.6: Exploratory multi-level plot of population-level and participant-level change
</p>
</div>
<p>Note</p>
<ul>
<li>how with <code>gridExtra::grid.arrange()</code> we can multiple plots into a grid, which is more flexible than using facetting</li>
<li>that <code>ggrepel::geom_label_repel</code> produces non-overlapping labels in plots</li>
</ul>
<p>Figure <a href="mlm.html#fig:tml-2">6.6</a> is a multi-level plot, as it shows the same effect on two different levels <em>alongside</em>. In this case, the participant-level plot confirms that the trend of the population-level effects is representative. Most worries about the novel design are removed, with the one exception of participant 3, all users had net benefit from using the novel design and we can call the novel design universally better. In addition, some users (4, 8 and 9) seem to have experienced catastrophes with the legacy design, but their difficulties disappear when they switch to the novel design.</p>
<p>If you look again at the participant-level <em>spaghetti plot</em> (They are uncooked!) and find it similar to what you have seen before, you are right: This is an design-by-participant <em>conditional plot</em>. Recall, that conditional effects represent the change of outcome, depending on another factor. In this multi-level model, this second factor simply Part(icipant). That suggests that it is well within reach of plain linear models to estimate design-by-participant conditional effects. Just for the purpose of demonstration, we can estimate a population level model, conditioning the design effect on participants. Ideally, we would use a parametrization giving us separate Intercept and DesignNovel effects per participant, but the formula interface is not flexible enough and we would have to work with dummy variable expansion. Since this is just a demonstration before we move on to the multi-level formula extensions, I use an AMM instead. A plain linear model can only hold one level at a time, which is why we have to estimate the two separate models for population and participant levels. Then we combine the posterior objects, extract the CLU table and plot the center estimates in Figure <a href="mlm.html#fig:tml-3">6.7</a>.</p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="mlm.html#cb482-1" aria-hidden="true" tabindex="-1"></a>M_amm_pop <span class="ot">&lt;-</span></span>
<span id="cb482-2"><a href="mlm.html#cb482-2" aria-hidden="true" tabindex="-1"></a>  D_pumps <span class="sc">%&gt;%</span></span>
<span id="cb482-3"><a href="mlm.html#cb482-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stan_glm</span>(ToT <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Design, <span class="at">data =</span> .)</span>
<span id="cb482-4"><a href="mlm.html#cb482-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb482-5"><a href="mlm.html#cb482-5" aria-hidden="true" tabindex="-1"></a>M_amm_part <span class="ot">&lt;-</span></span>
<span id="cb482-6"><a href="mlm.html#cb482-6" aria-hidden="true" tabindex="-1"></a>  D_pumps <span class="sc">%&gt;%</span></span>
<span id="cb482-7"><a href="mlm.html#cb482-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stan_glm</span>(ToT <span class="sc">~</span> (<span class="dv">0</span> <span class="sc">+</span> Design)<span class="sc">:</span>Part, <span class="at">data =</span> .)</span></code></pre></div>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="mlm.html#cb483-1" aria-hidden="true" tabindex="-1"></a>T_amm <span class="ot">&lt;-</span></span>
<span id="cb483-2"><a href="mlm.html#cb483-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb483-3"><a href="mlm.html#cb483-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">posterior</span>(M_amm_pop),</span>
<span id="cb483-4"><a href="mlm.html#cb483-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">posterior</span>(M_amm_part)</span>
<span id="cb483-5"><a href="mlm.html#cb483-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb483-6"><a href="mlm.html#cb483-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fixef</span>() <span class="sc">%&gt;%</span></span>
<span id="cb483-7"><a href="mlm.html#cb483-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(fixef, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;Design&quot;</span>, <span class="st">&quot;Part&quot;</span>))</span>
<span id="cb483-8"><a href="mlm.html#cb483-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb483-9"><a href="mlm.html#cb483-9" aria-hidden="true" tabindex="-1"></a>T_amm <span class="sc">%&gt;%</span></span>
<span id="cb483-10"><a href="mlm.html#cb483-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Design, <span class="at">y =</span> center, <span class="at">group =</span> Part, <span class="at">color =</span> model)) <span class="sc">+</span></span>
<span id="cb483-11"><a href="mlm.html#cb483-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<div class="figure"><span id="fig:tml-3"></span>
<img src="Linear_mixed-effects_models_files/figure-html/tml-3-1.png" alt="Spaghetti plot combining the results of a population-level with a participant-level model" width="90%" />
<p class="caption">
Figure 6.7: Spaghetti plot combining the results of a population-level with a participant-level model
</p>
</div>
<p>The convenience of (true) multi-level models is that both (or more) levels are specified and estimated as one model. For the multi-level models that follow, we will use a specialized engine, <code>brm()</code> (generalized multi-level regression) that estimates both levels simultaneously and produce multi-level coefficients. The multi-level CGM we desire is written like this:</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="mlm.html#cb484-1" aria-hidden="true" tabindex="-1"></a>M_mlcgm <span class="ot">&lt;-</span></span>
<span id="cb484-2"><a href="mlm.html#cb484-2" aria-hidden="true" tabindex="-1"></a>  D_pumps <span class="sc">%&gt;%</span></span>
<span id="cb484-3"><a href="mlm.html#cb484-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(ToT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> Design <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> Design <span class="sc">|</span> Part), <span class="at">data =</span> .)</span></code></pre></div>
<p>In the formula of this multi-level CGM the predictor term (<code>1 + Design</code>) is just copied. The first instance is the usual population-level averages, but the second is on participant-level. The <code>|</code> operator in probability theory means “conditional upon” and here this can be read as <em>effect of Design conditional on participant</em>.</p>
<p>For linear models we have been using the <code>coef()</code> command to extract all coefficients. Here it would extract all coefficients on both levels. With multi-level models, two specialized command exist to separate the levels: we can extract population-level effects using the <code>fixef()</code> command for <em>fixed effects</em> (Table <a href="mlm.html#tab:tml-4">6.11</a>). All lower level effects can be accessed with the <code>ranef</code> command, which stands for <em>random effects</em>. Random effects are <em>differences towards the population-level</em>. This is why random effects are always <em>centered at zero</em>. In the following histogram, the distribution of the DesignNovel random effects are shown. This is how much users deviate from the average effect in the population (Figure <a href="mlm.html#fig:tml-5">6.8</a>))</p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="mlm.html#cb485-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span>(M_mlcgm)</span></code></pre></div>
<table>
<caption><span id="tab:tml-4">Table 6.11: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">fixef</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">27.6</td>
<td align="right">23.7</td>
<td align="right">31.54</td>
</tr>
<tr class="even">
<td align="left">DesignNovel</td>
<td align="right">-11.7</td>
<td align="right">-15.3</td>
<td align="right">-8.05</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="mlm.html#cb486-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(M_mlcgm) <span class="sc">%&gt;%</span></span>
<span id="cb486-2"><a href="mlm.html#cb486-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">Part =</span> re_entity, <span class="st">`</span><span class="at">deviation</span><span class="st">`</span> <span class="ot">=</span> center) <span class="sc">%&gt;%</span></span>
<span id="cb486-3"><a href="mlm.html#cb486-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> deviation)) <span class="sc">+</span></span>
<span id="cb486-4"><a href="mlm.html#cb486-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="sc">~</span>fixef) <span class="sc">+</span></span>
<span id="cb486-5"><a href="mlm.html#cb486-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span></code></pre></div>
<div class="figure"><span id="fig:tml-5"></span>
<img src="Linear_mixed-effects_models_files/figure-html/tml-5-1.png" alt="Participant-level random effects in a CGM" width="90%" />
<p class="caption">
Figure 6.8: Participant-level random effects in a CGM
</p>
</div>
<p>The distribution of random effects should resemble a <em>Gaussian distribution</em>. It is usually hard to tell with such small sample sizes, but it seems that the Intercept effects have a left skew. As we will see in chapter <a href="glm.html#glm">7</a>, this problem is not surprising and can be resolved. The distributions are also centered at zero, which is not a coincidence, but the way random effects are designed: deviations from the population mean. That opens up two interesting perspectives: first, random effects look a lot like residuals <a href="lm.html#likelihood-random-term">4.1.2</a>, and like those we can summarize a random effects vector by its <em>standard deviation</em>, using the <code>grpef</code> command from package Bayr (Table <a href="mlm.html#tab:tml-6">6.12</a>).</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="mlm.html#cb487-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grpef</span>(M_mlcgm)</span></code></pre></div>
<table>
<caption><span id="tab:tml-6">Table 6.12: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">fixef</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">8.71</td>
<td align="right">6.03</td>
<td align="right">12.47</td>
</tr>
<tr class="even">
<td align="left">DesignNovel</td>
<td align="right">6.02</td>
<td align="right">2.98</td>
<td align="right">9.82</td>
</tr>
</tbody>
</table>
<p>Most design research is located on the population level. We want to know how a design works, broadly. Sometimes, stratified samples are used to look for conditional effects in (still broad) subgroups. Reporting individual differences makes little sense in such situations. The standard deviation summarizes individual differences and can be interpreted the <em>degree of diversity</em>. The command <code>bayr::fixef_ml</code> is implementing this by simply attaching the standard deviation center estimates to the respective population-level effect (Table <a href="mlm.html#tab:tml-7">6.13</a>). As coefficients and standard deviations are on the same scale, they can be compared. Roughly speaking, a two-thirds of the population is contained in an interval <em>twice as large</em> as the SD.</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="mlm.html#cb488-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef_ml</span>(M_mlcgm)</span></code></pre></div>
<table>
<caption><span id="tab:tml-7">Table 6.13: </span>Population-level coefficients with random effects standard deviations</caption>
<thead>
<tr class="header">
<th align="left">fixef</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
<th align="right">SD_Part</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">27.6</td>
<td align="right">23.7</td>
<td align="right">31.54</td>
<td align="right">8.71</td>
</tr>
<tr class="even">
<td align="left">DesignNovel</td>
<td align="right">-11.7</td>
<td align="right">-15.3</td>
<td align="right">-8.05</td>
<td align="right">6.02</td>
</tr>
</tbody>
</table>
<p>That having said, I believe that more researchers should watch their participant levels more closely. Later, we will look at two specific situations: psychometric models have the purpose of measuring individuals <a href="mlm.html#psychometrics">6.8</a> and those who propose universal theories (i.e., about people <em>per se</em>) must also show that their predictions hold for each and everyone <a href="mlm.html#universality">6.4</a>.</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<!-- The population-level coefficients represent the  -->
<!-- The random factor variation is extracted from the posterior distribution using the `grpef` command. The coefficients are standard deviations of the two random factors, Intercept and DesignB. The results confirm the earlier fixed effects analysis on the data set: the benefits of Design B varies a lot between users. When comparing the standard deviation with the the population-level effect, it seems that some users are experiencing a disadvantage, even. That matches the earlier results, where design B caused problems for elderly users. In fact, we can phrase the slope random effect in much the same way as conditional effect `age:Design` in \@ref(differential_design_effects), namely as a conditional statement of the form: -->
<!-- > the effect of Design depends on the participant.  -->
<!-- ```{r results = "tab"} -->
<!-- attach(BrowsingAB) -->
<!-- P_slope_1 %>%  -->
<!--   filter(fixef %in% c("Intercept", "DesignB"), -->
<!--          type %in% c("grpef", "fixef")) %>%  -->
<!--   group_by(re_factor, fixef) %>%  -->
<!--   clu() -->
<!-- detach(BrowsingAB) -->
<!-- ``` -->
<!-- Intercept random effects capture gross variations between users. Independent of designs, tasks or situation, some users can be assumed to always be faster, more accurate or pleased. That is certainly better than sticking with the image of the average user, but it remains static. With slope random effects can we render *individual differences in the process*. How differently do individual users react when proceeding from design A to B? That is a completely different question than the average difference between designs. Review the spaghetti plot \@ref(fig:BAB_RE_age) once again. Adding a slope random effect to the model really means that the effect is estimated as many times as there are participants in the sample (run `ranef(M_slope_1)` to see it). And these coefficients tell a story of *universality*. The more the random effects are dispersed, the less typical is the average (the fixed effect). Whether you are doing practical design research or  experimental design studies, universality matters.  -->
<!-- Assume an A/B study tested five participants with one task each.   -->
<!-- #### MAKE Sleep_study -->
<!-- #### REWORK ALL FORMULAS -->
<!-- The following simulation function creates a multi-level data set by sampling the Intercept effect and the Design effect from a Gaussian distribution. Per default arguments, participants differ a lot ($\sigma_{0P}$) The figure below illustrates the model on a sample of five participants. As the effect is the same, we see five parallel lines. While the height where a line starts differs between users, they all benefit to the precisely same amount from design B.Is that realistic? If we expect that differential design effects exist, it is not. There can be plenty of reasons why two users differ in how much the benefit from a certain design. For example, the BrowsingAB case features a strong conditional effect on age. When thinking of random effects, it helps to imagine the situation where an influencing factor exists, but was not recorded. The inter-individual variance will remain, and the participant identifier is the only predictor at hand. -->
<!-- ```{r} -->
<!-- sim <- function(n_Part = 5, -->
<!--                 beta_0P = rnorm(n_Part,0, sigma_0P), -->
<!--                 sigma_0P = 20, -->
<!--                 beta_1P = rnorm(n_Part,0, sigma_1P), -->
<!--                 sigma_1P = 0, -->
<!--                 sigma_eps = 0) { -->
<!--   Part = tibble(Part = 1:n_Part,  -->
<!--                      beta_0P = beta_0P,  -->
<!--                      beta_1P = beta_1P) -->
<!--   Design = tibble(Design = c("A", "B"), -->
<!--                        beta_0 = 120, -->
<!--                        beta_1 = -30) -->
<!--   mascutils::expand_grid(Part = Part$Part, Design = Design$Design) %>%  -->
<!--     left_join(Part) %>%  -->
<!--     left_join(Design) %>%  -->
<!--     mutate(mu = beta_0 + beta_0P + (beta_1 + beta_1P) * (Design == "B"), -->
<!--            ToT = rnorm(nrow(.), mu, 0)) %>%  -->
<!--     as_tbl_obs() -->
<!-- } -->
<!-- sim() %>%  -->
<!--   ggplot(aes(x = Design,  -->
<!--              y = ToT, -->
<!--              group = Part)) + -->
<!--   geom_line() -->
<!-- ``` -->
<!-- A more realistic figure of the effects is the spaghetti plot below. All but one of the participants improve with design B, but to rather different degrees. The lines have different starting points, and they differ in slopes. This is called a *slope random effect*. Similar to intercept random effects, slope random effects are factors that represent individual deviations from the population-level effect.  -->
<!-- ```{r} -->
<!-- sim(sigma_1P = 15) %>%  -->
<!--   ggplot(aes(x = Design,  -->
<!--              y = ToT, -->
<!--              group = Part)) + -->
<!--   geom_line() -->
<!-- ``` -->
<!-- For the design effect in BrowsingAB, a model with intercept and slope random effects is formally specified as: -->
<!-- $$ -->
<!-- \mu_i = \beta_0 + \beta_{1P} + x_1\beta_1 + x_{1}\beta_{1p}\\ -->
<!-- \beta_{1P} \sim \textrm{Gaus}(0,\sigma_{1P})\\ -->
<!-- \beta_{1p} \sim \textrm{Gaus}(0,\sigma_{1P}) -->
<!-- $$ -->
<!-- Previously, we have seen that repeated measures are the key to pull a random effect out of the residual term. The same holds for slope random effects. For estimating individual slopes, the same participant (or any non-human entity) must encounter multiple conditions. For demonstration of slope random effects, we examine another instantiation of the BrowsingAB data set `BAB5`, which differs from `BAB1` in two aspects: all participants encounter both designs (within-entity design) and ToT was measured on five given tasks (repeated measures). We use the simulation function as provided by the BrowsingAB case environment. As always, we start with some exploratory analysis.  -->
<!-- ```{r} -->
<!-- attach(BrowsingAB) -->
<!-- ``` -->
<!-- The spaghetti plot (the pasta is dry, not cooked) is excellent for visualizing participant-level effects. For the BAB5 data set the following figure shows the individual design effects. While on average design B is favoured, there is a wild bunch of slopes. That should not surprise us, as in the previous chapter we discovered a strong conditional effect by age. Here we ignore this predictor (or pretend not to have recorded it) and exclusively work with the participant factor. -->
<!-- ```{r BAB_RE_age, opts.label = "fig.wide"} -->
<!-- G_slope_RE_1 <- -->
<!--   BAB5 %>%  -->
<!--   group_by(Part, Design) %>%  -->
<!--   summarize(ToT = mean(ToT)) %>%  -->
<!--   ggplot(aes(x = Design,  -->
<!--               y = ToT)) + -->
<!--   geom_line(aes(color = "participant effects", group = Part), alpha = .7) + -->
<!--   geom_line(data = group_by(BAB5, Design) %>% summarize(ToT = mean(ToT)),  -->
<!--             aes(X = Design, y = ToT, group = 1, color = "population effect"), size = 1) + -->
<!--   labs(color = NULL) -->
<!-- G_slope_RE_1 -->
<!-- ``` -->
</div>
<div id="universality" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Testing universality of theories</h2>
<p>Often, the applied researcher is primarily interested in a population-level effect, as this shows the <em>average</em> expected benefit. If you run a webshop, your returns are exchangeable. One customer lost can be compensated by gaining a new one. In such cases, it suffices to report the random effects standard deviation. If user performance varies strongly, this can readily be seen in this one number.</p>
<p>In at least two research situations, going for the average is just not enough: when testing hazardous equipment and when testing theories. In safety critical research, such as a medical infusion pump, the rules are different than for a webshop. The rules are non-compensatory, as the benefit of extreme high performance on one patient cannot compensate the costs associated with a single fatal error on another patient. For this asymmetry, the design of such a system must enforce a <em>robust</em> performance, with no catastrophes. The multi-level analysis of the infusion pumps in <a href="mlm.html#thinking-multi-level">6.3</a> is an example. It demonstrated that practically all nurses will have a benefit from the novel design.</p>
<p>The other area where on-average is not enough, is theory-driven experimental research. Fundamental behavioural researchers are routinely putting together theories on The Human Mind and try to challenge these theories. For example the Uncanny Valley effect <a href="mpm.html#prm">5.5</a>: one social psychologist’s theory could be that the Uncanny Valley effect is caused by religious belief, whereas a cognitive psychologist could suggest that the effect is caused by a category confusion on a fundamental processing level (seeing faces). Both theories make universal statements, about all human beings. <em>Universal statements</em> can never be proven, but can only be hardened. However, once a counter-example is found, the theory needs to be abandonded. If there is one participant who is provenly non-religious, but falls into the Uncanny Valley, our social psychologist would be proven wrong. If there is a single participant in the world, who is robvust against the Uncanny Valley, the cognitive psychologist was wrong.</p>
<p>Obviously, this counter-evidence can only be found on participant level. In some way, the situation is analog to robustness. The logic of universal statements is that they are false if there is one participant who breaks the pattern, and there is no compensation possible. Unfortunately, the majority of fundamental behavioural researchers, have ignored this simple logic and still report population-level estimates when testing universal theories. In my opinion, all these studies should not be trusted, before a multi-level analysis shows that the pattern exists on participant level.</p>
<p>In <a href="mpm.html#prm">5.5</a>, the Uncanny Valley effect has been demonstrated on population level. This is good enough, if we just want to confirm the Uncanny Valley effect as an observation, something that frequently
happens, but not necessarily for everyone. The sample in our study consisted of mainly students and their closer social network. It is almost certain, that many of the tested persons were religious and others were atheists. If the religious-attitude theory is correct, we would expect to see the Uncanny Valley in several participants, but not in all. If the category confusion theory is correct, we would expect all participants to fall into the valley. The following model performs the polynomial analysis as before <a href="mpm.html#prm">5.5</a>, but multi-level:</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="mlm.html#cb490-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Uncanny)</span></code></pre></div>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="mlm.html#cb491-1" aria-hidden="true" tabindex="-1"></a>M_poly_3_ml <span class="ot">&lt;-</span></span>
<span id="cb491-2"><a href="mlm.html#cb491-2" aria-hidden="true" tabindex="-1"></a>  RK_1 <span class="sc">%&gt;%</span></span>
<span id="cb491-3"><a href="mlm.html#cb491-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(response <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> huMech1 <span class="sc">+</span> huMech2 <span class="sc">+</span> huMech3 <span class="sc">+</span></span>
<span id="cb491-4"><a href="mlm.html#cb491-4" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">+</span> huMech1 <span class="sc">+</span> huMech2 <span class="sc">+</span> huMech3 <span class="sc">|</span> Part),</span>
<span id="cb491-5"><a href="mlm.html#cb491-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> ., <span class="at">iter =</span> <span class="dv">2500</span></span>
<span id="cb491-6"><a href="mlm.html#cb491-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb491-7"><a href="mlm.html#cb491-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb491-8"><a href="mlm.html#cb491-8" aria-hidden="true" tabindex="-1"></a>P_poly_3_ml <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_poly_3_ml)</span>
<span id="cb491-9"><a href="mlm.html#cb491-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb491-10"><a href="mlm.html#cb491-10" aria-hidden="true" tabindex="-1"></a>PP_poly_3_ml <span class="ot">&lt;-</span> <span class="fu">post_pred</span>(M_poly_3_ml, <span class="at">thin =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>One method for testing universality is to extract the fitted responses (<code>predict</code>) and perform a visual examination: can we see a valley for every participant?</p>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb492-1"><a href="mlm.html#cb492-1" aria-hidden="true" tabindex="-1"></a>T_pred <span class="ot">&lt;-</span></span>
<span id="cb492-2"><a href="mlm.html#cb492-2" aria-hidden="true" tabindex="-1"></a>  RK_1 <span class="sc">%&gt;%</span></span>
<span id="cb492-3"><a href="mlm.html#cb492-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">M_poly_3_ml =</span> <span class="fu">predict</span>(PP_poly_3_ml)<span class="sc">$</span>center)</span>
<span id="cb492-4"><a href="mlm.html#cb492-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb492-5"><a href="mlm.html#cb492-5" aria-hidden="true" tabindex="-1"></a>T_pred <span class="sc">%&gt;%</span></span>
<span id="cb492-6"><a href="mlm.html#cb492-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> huMech, <span class="at">y =</span> M_poly_3_ml, <span class="at">group =</span> Part)) <span class="sc">+</span></span>
<span id="cb492-7"><a href="mlm.html#cb492-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> F, <span class="at">size =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb492-8"><a href="mlm.html#cb492-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;human likeness&quot;</span>, <span class="at">y =</span> <span class="st">&quot;fitted emotional response&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:uncanny-7"></span>
<img src="Linear_mixed-effects_models_files/figure-html/uncanny-7-1.png" alt="Participant-level associations between human likeness and " width="90%" />
<p class="caption">
Figure 6.9: Participant-level associations between human likeness and
</p>
</div>
<p>This spaghetti plot broadly confirms, that all participants experience the Uncanny Valley. For a more detailed analysis, a facetted plot would be better suited, allowing to inspect the curves case-by-case.</p>
<p>We proceed directly to a more formal method of testing universality: In <a href="mpm.html#test-stat">5.5.1</a> we have seen how the posterior distributions of shoulder and trough can be first derived and then used to give a more definitive answer on the shape of the polynomial. It was argued that the unique pattern of the Uncanny Valley is to have a shoulder left of a trough. These two properties can be checked by identifying the stationary points. The proportion of MCMC iterations that fulfill these properties can is evidence that the effect exists.</p>
<p>For testing universality of the effect, we just have to run the same analysis on participant-level. Since the participant-level effects are deviations from the population-level effect, we first have to add the population level effect to the random effects (using the Bayr command <code>re_scores</code>), which creates absolute polynomial coefficients. The two commands <code>trough</code> and <code>shoulder</code> from package Uncanny require a matrix of coefficients, which is done by spreading out the posterior distribution table. Then all the characteristics of the polynomial are checked, that define the Uncanny Valley phenomenon:</p>
<ul>
<li>a trough</li>
<li>a shoulder</li>
<li>the shoulder is left of the trough</li>
</ul>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="mlm.html#cb493-1" aria-hidden="true" tabindex="-1"></a><span class="co"># devtools::install_github(&quot;schmettow/uncanny&quot;)</span></span>
<span id="cb493-2"><a href="mlm.html#cb493-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb493-3"><a href="mlm.html#cb493-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(uncanny)</span>
<span id="cb493-4"><a href="mlm.html#cb493-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb493-5"><a href="mlm.html#cb493-5" aria-hidden="true" tabindex="-1"></a>P_univ_uncanny <span class="ot">&lt;-</span></span>
<span id="cb493-6"><a href="mlm.html#cb493-6" aria-hidden="true" tabindex="-1"></a>  P_poly_3_ml <span class="sc">%&gt;%</span></span>
<span id="cb493-7"><a href="mlm.html#cb493-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">re_scores</span>() <span class="sc">%&gt;%</span></span>
<span id="cb493-8"><a href="mlm.html#cb493-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(iter, <span class="at">Part =</span> re_entity, fixef, value) <span class="sc">%&gt;%</span></span>
<span id="cb493-9"><a href="mlm.html#cb493-9" aria-hidden="true" tabindex="-1"></a>  tidyr<span class="sc">::</span><span class="fu">spread</span>(<span class="at">key =</span> <span class="st">&quot;fixef&quot;</span>, <span class="at">value =</span> <span class="st">&quot;value&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb493-10"><a href="mlm.html#cb493-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(iter, Part, <span class="at">huMech0 =</span> Intercept, huMech1<span class="sc">:</span>huMech3) <span class="sc">%&gt;%</span></span>
<span id="cb493-11"><a href="mlm.html#cb493-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb493-12"><a href="mlm.html#cb493-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">trough =</span> <span class="fu">trough</span>(<span class="fu">select</span>(., huMech0<span class="sc">:</span>huMech3)),</span>
<span id="cb493-13"><a href="mlm.html#cb493-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">shoulder =</span> <span class="fu">shoulder</span>(<span class="fu">select</span>(., huMech0<span class="sc">:</span>huMech3)),</span>
<span id="cb493-14"><a href="mlm.html#cb493-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">has_trough =</span> <span class="sc">!</span><span class="fu">is.na</span>(trough),</span>
<span id="cb493-15"><a href="mlm.html#cb493-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">has_shoulder =</span> <span class="sc">!</span><span class="fu">is.na</span>(shoulder),</span>
<span id="cb493-16"><a href="mlm.html#cb493-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">shoulder_left =</span> trough <span class="sc">&gt;</span> shoulder,</span>
<span id="cb493-17"><a href="mlm.html#cb493-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">is_uncanny =</span> has_trough <span class="sc">&amp;</span> has_shoulder <span class="sc">&amp;</span> shoulder_left</span>
<span id="cb493-18"><a href="mlm.html#cb493-18" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>To produce Figure <a href="mlm.html#fig:uncanny-8">6.10</a>, the probability that the participant experienced the Uncanny Valley is calculated as the proportion (<code>mean</code>) of MCMC samples that meet the criteria.</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="mlm.html#cb494-1" aria-hidden="true" tabindex="-1"></a>P_univ_uncanny <span class="sc">%&gt;%</span></span>
<span id="cb494-2"><a href="mlm.html#cb494-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part) <span class="sc">%&gt;%</span></span>
<span id="cb494-3"><a href="mlm.html#cb494-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_uncanny =</span> <span class="fu">mean</span>(is_uncanny)) <span class="sc">%&gt;%</span></span>
<span id="cb494-4"><a href="mlm.html#cb494-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">label =</span> <span class="fu">str_c</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="fu">round</span>(prob_uncanny, <span class="dv">4</span>), <span class="st">&quot;%&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb494-5"><a href="mlm.html#cb494-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Part, <span class="at">y =</span> prob_uncanny)) <span class="sc">+</span></span>
<span id="cb494-6"><a href="mlm.html#cb494-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb494-7"><a href="mlm.html#cb494-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_label</span>(<span class="fu">aes</span>(<span class="at">label =</span> label)) <span class="sc">+</span></span>
<span id="cb494-8"><a href="mlm.html#cb494-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>))</span></code></pre></div>
<div class="figure"><span id="fig:uncanny-8"></span>
<img src="Linear_mixed-effects_models_files/figure-html/uncanny-8-1.png" alt="Participant-level certainty that the Uncanny Valley phenomenon happened" width="90%" />
<p class="caption">
Figure 6.10: Participant-level certainty that the Uncanny Valley phenomenon happened
</p>
</div>
<p>Figure <a href="mlm.html#fig:uncanny-8">6.10</a> gives strong support to the universality of the Uncanny Valley. What may raise suspicion is rather that for most participants the probability is 100%. If this is all based on a random walk, we should at least see a few deviations, shouldn’t we. The reason for that is that MCMC samples approximate the posterior distribution by frequency. As their is a limited number of samples (here: 4000), the resolution is limited. If we increase the number of iterations enough, we would eventually see few “deviant” samples appear and measure the tiny chance that a participant does not fall for the Uncanny Valley.</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<p>This is great news for all scientists who believe that the Uncanny Valley effect is an innate cognitive phenomenon (rather than cultural). The same technique can also be used for the identification of deviant participants, those few that are totally against the trend. We briefly re-visit case Sleepstudy, for which we have estimated a multi-level linear regression model to render individual increase of reaction time as result of sleep deprivation (<a href="mlm.html#slope-re">6.2</a>). By visual inspection, we identified a single deviant participant who showed an improvement over time, rather than a decline. However, the fitted lines a based on point estimates, only (the median of the posterior). Using the same technique as above, we can calculate the participant-level probabilities for the slope being positive, as expected.</p>
<div class="sourceCode" id="cb496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb496-1"><a href="mlm.html#cb496-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Sleepstudy)</span></code></pre></div>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="mlm.html#cb497-1" aria-hidden="true" tabindex="-1"></a>P_scores <span class="ot">&lt;-</span></span>
<span id="cb497-2"><a href="mlm.html#cb497-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">posterior</span>(M_slpsty_1) <span class="sc">%&gt;%</span></span>
<span id="cb497-3"><a href="mlm.html#cb497-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">re_scores</span>() <span class="sc">%&gt;%</span></span>
<span id="cb497-4"><a href="mlm.html#cb497-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Part =</span> re_entity)</span>
<span id="cb497-5"><a href="mlm.html#cb497-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb497-6"><a href="mlm.html#cb497-6" aria-hidden="true" tabindex="-1"></a>P_scores <span class="sc">%&gt;%</span></span>
<span id="cb497-7"><a href="mlm.html#cb497-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(fixef <span class="sc">==</span> <span class="st">&quot;days&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb497-8"><a href="mlm.html#cb497-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part) <span class="sc">%&gt;%</span></span>
<span id="cb497-9"><a href="mlm.html#cb497-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_positive =</span> <span class="fu">mean</span>(value <span class="sc">&gt;=</span> <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb497-10"><a href="mlm.html#cb497-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">label =</span> <span class="fu">str_c</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="fu">round</span>(prob_positive, <span class="dv">4</span>), <span class="st">&quot;%&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb497-11"><a href="mlm.html#cb497-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Part, <span class="at">y =</span> prob_positive)) <span class="sc">+</span></span>
<span id="cb497-12"><a href="mlm.html#cb497-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb497-13"><a href="mlm.html#cb497-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_label</span>(<span class="fu">aes</span>(<span class="at">label =</span> label), <span class="at">vjust =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb497-14"><a href="mlm.html#cb497-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>))</span></code></pre></div>
<div class="figure"><span id="fig:slpstd-7"></span>
<img src="Linear_mixed-effects_models_files/figure-html/slpstd-7-1.png" alt="Participant-level certainty that the Uncanny Valley phenomenon happened" width="90%" />
<p class="caption">
Figure 6.11: Participant-level certainty that the Uncanny Valley phenomenon happened
</p>
</div>
<p>All, but participants 309 and 335, almost certainly have positive slopes. Participant 335 we had identified earlier by visual inspection. Now, that we account for the full posterior distribution, it seems less suspicious. There is almost a 50% chance that the participant is suffering from sleep deprivation, too. Figure <a href="mlm.html#fig:slpstd-8">6.12</a> is an attempt at illustrating the uncertainty. It shows all the possible slopes the MCMC random walk has explored from (unsuspicious) participant 308 and participant 335. While the latter has a distinctly different distribution, there is no compelling reason to get too excited and call 335 a true counter-example from the rule that sleep deprivation reduces cognitive performance.</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="mlm.html#cb498-1" aria-hidden="true" tabindex="-1"></a>P_scores <span class="sc">%&gt;%</span></span>
<span id="cb498-2"><a href="mlm.html#cb498-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Part <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">308</span>, <span class="dv">335</span>), fixef <span class="sc">==</span> <span class="st">&quot;days&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb498-3"><a href="mlm.html#cb498-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb498-4"><a href="mlm.html#cb498-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="fl">0.05</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb498-5"><a href="mlm.html#cb498-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">25</span>) <span class="sc">+</span></span>
<span id="cb498-6"><a href="mlm.html#cb498-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="fu">aes</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> value),</span>
<span id="cb498-7"><a href="mlm.html#cb498-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">01</span></span>
<span id="cb498-8"><a href="mlm.html#cb498-8" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb498-9"><a href="mlm.html#cb498-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(. <span class="sc">~</span> Part)</span></code></pre></div>
<div class="figure"><span id="fig:slpstd-8"></span>
<img src="Linear_mixed-effects_models_files/figure-html/slpstd-8-1.png" alt="Visualizing the uncertainty in Days for two pareticipants" width="90%" />
<p class="caption">
Figure 6.12: Visualizing the uncertainty in Days for two pareticipants
</p>
</div>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<p>In turn, the method of posterior-based test statistics can also be used for <em>analysis of existence</em>. In the Sleepstudy case a hypothetical question of existence would be that there exist persons who are completely insensitive to sleep deprivation. Why not? Recently, I saw a documentary about a guy who could touch charged electric wires, because due to a rare genetic deviation, his skin had no sweat glands. Whereas universal statements can only be falsified by a counter-example, statements of existence can be proven by just a single case. For example, in the 1980 dyslexia became more widely recognized as a defined condition. Many parents finally got an explanation for the problems their kids experienced in school. Many teachers complained that many parents would just seek cheap excuses for their lesser gifted offsprings. And some people argued that dyslexia does not exist and that the disability to read is just a manifestation of lower intelligence. According to the logic of existence, a single person with a well functioning intellect, but hampered reading suffices to proof the existence of dyslexia. These people have been found in the meantime.</p>
<!-- Robustness and universality can be examined by looking at participant-level estimates. In \@ref(thinking-multilevel) we compared two infusion pump designs using a multi-level model. The participant-level results showed that  -->
<!-- The question of universality is also relevant for safety-critical systems, because they have a non-linear loss function:  In  section [thinking-multi-level] we already encountered such a case: a novel infusion pump interface was compared with a legacy design. In this study, all participants encountered both designs, so we can estimate all effects on participant level and check universality of direction. Is the novel design better for everyone? -->
<!-- At the same time, we studied learnability in this experiment by tracking performance across three sessions with the same set of tasks. For learnability, it makes not so much sense to examine unversality. Learning by repetition is so common, that no one would be surprised in learning that every single participant got better with practice. -->
<!-- The following model specifies the effects of design and practice on cognitive workload. This is simultaneously estimated on population and participant level. In order to make the interpretation of coefficients and their variance easier to interpret, we are estimating a multi-level model with absolute group means for the first session per design and . The factor Session, we leave as successive difference coding [contrasts]. -->
<!-- #### HERE -->
<!-- ```{r} -->
<!-- attach(IPump) -->
<!-- ``` -->
<!-- ```{r opts.label = "mcmc"} -->
<!-- M_wkld <-    -->
<!--   D_pumps %>%   -->
<!--   brm(workload ~  -->
<!--                 0 + Design:Session + Design +  -->
<!--                (0 + Design:Session + Design|Part), -->
<!--              data = ., -->
<!--              iter = 200) -->
<!-- ``` -->
<!-- ```{r opts.label = "mcsync"} -->
<!-- sync_CE(IPump,M_wkld) -->
<!-- ``` -->
<!-- In  order to help the reader interpreting the magnitude of effects and inspect variation of that effect, a useful form of presenting multi-level results is to attach the random factor standard deviations to the coefficient table. The following function creates such a table. It first extracts the SD center estimates and puts them into as many columns as there are factor levels (Part, Task). The result is joint with the population-level coefficients. -->
<!-- ```{r} -->
<!-- fixef_ml <- function(model, ...){ -->
<!--   T_grpef <-  -->
<!--     grpef(model, ...) %>%  -->
<!--     select(fixef, re_factor, SD = center) %>%  -->
<!--     mutate(re_factor = str_c("SD_", re_factor)) %>%  -->
<!--     spread(re_factor, SD) -->
<!--   fixef(model, ...)  %>% -->
<!--     left_join(T_grpef, by = "fixef") %>%  -->
<!--     discard_redundant() -->
<!-- } -->
<!-- ``` -->
<!-- ```{r} -->
<!-- T_fixef_ml <- fixef_ml(M_wkld) -->
<!-- T_fixef_ml -->
<!-- T_fixef_ml %>%  -->
<!--   ggplot(aes(x = Session, -->
<!--              y = center, -->
<!--              color = Design)) -->
<!-- ``` -->
<!-- This shows that participants vary strongly in the levels of mental workload they reported. The Part-level SD for the Intercept is   -->
<!-- ```{r} -->
<!-- detach(IPump) -->
<!-- ``` -->
<!-- #### Exercises -->
<!-- 1. Review the scientific literature in your field. Find examples of design experiments where general conclusions were drawn from between-subject predictors. If that was easy, visit one of the leading social psychology journals and repeat. -->
</div>
<div id="non-human-populations" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Non-human populations and cross-overs</h2>
<p>With multi-level models design researchers can examine how a design affects the population of users as a whole, as well as on individual level. If there is little variation between users, it can be concluded that the effect is uniform in the population of users. In this section we will generalize the term <em>population</em> and extend the application of multi-level modeling to other types of research entities, such as designs, questionnaire items and tasks.</p>
<!-- In the  BrowsingAB case, this gives valuable information on how well this particular design serves the population of users and whether one should be satisfied with it or not. This is a typical research question in applied design research where one seeks to choose one from a small set of designs. Generally, A/B studies seek to answer the question: *is one design better for the user population?*. This question has two entities: the user and the design. However, it is not symmetric, as users are provided as a sample from which one wishes to generalize, whereas the two designs are exhaustive. There is the choice between the two and they are both present. -->
<p>Many studies in, what one could call <em>fundamental design research</em> seek to uncover general laws of design that may guide future system development. Fundamental design research is not concerned with choosing between individual designs, whether they are good enough or not, but with separating the population of possible designs into good ones and bad ones by universal statements, such as “For informational websites, broad navigation structures are better than deep ones.” Note how this statement speaks of designs (not users) in an unspecified plural. It is framed as a universal law for the population of designs.</p>
<p>Comparative evaluation studies, such as the IPump case, are not adequate to answer such questions, simply because you cannot generalize to the population from a sample of two. This is only possible under strict constraints, namely that the two designs under investigation only differ in one design property. For example two versions of a website present the same web content in a deep versus a wide hierarchy, but layout, functionality are held constant. And even then, we should be very careful with conclusions, because there can be interaction effects. For example, the rules could be different for a website used by expert users.</p>
<p>If the research question is universal, i.e. aiming at general conclusions on all designs (of a class), it is inevitable to see designs as a population from which we collect a sample. The term population suggests a larger set of entities, and in fact many application domains have an abundance of existing designs and a universe of possible designs. Just to name a few: there exist dozens of note taking apps for mobile devices and hundreds of different jump’n run games. Several classes of websites count in the ten thousands, such as webshops, municipal websites or intranets.</p>
<p>We can define classes of objects in any way we want, but the term population, has a stronger meaning than just a collection. A population contains individuals of the same kind and these individuals vary, but only to some extent. At the same time, it is implied that we can identify some sort of typical value for a population, such that most individuals are clumped around this typical value. Essentially, if it looks similar to one of the basic statistical distributions <a href="ebs.html#distributions">3.5.2</a>, we can call it a population.</p>
<p>To illustrate that not every class is a population, take vehicles. Vehicles are a class of objects that transport people or goods. This broad definition covers many types of vehicles, including bicycles, rikshas, cars, buses, trucks and container vessels. If the attribut under question is the weight, we will see a distribution spreading from a 10 kilograms up to 100 tons (without freight). That is a a scale of 1:10.000 and the distribution would spread out like butter on a warm toast. Formally, we can calculate the average weight of a all vehicles, but that would in no way represent a typical value.</p>
<!-- Even in highly standardized domains such as automotive cockpits the differences between generations, manufacturers and models are noticable to be called individuals from a population. That is precisely the idea of a random effect: entities vary around a clump of commonalities. In consequence, when testing a fundamental design rule, like *large fonts are better to read*, the proposed research strategy is to sample from the population of websites, classify sample members by font size, and test every design with a sample of users. Given our definition of random effects it is easy to see that the regression model will contain two random effects (at least), one across users, the other across websites. More on that later. -->
<p>In design research the most compelling populations are <em>users</em> and <em>designs</em>. Besides that research objects exist that we can also call members of a population, such as <em>tasks</em>, <em>situations</em> and <em>questionnaire items</em>.</p>
<p><em>Tasks:</em> Modern informational websites contain thousands of information pieces and finding every one of those can be considered a task. At the same time, it is impossible to cover them all in one study, such that sampling a few is inevitable. We will never be able to tell the performance of every task, but using random effects it is possible to estimate the variance of tasks. Is that valuable information? Probably it is in many cases, as we would not easily accept a design that prioritizes on a few items at the expense of many others, which are extremely hard to find.</p>
<p><em>Situations:</em> With the emerge of the web, practically everyone started using computers to find information. With the more recent breakthrough in mobile computing, everyone is doing everything using a computer in almost every situation. People chat, listen to music and play games during meals, classes and while watching television. They let themselves being lulled into sleep, which is tracked and interrupted by smart alarms. Smartphones are being used on trains, while driving cars and bikes, however dangerous that might be, and not even the most private situations are spared. If you want to evaluate the usability of any mobile messaging, navigation and e-commerce app, you should test it in all these situations. A study to examine performance across situations needs a sample from a population of situations.</p>
<p><em>Questionnaire items:</em> Most design researchers cannot refrain from using questionnaires to evaluate certain elucive aspects of their designs. A well constructed rating scale consists of a set of items that trigger similar responses. At the same time, it is desireable that items are unsimilar to a degree, as that establishes good discrimination across a wide range. In ability tests, for example to assess people’s intelligence or math skills, test items are constructed to vary in difficulty. The more ability a person has, the more likely will a very difficult item be solved correctly. In design research, rating scales cover concepts such as perceived mental workload, perceived usability, beauty or trustworthiness. Items of such scales differ in how extreme the proposition is, like the following three items that could belong to a scale for aesthetic perception:</p>
<ol style="list-style-type: decimal">
<li>The design is not particularly ugly.</li>
<li>The design is pretty.</li>
<li>The design is a piece of art.</li>
</ol>
<p>For any design it is rather difficult to get a positive response on item 3, whereas item 1 is a small hurdle. So, if one thinks of all possible propositions about beauty, any scale is composed of a sample from the population of beauty propositions.</p>
<p>If we look beyond design research, an abundance of non-human populations can be found in other research disciplines, such as:</p>
<ul>
<li>products in consumer research</li>
<li>phonemes in psycholinguistics</li>
<li>test items in psychometrics</li>
<li>pictures of faces in face recognition research</li>
<li>patches of land in agricultural studies</li>
<li>households in socio-economic studies</li>
</ul>
<p>In all these cases it is useful (if not inevitable) to ask multi-level questions not just on the human population, but on the encounter of multiple populations. In research on a single or few designs, such as in A/B testing, designs are usually thought of (and modeled) as common fixed-effects factors. However, when the research question is more fundamental, such that it regards a whole class of designs, it is more useful to think of designs as a population and draw a sample. In the next section we will see an example, where a sample of users encounters a sample of designs and tasks.</p>
<p>In experimental design research, the research question often regards a whole class of designs and it is almost inevitableto view designs as a population. As we usually want to generalize across users, that is another sample. A basic experimental setup would be to have every user rate (or do a task) on every design, which is called a complete (experimental) design, but I prefer to think of it as a complete <em>encounter</em>.</p>
<p>Every measure is an encounter of one participant and one design. But, if a multi-item rating scale is used, measures are an encounter between three populations. Every measure combines the impact from three members from these populations. With a single measure, the impact factors are inseparable. But if we have repeated measures on all populations, we can apply a <em>cross-classified multi-level model</em> (CRMM). An intercept-only CRMM just adds intercept random effects for every population.</p>
<p>In the following case Egan, the question is a comparison of diversity across populations. Three decades ago, <span class="citation">(Egan 1988)</span> published one of the first papers on individual differences in computer systems design and made the following claim:</p>
<blockquote>
<p>‘differences among people usually account for much more variability in performance than differences in system designs’</p>
</blockquote>
<p>What is interesting about this research question is that it does not speak about effects, but about <em>variability of effects</em> and seeks to compare variability of two totally different populations. In the following we will see how this claim can be tested by measuring multiple encounters between populations</p>
<p>Egan’s claim has been cited in many papers that regarded individual differences and we were wondering how it would turn out in the third millennium, with the probably most abundant of all application domains: informational websites. For the convenience, we chose the user population of student users, with ten university websites as our design sample. Furthermore, ten representative tasks on such websites were selected, which is another population. During the experiment, all 41 participants completed 10 information search items such as:</p>
<blockquote>
<p>On website [utwente.nl] find the [program schedule Biology].</p>
</blockquote>
<!-- #### REDUCE -->
<!-- As this is a real study, there is some inconvenience ahead. Recall that the distribution of residuals is assumed to be Gaussian in linear regression models. Unfortunately, that is not how the noise of time-on-task measures and other "temporal" variables is frequently shaped. The cheap trick of *log transformation* often serves the purpose when not much is at stake. A more disciplined approach to work with time variables is given in \@ref(duration-measures).  -->
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="mlm.html#cb500-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Egan)</span></code></pre></div>
<p><em>Note</em> that ToT is log-transformed for compliance with the assumptions of Linear Models. Generally, the advice is to use a Generalized Linear Model instead <a href="glm.html#exgauss-reg">7.3.2</a>.
Egan’s claim is a two-way encounter to which we added the tasks, which makes it three-way. However, our data seemed to require a fourth random effect, which essentially is a conditional effect between tasks and websites, which we call an item. Figure <a href="mlm.html#fig:egan-1">6.13</a> shows a grid of histogram with the marginal distributions of human and non-human populations. The individual plots were created using the following code template:</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="mlm.html#cb501-1" aria-hidden="true" tabindex="-1"></a>D_egan <span class="sc">%&gt;%</span></span>
<span id="cb501-2"><a href="mlm.html#cb501-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part) <span class="sc">%&gt;%</span></span>
<span id="cb501-3"><a href="mlm.html#cb501-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">avg_logToT =</span> <span class="fu">mean</span>(logToT)) <span class="sc">%&gt;%</span></span>
<span id="cb501-4"><a href="mlm.html#cb501-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> avg_logToT)) <span class="sc">+</span></span>
<span id="cb501-5"><a href="mlm.html#cb501-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb501-6"><a href="mlm.html#cb501-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;participant-level average log-times&quot;</span>) <span class="sc">+</span></span>
<span id="cb501-7"><a href="mlm.html#cb501-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="fl">1.5</span>, <span class="fl">6.5</span>)</span></code></pre></div>
<div class="figure"><span id="fig:egan-1"></span>
<img src="Linear_mixed-effects_models_files/figure-html/egan-1-1.png" alt="Distribution of human and non-human populations in the Egan experiment (scale log(ToT))" width="90%" />
<p class="caption">
Figure 6.13: Distribution of human and non-human populations in the Egan experiment (scale log(ToT))
</p>
</div>
<p>There seems to be substantial variation between participants, tasks and items, but very little variation in designs. We build a GMM for the encounter of the four populations.</p>
<!-- #### FORMULAS -->
<!-- $$ -->
<!-- \mu_i = \beta_0 + x_{Pi}\beta_{P} + x_{Di}\beta_{D} + x_{Ti}\beta_{T} + x_{D:Ti}\beta_{D:T}\\ -->
<!-- \beta_{P} \sim \textrm{Gaus}(0, \sigma_{P}) \\ -->
<!-- \beta_{D} \sim \textrm{Gaus}(0, \sigma_{D}) \\ -->
<!-- \beta_{T} \sim \textrm{Gaus}(0, \sigma_{T}) \\ -->
<!-- \beta_{DxT} \sim \textrm{Gaus}(0, \sigma_{DxT})\\ -->
<!-- y_i \sim \textrm{Gaus}(\mu, \sigma_\epsilon) -->
<!-- $$ -->
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="mlm.html#cb502-1" aria-hidden="true" tabindex="-1"></a>M_1 <span class="ot">&lt;-</span></span>
<span id="cb502-2"><a href="mlm.html#cb502-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(logToT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span></span>
<span id="cb502-3"><a href="mlm.html#cb502-3" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">|</span> Part) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Design) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Task) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Design<span class="sc">:</span>Task),</span>
<span id="cb502-4"><a href="mlm.html#cb502-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> D_egan</span>
<span id="cb502-5"><a href="mlm.html#cb502-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb502-6"><a href="mlm.html#cb502-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb502-7"><a href="mlm.html#cb502-7" aria-hidden="true" tabindex="-1"></a>P_1 <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_1)</span></code></pre></div>
<p>A Bayesian multi-level model estimates the standard deviation alongside with coefficients, such that we can compare magnitude and certainty of variability. In addition, we include the standard error as an observation-level effect (Obs) for comparison (Figure <a href="mlm.html#fig:egan-3">6.14</a>).</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="mlm.html#cb503-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mascutils) <span class="co"># reorder-levels</span></span>
<span id="cb503-2"><a href="mlm.html#cb503-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb503-3"><a href="mlm.html#cb503-3" aria-hidden="true" tabindex="-1"></a>P_1 <span class="sc">%&gt;%</span></span>
<span id="cb503-4"><a href="mlm.html#cb503-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(type <span class="sc">==</span> <span class="st">&quot;grpef&quot;</span> <span class="sc">|</span> type <span class="sc">==</span> <span class="st">&quot;disp&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb503-5"><a href="mlm.html#cb503-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb503-6"><a href="mlm.html#cb503-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">re_factor =</span> <span class="fu">if_else</span>(type <span class="sc">==</span> <span class="st">&quot;disp&quot;</span>,</span>
<span id="cb503-7"><a href="mlm.html#cb503-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;Obs&quot;</span>, re_factor</span>
<span id="cb503-8"><a href="mlm.html#cb503-8" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb503-9"><a href="mlm.html#cb503-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">re_factor =</span> <span class="fu">reorder_levels</span>(</span>
<span id="cb503-10"><a href="mlm.html#cb503-10" aria-hidden="true" tabindex="-1"></a>      re_factor,</span>
<span id="cb503-11"><a href="mlm.html#cb503-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb503-12"><a href="mlm.html#cb503-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb503-13"><a href="mlm.html#cb503-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb503-14"><a href="mlm.html#cb503-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value)) <span class="sc">+</span></span>
<span id="cb503-15"><a href="mlm.html#cb503-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>() <span class="sc">+</span></span>
<span id="cb503-16"><a href="mlm.html#cb503-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;random effect standard deviation&quot;</span>) <span class="sc">+</span></span>
<span id="cb503-17"><a href="mlm.html#cb503-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(re_factor <span class="sc">~</span> .)</span></code></pre></div>
<div class="figure"><span id="fig:egan-3"></span>
<img src="Linear_mixed-effects_models_files/figure-html/egan-3-1.png" alt="Density plot of random effects standard deviations." width="90%" />
<p class="caption">
Figure 6.14: Density plot of random effects standard deviations.
</p>
</div>
<!-- Before we formally evaluate Egan's claim, there are a few noteworthy remarks on how to read the posteriors, when the parameter is a group-level standard deviation. First, standard deviation is on the same scale as the measured variable. Usually, this makes standard deviations  rather intuitive to interpret. This is, *unless* you have obscured your variable by log transformation, which is the major disadvantage of this procedure.  -->
<!-- Second, the posterior graph is too easily misinterpreted by confusing the posterior distribution for the group-level distribution. Instead, the amount of variation in a random factor is reflected by the location on the x-axis, while the spread is uncertainty. The population of designs seems to have the lowest variation of all, with users being close second. The observation-level variation (Obs) is nothing but the standard error, $\sigma_\epsilon$. The observation-level variation sometimes serves well as a reference point to make quantitative statements on variation.  -->
<p>The outcomes of our study are indecisive regarding Egan’s claim. Variance of participants is stronger than variance of designs, but the posterior distributions overlap a good deal. Both factors also produce much less variability in measures than does the remaining noise. Tasks seem to have the overall strongest effect, but this comes with huge uncertainty. The strongest variability is found in the sample of items (Design x Task), which is an interesting observation. How easy a task is, largely depends on the website where it is carried out. That makes sense, as all pieces of information somehow compete for space. For example, one university website could present the library on the homepage, whereas another websites hides it deep in its navigation structure.</p>
<p>A secondary observation on the posterior plot is that some effects are rather certain, such as Obs and Design:Task, whereas others are extremely uncertain, especially Task. There is a partial explanation for this: the variation is estimated from the “heads” in thehuman or non-human population. It therefore strongly depends on respective sample size. Design and Task have a meager <span class="math inline">\(N = 10\)</span>, which is why the estimate are so uncertain. With <span class="math inline">\(N = 41\)</span> the participant level estimate has more data and reaches better certainty, same for the pairs (<span class="math inline">\(N = 100\)</span>). The observations level can employ to all 410 observations, resulting in a highly certain estimate.</p>
<!-- All conditional effects are potential assaults on generalizability and so are items (`Design:Task`). Without this conditional effect, the model would assume that all ten tasks had the same relative difficulty regardless of the website. And the same goes for website. Given the countless possibilities to structure information on a website, this is a bold assumption. It were as if all ten information architects had previously agreed on how well to support any of the tasks. And, as the results show, there is substantial conditional variation, information architects do not fully agree. Regarding the interpretation, the question is: are we willing to add the *conditional* design effects under what Egan called "designs", or can only complete websites be called designs, with everything underneath being singular forces that amplify or erase each other? This depends on whether you are an optimist or realist designer. The realist thinks that design is a wicked problem science, where a good design is a bunch of reasonable compromises, but it is never the maximum. You may use large fonts to improve reading speed, but that comes at more scrolling time. You may choose to place an awesome video presentation of your university on its homepage, but you are using costly space you could use for other frequently used information. In such a view, a design is a set of carefully calibrated trade-offs and must therefore be taken as a whole.  -->
<p>Still, Egan’s claim is out in the world and requires an answer. To reduce the quantitative findings to a Yes/No variable, we use the same technique as in <a href="mpm.html#test-stat">5.5.1</a> and <a href="mlm.html#universality">6.4</a>. What is the probability, that Egan is right? We create a Boolean variable and summarize the proportion of MCMC draws, where <span class="math inline">\(\sigma_ \textrm{Part} &gt; \sigma_ \textrm{Design}\)</span> holds.</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="mlm.html#cb504-1" aria-hidden="true" tabindex="-1"></a>P_1 <span class="sc">%&gt;%</span></span>
<span id="cb504-2"><a href="mlm.html#cb504-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(type <span class="sc">==</span> <span class="st">&quot;grpef&quot;</span>, re_factor <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Part&quot;</span>, <span class="st">&quot;Design&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb504-3"><a href="mlm.html#cb504-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(chain, iter, re_factor, value) <span class="sc">%&gt;%</span></span>
<span id="cb504-4"><a href="mlm.html#cb504-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spread</span>(re_factor, value) <span class="sc">%&gt;%</span></span>
<span id="cb504-5"><a href="mlm.html#cb504-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_Egan_is_right =</span> <span class="fu">mean</span>(Part <span class="sc">&gt;</span> Design)) </span></code></pre></div>
<table>
<caption><span id="tab:egan-4">Table 6.14: </span>The probability that Egan’s claim is right derived from MCMC samples</caption>
<thead>
<tr class="header">
<th align="right">prob_Egan_is_right</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.928</td>
</tr>
</tbody>
</table>
<p>Such a chance can count as good evidence in favor of Egan’s claim, although it certainly does not match the “much more” in the original quote. However, if we take the strong and certain Item effect (Design x Task) into account, the claim could even be reversed. Apparently, the difficulty of a task depends on the design, that means, it depends on where this particular designer has placed an item in the navigation structure. These are clearly design choices and if we see it this way, evidence for Egan’s claim is practically zero (.0005, Table <a href="mlm.html#tab:egan-5">6.15</a>).</p>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="mlm.html#cb505-1" aria-hidden="true" tabindex="-1"></a>P_1 <span class="sc">%&gt;%</span></span>
<span id="cb505-2"><a href="mlm.html#cb505-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(type <span class="sc">==</span> <span class="st">&quot;grpef&quot;</span>, re_factor <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Part&quot;</span>, <span class="st">&quot;Design&quot;</span>, <span class="st">&quot;Design:Task&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb505-3"><a href="mlm.html#cb505-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(chain, iter, re_factor, value) <span class="sc">%&gt;%</span></span>
<span id="cb505-4"><a href="mlm.html#cb505-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spread</span>(re_factor, value) <span class="sc">%&gt;%</span></span>
<span id="cb505-5"><a href="mlm.html#cb505-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Egan_is_right =</span> Part <span class="sc">&gt;</span> Design <span class="sc">&amp;</span> Part <span class="sc">&gt;</span> <span class="st">`</span><span class="at">Design:Task</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb505-6"><a href="mlm.html#cb505-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_Egan_is_right =</span> <span class="fu">mean</span>(Egan_is_right)) </span></code></pre></div>
<table>
<caption><span id="tab:egan-5">Table 6.15: </span>The probability that Egan’s claim is right, including the Item effects (Design x Task)</caption>
<thead>
<tr class="header">
<th align="right">prob_Egan_is_right</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5e-04</td>
</tr>
</tbody>
</table>
<p>In this section we have seen that measures in design research happen in encounters between users, designs and several other non-human populations. Cross-classified random effects models capture these structures. When testing Egan’s claim, we saw how an exotic hypothesis such as the difference in variance, can be answered probabilistically, because with Bayesian models, we get posterior distributions for all parameters in a model, not just coefficients.</p>
<!-- ############### HERE ############## -->
</div>
<div id="nested-re" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Nested random effects</h2>
<p>In some research designs, we are dealing with populations that have a hierarchical structure, where every member is itself composed of another population of entities. A classic example is from educational research: schools are a non-human population, underneath which we find a couple of other populations, classes and students. Like cross-classified models, nested models consist of multiple levels. The difference is that if one knows the lowest (or: a lower) level of an observation, the next higher level is unambiguous, like:</p>
<ul>
<li>every class is in exactly one school</li>
<li>every student is in exactly one school (or class)</li>
</ul>
<p><em>Nested random effects</em> (NRE) represent nested sampling schemes. As we have seen above, cross-classified models play an important role in design research, due to the user/task/design encounter. NREs are more common in research disciplines where organisation structures or geography plays a role, such as education science (think of the international school comparison studies PISA and TIMMS), organisational psychology or political science.</p>
<p>One examples of a nested sampling structure in design research is the CUE8 study, which is the eighth instance of Comparative Usability Evaluation (CUE) studies by Rolf Molich <span class="citation">(Molich et al. 2010)</span>. Different to what the name might suggest, not designs are under investigation in CUE, but usability professionals. The over-arching question in the CUE series is the performance and reliability of usability professionals when evaluating designs. Earlier studies sometimes came to devastating results regarding consistency across professional groups when it comes to identifying and reporting usability problems. The CUE8 study lowered the bar, by asking if professionals can at least measure time in a comparable way.</p>
<p>The CUE8 study measured time-on-task in usability tests, which had been conducted by 14 different teams. The original research question was: How reliable are time-on-task measures across teams? All teams used the same website (a car rental company) and the same set of tasks. All teams did moderated or remote testing (or both) and recruited their own sample of participants (Table <a href="mlm.html#tab:cue8-1">6.16</a>)).</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="mlm.html#cb506-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(CUE8)</span>
<span id="cb506-2"><a href="mlm.html#cb506-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb506-3"><a href="mlm.html#cb506-3" aria-hidden="true" tabindex="-1"></a>D_cue8</span></code></pre></div>
<table>
<caption><span id="tab:cue8-1">Table 6.16: </span>Data set with 8 variables, showing 8 of 2620 observations.</caption>
<thead>
<tr class="header">
<th align="right">Obs</th>
<th align="left">Team</th>
<th align="left">Part</th>
<th align="left">Condition</th>
<th align="right">SUS</th>
<th align="left">Task</th>
<th align="right">ToT</th>
<th align="right">logToT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">521</td>
<td align="left">G3</td>
<td align="left">105</td>
<td align="left">moderated</td>
<td align="right"></td>
<td align="left">1</td>
<td align="right">347</td>
<td align="right">5.85</td>
</tr>
<tr class="even">
<td align="right">818</td>
<td align="left">H3</td>
<td align="left">164</td>
<td align="left">remote</td>
<td align="right">95</td>
<td align="left">3</td>
<td align="right">121</td>
<td align="right">4.80</td>
</tr>
<tr class="odd">
<td align="right">882</td>
<td align="left">J3</td>
<td align="left">177</td>
<td align="left">remote</td>
<td align="right"></td>
<td align="left">2</td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="right">886</td>
<td align="left">J3</td>
<td align="left">178</td>
<td align="left">remote</td>
<td align="right"></td>
<td align="left">1</td>
<td align="right">196</td>
<td align="right">5.28</td>
</tr>
<tr class="odd">
<td align="right">1177</td>
<td align="left">L3</td>
<td align="left">236</td>
<td align="left">remote</td>
<td align="right">80</td>
<td align="left">2</td>
<td align="right">123</td>
<td align="right">4.81</td>
</tr>
<tr class="even">
<td align="right">1230</td>
<td align="left">L3</td>
<td align="left">246</td>
<td align="left">remote</td>
<td align="right">98</td>
<td align="left">5</td>
<td align="right">99</td>
<td align="right">4.59</td>
</tr>
<tr class="odd">
<td align="right">1879</td>
<td align="left">L3</td>
<td align="left">376</td>
<td align="left">remote</td>
<td align="right">98</td>
<td align="left">4</td>
<td align="right">105</td>
<td align="right">4.65</td>
</tr>
<tr class="even">
<td align="right">2605</td>
<td align="left">O3</td>
<td align="left">521</td>
<td align="left">moderated</td>
<td align="right"></td>
<td align="left">5</td>
<td align="right">44</td>
<td align="right">3.78</td>
</tr>
</tbody>
</table>
<p>An analysis can performed on three levels: the population level would tell us the average performance on this website. That could be interesting for the company running it. Below that are the teams and their variation is what the original research question is about. Participants make the third level for a nested multi-level model. It is nested, because every participant is assigned to exactly one team. If that weren’t the case, say there is one sample of participants shared by the teams, that would be cross-classification.</p>
<p>As the original research question is on the consistency across teams, we can readily take the random effect variance as a measure for the opposite: when variance is high, consistency is low. But, how low is low? It is difficult to come up with an absolute standard for inter-team reliability. Because we also have the participant-level, we can resort to a relative standard: how does the variation between teams compare to variation between individual participants?</p>
<p>Under this perspective, we examine the data. This time, we have real time-on-task data and as so often, it is highly skewed. Again, we use the trick of logarithmic transformation to obtain a more symmetric distribution of residuals. The downside is that the outcome variable may not be zero. For time-on-task data this is not an issue. Before proceeding to the model, we explore the original variable <code>ToT</code> on the two levels (Participant and Team). In the following code the mean ToT is computed for the two levels of analysis, participants and teams and shown in ascending order (Figure <a href="mlm.html#fig:cue8-2">6.15</a>).</p>
<div class="figure"><span id="fig:cue8-2"></span>
<img src="Linear_mixed-effects_models_files/figure-html/cue8-2-1.png" alt="Distribution of mean scores on three levels" width="90%" />
<p class="caption">
Figure 6.15: Distribution of mean scores on three levels
</p>
</div>
<p>It seems there is ample variation in ToT for participants, with mean ToT ranging from below 100 to almost 500 seconds. There also is considerable variation on team level, but the overall range seems to be a little smaller. Note, however, that the participant level contains all the variation that is due to teams. A model with nested random effects can separate the sources of variation. When two (or more) levels are nested, a special syntax applies for specifying nested random effects. <code>1|Team/Part</code>.</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="mlm.html#cb507-1" aria-hidden="true" tabindex="-1"></a>M_1 <span class="ot">&lt;-</span></span>
<span id="cb507-2"><a href="mlm.html#cb507-2" aria-hidden="true" tabindex="-1"></a>  D_cue8 <span class="sc">%&gt;%</span></span>
<span id="cb507-3"><a href="mlm.html#cb507-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(logToT <span class="sc">~</span> Condition <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Team <span class="sc">/</span> Part),</span>
<span id="cb507-4"><a href="mlm.html#cb507-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> .</span>
<span id="cb507-5"><a href="mlm.html#cb507-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb507-6"><a href="mlm.html#cb507-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb507-7"><a href="mlm.html#cb507-7" aria-hidden="true" tabindex="-1"></a>P_1 <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_1)</span></code></pre></div>
<p>Note that the model contains another feature of the CUE8 study the effect of the testing condition, moderated or remote. Why does this not have a participant-level effect. As participants are either moderated or remote, we simply don’t get any data, on how the same participant behaved in the other condition.</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb508-1"><a href="mlm.html#cb508-1" aria-hidden="true" tabindex="-1"></a>P_1</span></code></pre></div>
<table>
<caption><span id="tab:cue8-4">Table 6.17: </span>MCMC posterior with 4000 samples of 542 parameters in 1 model(s)</caption>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="left">parameter</th>
<th align="left">type</th>
<th align="left">fixef</th>
<th align="left">re_factor</th>
<th align="right">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">M_1</td>
<td align="left"></td>
<td align="left">ranef</td>
<td align="left">Intercept</td>
<td align="left">Team</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="left">M_1</td>
<td align="left"></td>
<td align="left">ranef</td>
<td align="left">Intercept</td>
<td align="left">Team:Part</td>
<td align="right">523</td>
</tr>
<tr class="odd">
<td align="left">M_1</td>
<td align="left">b_Conditionmoderated</td>
<td align="left">fixef</td>
<td align="left">Conditionmoderated</td>
<td align="left"></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">M_1</td>
<td align="left">b_Intercept</td>
<td align="left">fixef</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">M_1</td>
<td align="left">sigma</td>
<td align="left">disp</td>
<td align="left"></td>
<td align="left"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">M_1</td>
<td align="left">sd_Team:Part__Intercept</td>
<td align="left">grpef</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">M_1</td>
<td align="left">sd_Team__Intercept</td>
<td align="left">grpef</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>The posterior object reveals two random factors, one for teams and one for participants. The interpretation is in no way different than cross-classified random effects. In both cases, the absolute group mean for a certain participant is obtained by adding up all two coefficients.</p>
<p>The syntax really is just a safe way to deal with nested samples, where participant identifiers could be re-used. If participant identifiers were unique (Table <a href="mlm.html#tab:cue8-5">6.18</a>), a cross-classified model with the formula <code>logToT ~ Condition + (1|Part) + (1|Team)</code> would produce the exact same results.</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="mlm.html#cb509-1" aria-hidden="true" tabindex="-1"></a>D_cue8_x <span class="ot">&lt;-</span></span>
<span id="cb509-2"><a href="mlm.html#cb509-2" aria-hidden="true" tabindex="-1"></a>  D_cue8 <span class="sc">%&gt;%</span></span>
<span id="cb509-3"><a href="mlm.html#cb509-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unite</span>(Part, Team<span class="sc">:</span>Part, <span class="at">remove =</span> F) <span class="sc">%&gt;%</span></span>
<span id="cb509-4"><a href="mlm.html#cb509-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tbl_obs</span>()</span>
<span id="cb509-5"><a href="mlm.html#cb509-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb509-6"><a href="mlm.html#cb509-6" aria-hidden="true" tabindex="-1"></a>D_cue8_x</span></code></pre></div>
<table>
<caption><span id="tab:cue8-5">Table 6.18: </span>Data set with 8 variables, showing 8 of 2620 observations.</caption>
<thead>
<tr class="header">
<th align="right">Obs</th>
<th align="left">Part</th>
<th align="left">Team</th>
<th align="left">Condition</th>
<th align="right">SUS</th>
<th align="left">Task</th>
<th align="right">ToT</th>
<th align="right">logToT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">399</td>
<td align="left">F3_80</td>
<td align="left">F3</td>
<td align="left">remote</td>
<td align="right"></td>
<td align="left">4</td>
<td align="right">225</td>
<td align="right">5.42</td>
</tr>
<tr class="even">
<td align="right">408</td>
<td align="left">F3_82</td>
<td align="left">F3</td>
<td align="left">remote</td>
<td align="right"></td>
<td align="left">3</td>
<td align="right">70</td>
<td align="right">4.25</td>
</tr>
<tr class="odd">
<td align="right">522</td>
<td align="left">G3_105</td>
<td align="left">G3</td>
<td align="left">moderated</td>
<td align="right"></td>
<td align="left">2</td>
<td align="right">153</td>
<td align="right">5.03</td>
</tr>
<tr class="even">
<td align="right">1538</td>
<td align="left">L3_308</td>
<td align="left">L3</td>
<td align="left">remote</td>
<td align="right">58</td>
<td align="left">3</td>
<td align="right">69</td>
<td align="right">4.23</td>
</tr>
<tr class="odd">
<td align="right">1544</td>
<td align="left">L3_309</td>
<td align="left">L3</td>
<td align="left">remote</td>
<td align="right">70</td>
<td align="left">4</td>
<td align="right">145</td>
<td align="right">4.98</td>
</tr>
<tr class="even">
<td align="right">1986</td>
<td align="left">L3_398</td>
<td align="left">L3</td>
<td align="left">remote</td>
<td align="right">85</td>
<td align="left">1</td>
<td align="right">40</td>
<td align="right">3.69</td>
</tr>
<tr class="odd">
<td align="right">2271</td>
<td align="left">L3_455</td>
<td align="left">L3</td>
<td align="left">remote</td>
<td align="right">60</td>
<td align="left">1</td>
<td align="right">111</td>
<td align="right">4.71</td>
</tr>
<tr class="even">
<td align="right">2308</td>
<td align="left">M3_462</td>
<td align="left">M3</td>
<td align="left">remote</td>
<td align="right">5</td>
<td align="left">3</td>
<td align="right">139</td>
<td align="right">4.93</td>
</tr>
</tbody>
</table>
<p>Let’s take a closer look at the results regarding consistency of ToT measures across teams (Table <a href="mlm.html#tab:cue8-6">6.19</a>). We would always expect participants to show variation, but if team averages show strong variation, then we can suspect that there are biases. It turns out that the variation by team is by a factor of 1.5 larger than individual differences. And it is on par with the measurement error (sigma).</p>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb510-1"><a href="mlm.html#cb510-1" aria-hidden="true" tabindex="-1"></a>P_1 <span class="sc">%&gt;%</span></span>
<span id="cb510-2"><a href="mlm.html#cb510-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(type <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;fixef&quot;</span>, <span class="st">&quot;grpef&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb510-3"><a href="mlm.html#cb510-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu</span>()</span></code></pre></div>
<table>
<caption><span id="tab:cue8-6">Table 6.19: </span>Parameter estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="left">fixef</th>
<th align="left">re_factor</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b_Intercept</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="right">4.629</td>
<td align="right">4.062</td>
<td align="right">5.19</td>
</tr>
<tr class="even">
<td align="left">b_Conditionmoderated</td>
<td align="left">Conditionmoderated</td>
<td align="left"></td>
<td align="right">0.326</td>
<td align="right">-0.393</td>
<td align="right">1.12</td>
</tr>
<tr class="odd">
<td align="left">sd_Team__Intercept</td>
<td align="left">Intercept</td>
<td align="left">Team</td>
<td align="right">0.619</td>
<td align="right">0.417</td>
<td align="right">1.01</td>
</tr>
<tr class="even">
<td align="left">sd_Team:Part__Intercept</td>
<td align="left">Intercept</td>
<td align="left">Team:Part</td>
<td align="right">0.428</td>
<td align="right">0.390</td>
<td align="right">0.47</td>
</tr>
</tbody>
</table>
<p>It is not surprising to see the test users vary greatly in performance. What is concerning is that the discordance between professional teams. Note that this is the net variance after controlling for the condition, remote or moderated. Surprisingly, evidence for just that difference rather low and highly uncertain (<span class="math inline">\(0.33 [-0.39, 1.12]_{CI95}\)</span>).</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<!-- Actually, it is not even necessary to specify that participants are nested within teams. If we make sure that participant identifiers are unique across the whole study (not just within a team unit), we can also just use `1|Part + 1|Team`. If the participant identifier is only unique within a team, it is either to be recoded, e.g. `mutate(Part = str_c(Team, Part))`. -->
<p>In this section we introduced a new perspective on multi-level models. Here, the question was to quantify and compare samples (rather than conditions) as sources of variation. With multi-level models, we can separate sources of variation. This builds on how random effects are constructed, as factor levels drawn from a Gaussian distribution. In the following section, we will delve deeper into the matter of random effects.</p>
<!-- ################ HERE ######## -->
</div>
<div id="pool-shrink" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> What are random effects? On pooling and shrinkage</h2>
<p>At least half a dozen of definitions exist for the term random effect. This is so confusing that some authors refrain to use the term altogether.
In addition, the very terms <em>random effect</em> and <em>random factor</em> are highly misleading, as there is nothing more or less random in a random factors as compared to fixed factors. Here, the definition of a random effects is conceptually based on the idea of a population, and implemented as a factor, where levels are assumed to follow a Gaussian distribution.</p>
<p>A Gaussian distribution extends in both directions infinitely, but the extreme tails are becoming very thin. The low assigned probability of extreme events acts on the estimate, by correcting extreme estimates towards the mean, which is called shrinkage.</p>
<!-- The opposite is the case: as we have seen above, a random effects model pulls a variance component from the random term and explains it by assigning coefficients to entities (teams or users). The best advice is  to not contemplate over what makes a factor random. It is just a name and because random factors are so amazingly useful, they should be called fonzy <!-- #87 factors, instead. -->
<p>When a data set contains a factor that we may wish to add to the model, the question is: fixed effect or random effect? In <a href="mlm.html#non-human-populations">6.5</a>, I have introduced the heuristic of populations. If one can conceive tasks, designs, or whatever set of items as a population, there is clumping to some degree, but also variation. The more clumping there is, the better is the guess for unobserved members by observing some members.</p>
<p>Obviously, we would never speak of a population, when the objects of interest are from different classes. Entities gathering on super market parking lots, like persons, cars, baskets and and dropped brochures, we would never see as a population. People, we would generally see as a population, as long as what we want to observe is somewhat comparable between members. When the question is, how fast persons can do a 2000 meter run at the Olympic games, we would certainly want one population per discipline (swimming, running, etc). Why is that so? It is because we expect members of a population to have some similarity, with the consequence that, if you already have observed some members of the population, this tells you something about any unobserved members.</p>
<p>Reconsider the Bayesian principle of prior knowledge by an experiment of thought: Consider, a UX expert with experience in e-commerce is asked to estimate how long it takes users to do the checkout, but without showing the expert the actual system. The expert will probably hesitate briefly, and then come up with an estimate of, let’s say, 45 seconds. Without any data, the expert made some reasonable assumptions, e.g. that a disciplined design process has been followed, and then relies on experience. The experts personal experience has formed prior to the study by observing many other cases. Now, we confront the expert with an even more bizzare situation: guess the time-on-task for an unknown task with an unseen system of unknown type! The expert will probably refuse to give an answer, arguing that some systems have tasks in the second range (e.g. starting a car), whereas other processes easily run for hours or days (e.g. writing a report). This is a good point and the expert is provided, not with knoeledge of the system, but with average ToT of four other tasks within the same system:</p>
<p><span class="math inline">\(ToT_{1-4} = {23, 45, 66, 54}\)</span></p>
<p>Now, the expert is confident that ToT be around 50 seconds and that is probably a good guess. What has happened is that prior belief about the unkown task parameter has been formed not externally, but <em>by data</em> as it arrived. The likely value of one unit has been learned from the other units and this appears pretty reasonable. The same principle applies when visually identifying outliers in a boxplot or scatterplot. First, the mind of the observer forms a gestalt that covers the salient features of data, for example: almost all points are located in the range 100 - 500. Once this pattern has formed, deviant points stand out.</p>
<p>However, the salience of the gestalt may vary. Consider a situation where ToT has been measured by the same procedure, but using five different stop watches. Stop watches are so incredibly accurate that if you know one measure, you basically know them all. What many researchers do with repeated measures data, is take the average. This is the one extreme called <em>total pooling</em>. In the stopwatch case the average of the five measures would be so highly representative, that total pooling is a reasonable thing to do.</p>
<p>In other cases, the levels of a factor are more or less independent, for example tasks in a complex system, where procedure duration ranges from seconds to hours. Guessing the duration of one task from a set of others is highly susceptible and the average duration across tasks is not representative at all. The best choice then is to see tasks as factor levels, that are independent. This extreme of <em>no pooling</em> is exactly represented by fixed effect factors as they have been introduced in <a href="lm.html#lm">4</a>.</p>
<p>Random effects sit right between these two extremes of no and total pooling and implement <em>partial pooling</em>: the more the group mean is representative for the units of the group, the more it is taken into account. By this we can also see, why a multi-level model must estimate alle levels simultaneously. The best thing about partial pooling is that, unlike real priors, there is not even the need to determine the amount of pooling in advance. The variation of entities has been observed. The stronger the enities vary, the less can be learned from the group level. The variation is precisely the group-level standard deviation of the random effect.</p>
<!-- Because the population-level learns from the participant-level, and vice vers, , we can think of random factors as factors where there is a certain amount of cross-talk between levels. The random effect estimate then draws on two sources of evidence: all data from the overarching population and data that belongs just to this one entity. As that is the case, the exploratory analysis of individual performance in SOV does not resemble a true random effect, as group means were calculated independently.  -->
<p>How are random effects implemented to draw on both sources? Obviously, the procedure must be more refined than just adding participant-level dummy variables into the structural part of the model. In the Bayesian framework a remarkably simple trick suffices, and it is even a familiar one. By the concept of prior distributions, we already know a way to restrict the range of an effect based on prior knowledge. For example, intelligence test results have the prior distribution <span class="math inline">\(IQ ~ \textrm{Gaus}(100, 15)\)</span>, just because they have been empirically calibrated this way. In most other cases, we do have rough ideas about the expected magnitude and range in the population, say: healthy human adults will finish a 2000m run in the range of 5-12 minutes.</p>
<p>As prior knowledge is external to the data, it often lacks systematic evidence, with the exception of a meta analyses. This is why we tend to use weak informative priors. Like priors, random effects take into account knowledge external to the entity under question. But, they draw this knowledge from the data, which is more convincing after all. The basic trick to establish the cross-talk between random factor levels, is to <em>simultaneously estimate factor levels and random factor variation</em>. This has several consequences:</p>
<p>All random effects get a more or less subtle trend towards the population mean. As a side effect, the random factor variance is usually smaller than variance between fixed factors, or naive group means. This effect is called <em>shrinkage</em>. When the random factor variation is small, extreme factor levels are pulled stronger towards the population mean, resulting in stronger shrinkage. Or vice versa: When random variation is large, the factor levels stand more on their own.</p>
<p>The random factor variation is an estimate and as such it is certain only to a degree. As we have seen in <a href="mlm.html#non-human-populations">6.5</a>, the more levels a random factor comprises, the more precise is the estimate of random factor variation. The strongest shrinkage occurs with few observations per factor levels and highly certain random factor variation.</p>
<p>Previously, I have stressed how important repeated measures design is, as the number of observations per entity plays a role, too. The more observations there are, the less is the group mean overruled by the population mean. Less shrinkage occurs. This is why multi-level models gracefully deal with imbalanced designs. Groups with more observations are just gradually more self-determined. Taking this to the opposite extreme: when a factor level contains no data at all, it will just be replaced by the population mean. This principle offers a very elegant solution to the problem of missing data. If you know nothing about a person, the best guess is the population mean.</p>
<p>Under the perspective of populations as a more or less similar set of entities, these principles seem to make sense. Within this framework, we can even define what fixed effects are:</p>
<blockquote>
<p>a fixed effect is a factor where levels are regarded so unsimilar, that the factor-level variance can be practically considered infinite.</p>
</blockquote>
<!-- We routinely approximate such a situation when using non-informative prior distributions, like $\beta_0 ~ \textrm{Gaus}(0, 10000)$. In the extreme case, a uniform distribution with an infinite upper boundary truly has an infinite variance: $\beta_0 ~ U(0, \infty)$. A finite population mean doesn't even exist with such a distribution. -->
<!-- So, when a design researcher has observed that with design A, ToT is approximately distributed as $ToT_A ~ \textrm{Gaus}(120, 40)$, is it realistic to assume that design B has ToT in the range of several hours? Would a cognitive psychologist see it equally likely that the difference in reaction time on two primitive tasks is 200ms or 2h? Probably not. Still, using fixed effects for factors with very few levels is a justifyable approximation. First of all, priors can be used at any time to factor in reasonable assumptions about the range. Second, with very few estimates, the random factor variation cannot be estimated with any useful certainty. Very small shrinkage would occur and the results would practically not differ. -->
<p>The CUE8 study makes a case for seeing shrinkage in action: Teams of researchers were asked to conduct a performance evaluation on a website. Tasks and website were the same, but the teams followed their own routines. Some teams tested a few handful of participants, whereas others tested dozens remotely. Teams, as another non-human population (sic!) differ vastly in the number of observations they collected. We can expect differences in shrinkage.</p>
<p>To see the effect, we compare the team-level group means as fixed factor versus random factor. All teams have enough participants tested to estimate their mean with some certainty. At the same time, the group sizes vary so dramatically that there should be clear differences in adjustment towards the mean. However, in absolute terms, the sample sizes are very large. There is enough data to estimate team-level scores, and the shrinkage effect is barely visible. For the purpose of demonstration, we use a data set that is reduced to one tenth of the original. We estimate two models, a fixed effects model and a random effects model, from which we collect the (absolute) random effect scores.</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="mlm.html#cb512-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(CUE8)</span></code></pre></div>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="mlm.html#cb513-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb513-2"><a href="mlm.html#cb513-2" aria-hidden="true" tabindex="-1"></a>D_cue8_1 <span class="ot">&lt;-</span></span>
<span id="cb513-3"><a href="mlm.html#cb513-3" aria-hidden="true" tabindex="-1"></a>  D_cue8 <span class="sc">%&gt;%</span></span>
<span id="cb513-4"><a href="mlm.html#cb513-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_frac</span>(.<span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="mlm.html#cb514-1" aria-hidden="true" tabindex="-1"></a>M_2 <span class="ot">&lt;-</span></span>
<span id="cb514-2"><a href="mlm.html#cb514-2" aria-hidden="true" tabindex="-1"></a>  D_cue8_1 <span class="sc">%&gt;%</span></span>
<span id="cb514-3"><a href="mlm.html#cb514-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(logToT <span class="sc">~</span> Team <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> .)</span>
<span id="cb514-4"><a href="mlm.html#cb514-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-5"><a href="mlm.html#cb514-5" aria-hidden="true" tabindex="-1"></a>M_3 <span class="ot">&lt;-</span></span>
<span id="cb514-6"><a href="mlm.html#cb514-6" aria-hidden="true" tabindex="-1"></a>  D_cue8_1 <span class="sc">%&gt;%</span></span>
<span id="cb514-7"><a href="mlm.html#cb514-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(logToT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Team), <span class="at">data =</span> .)</span></code></pre></div>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="mlm.html#cb515-1" aria-hidden="true" tabindex="-1"></a>P_fixef <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_2, <span class="at">type =</span> <span class="st">&quot;fixef&quot;</span>)</span>
<span id="cb515-2"><a href="mlm.html#cb515-2" aria-hidden="true" tabindex="-1"></a>P_ranef <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_3) <span class="sc">%&gt;%</span></span>
<span id="cb515-3"><a href="mlm.html#cb515-3" aria-hidden="true" tabindex="-1"></a>  bayr<span class="sc">::</span><span class="fu">re_scores</span>()</span>
<span id="cb515-4"><a href="mlm.html#cb515-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb515-5"><a href="mlm.html#cb515-5" aria-hidden="true" tabindex="-1"></a>T_shrinkage <span class="ot">&lt;-</span></span>
<span id="cb515-6"><a href="mlm.html#cb515-6" aria-hidden="true" tabindex="-1"></a>  D_cue8_1 <span class="sc">%&gt;%</span></span>
<span id="cb515-7"><a href="mlm.html#cb515-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Team) <span class="sc">%&gt;%</span></span>
<span id="cb515-8"><a href="mlm.html#cb515-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">N =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb515-9"><a href="mlm.html#cb515-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb515-10"><a href="mlm.html#cb515-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">fixef =</span> <span class="fu">fixef</span>(P_fixef)<span class="sc">$</span>center,</span>
<span id="cb515-11"><a href="mlm.html#cb515-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">ranef =</span> <span class="fu">ranef</span>(P_ranef)<span class="sc">$</span>center,</span>
<span id="cb515-12"><a href="mlm.html#cb515-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">shrinkage =</span> fixef <span class="sc">-</span> ranef</span>
<span id="cb515-13"><a href="mlm.html#cb515-13" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="mlm.html#cb516-1" aria-hidden="true" tabindex="-1"></a>T_shrinkage <span class="sc">%&gt;%</span></span>
<span id="cb516-2"><a href="mlm.html#cb516-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Team, <span class="at">size =</span> N)) <span class="sc">+</span></span>
<span id="cb516-3"><a href="mlm.html#cb516-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> fixef, <span class="at">col =</span> <span class="st">&quot;fixef&quot;</span>), <span class="at">alpha =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb516-4"><a href="mlm.html#cb516-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> ranef, <span class="at">col =</span> <span class="st">&quot;ranef&quot;</span>), <span class="at">alpha =</span> .<span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb516-5"><a href="mlm.html#cb516-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept =</span> <span class="fu">mean</span>(ranef))) <span class="sc">+</span></span>
<span id="cb516-6"><a href="mlm.html#cb516-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">&quot;Effect type&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:cue8-13"></span>
<img src="Linear_mixed-effects_models_files/figure-html/cue8-13-1.png" alt="Shrinkage shown as disparity of fixed effects and random effects" width="90%" />
<p class="caption">
Figure 6.16: Shrinkage shown as disparity of fixed effects and random effects
</p>
</div>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<p>Figure <a href="mlm.html#fig:cue8-13">6.16</a> shows how random effects are adjusted towards the grand mean. Groups that are distant (e.g. H, N and O) are more strongly pulled towards the mean. Also, when there is little data in a group, shrinkage is more pronounced (e.g. D, E and G).</p>
<p>In the case of full CUE8 data set, these correction are overall negligible, which is due to the fact that all teams gathered ample data. However, in all situations where there is little or unevenly distributed data, it makes sense to draw more information from the population mean and making inference from random effects is more accurate.</p>
<!-- Recall the SOV simulation above, where the set of tasks every user did was beyond control of the researcher. In situations with quite heterogeneous amount of missing data per participant, shrinkage is more pronounced and more information is drawn from the population mean. #88 -->
<!-- At the same time, shrinkage adjusts the estimates for variation, with $sd_{RE} = `sd_ranef` < sd_{FE} = `sd_fixef`$. The random effects estimate is an unbiased estimate for the population variance, whereas fixed effects variation would be overestimating. -->
<p>In conclusion, random effects are factors with the additional assumption of Gaussian distribution. When a multi-level model is estimated, the population level effect, the random effects levels and the variance of their distributions are estimated simultaneously. This creates two particular advantages of multi-level models with random effects:</p>
<ol style="list-style-type: decimal">
<li>In unbalanced research designs (with unequal number of observations per subject) small groups are corrected towards the population mean.</li>
<li>Strong outliers are corrected towards the population mean.</li>
</ol>
<p>Classical techniques for repeated measures often require additional tweaks to work well with unbalanced designs and outliers. Multi-level models with random effects handle those situations gracefully.</p>
</div>
<div id="psychometrics" class="section level2" number="6.8">
<h2><span class="header-section-number">6.8</span> Psychometrics and design-o-metric models</h2>
<p>Random effects apply to all factors, where the levels can be thought of as members of a population (<a href="mlm.html#non-human-populations">6.5</a>). Looking just at the variance inside the population is very common in experimental research, but we have already encountered situations, where analysis is based on individual random coefficients, for example when testing universality of an effect (<a href="mlm.html#universality">6.4</a>). Random coefficients can further be used to compare entities and rank them. If the entities are participants, this is called doing <em>psychometrics</em> and the individual scores represent a person’s trait, like computer enthusiasm, or ability, like in a math test.</p>
<!-- Up to to this point, we have characterized random factors mainly by their variance. However, a random effect is just like a factor, where the levels are typically entities in a sample. In a multi-level model, these levels are represented as coefficients. Every entity gets their own estimate which represents the level of functioning of the entity. These values can either be compared against an external benchmark, or they are compared to each other. When human individuals are being compared this is called *psychometrics*.  -->
<p>Traditionally, psychometrics deals with the valid and reliable measurement of personal characteristics, such as individual levels of performance, motivation, socio-cognitive attitude and the like. Advanced statistical models have been devised, such as factor analysis or item response models. The least to expect of a psychometric scale is that it can <em>order</em> persons by trait or ability.</p>
<p>In design research, multi-item validated scales are routinely used for one of two purposes:</p>
<ol style="list-style-type: decimal">
<li>A design-related research questions involve <em>traits or abilities of users</em>. For example: Do social network users with high Openness have more connections? A six-item test for Openness is used on every individual in the sample and the scores are compared the number of connections. In the following I will introduce how multi-level models can be used for basic <em>psychometric situations</em>, which is simply an <em>encounter of persons and items</em> and a cross-classified multi-level model applies.</li>
<li>In design research we frequently compare <em>quality of designs</em>, by using multi-item questionnaires. One example would be the comparison of user experience among a set of e-commerce homepages using scales such as the AttrakDiff (the hedonic dimension). Or, we want to rank a set of robot faces in how much they provoke eeriness.</li>
</ol>
<p>When the aim is to rank designs by user responses (on some multi item scale), the study is an <em>encounter of users, items and designs</em>, resulting in <em>yet another multi-level model</em>. Such a model I call a <em>design-o-metric model</em> and will introduce you to how it works in <a href="mlm.html#designometrix">6.8.4</a>.</p>
<p>We begin with the first case, standard psychometrics to assess user characteristics. For example, one could ask whether having a high visual-spatial ability helps in certain tasks, for example when a surgeon explores body cavities with an endoscope or an air traffic controller monitoring scattered displays. Visual-spatial ability could be a useful instrument to select good candidates. Let’s assume for a moment there existed enough evidence to use such a test, how could this ability be measured?</p>
<!-- In *mental rotation tasks*, participants are shown a visual reference figure, like a hand, and a rotated target figure. They are asked to decide whether the two figures are the same, except for rotation. It has been shown that r4eaction time is proportional  -->
<p>Let’s assume a simple experiment, such as mental rotation tasks, where reaction time is related to spatial processing speed. Reaction times are notoriously noisy and therefore a similar task is repeated ten times. Twenty participants solve such a sequence and reaction times are collected.</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="mlm.html#cb518-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1317</span>)</span>
<span id="cb518-2"><a href="mlm.html#cb518-2" aria-hidden="true" tabindex="-1"></a>n_Part <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb518-3"><a href="mlm.html#cb518-3" aria-hidden="true" tabindex="-1"></a>n_Trial <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb518-4"><a href="mlm.html#cb518-4" aria-hidden="true" tabindex="-1"></a>n_Obs <span class="ot">&lt;-</span> n_Part <span class="sc">*</span> n_Trial</span>
<span id="cb518-5"><a href="mlm.html#cb518-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb518-6"><a href="mlm.html#cb518-6" aria-hidden="true" tabindex="-1"></a>D_Part <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb518-7"><a href="mlm.html#cb518-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">Part =</span> <span class="dv">1</span><span class="sc">:</span>n_Part,</span>
<span id="cb518-8"><a href="mlm.html#cb518-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">true_score =</span> <span class="fu">rnorm</span>(n_Part, <span class="dv">900</span>, <span class="dv">80</span>)</span>
<span id="cb518-9"><a href="mlm.html#cb518-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb518-10"><a href="mlm.html#cb518-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb518-11"><a href="mlm.html#cb518-11" aria-hidden="true" tabindex="-1"></a>D_Trial <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Trial =</span> <span class="dv">1</span><span class="sc">:</span>n_Trial)</span>
<span id="cb518-12"><a href="mlm.html#cb518-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb518-13"><a href="mlm.html#cb518-13" aria-hidden="true" tabindex="-1"></a>D_CTT <span class="ot">&lt;-</span></span>
<span id="cb518-14"><a href="mlm.html#cb518-14" aria-hidden="true" tabindex="-1"></a>  mascutils<span class="sc">::</span><span class="fu">expand_grid</span>(</span>
<span id="cb518-15"><a href="mlm.html#cb518-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">Part =</span> D_Part<span class="sc">$</span>Part,</span>
<span id="cb518-16"><a href="mlm.html#cb518-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">Trial =</span> D_Trial<span class="sc">$</span>Trial</span>
<span id="cb518-17"><a href="mlm.html#cb518-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb518-18"><a href="mlm.html#cb518-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(D_Part) <span class="sc">%&gt;%</span></span>
<span id="cb518-19"><a href="mlm.html#cb518-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">RT =</span> <span class="fu">rnorm</span>(n_Obs,</span>
<span id="cb518-20"><a href="mlm.html#cb518-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> true_score,</span>
<span id="cb518-21"><a href="mlm.html#cb518-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> <span class="dv">100</span></span>
<span id="cb518-22"><a href="mlm.html#cb518-22" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span></span>
<span id="cb518-23"><a href="mlm.html#cb518-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tbl_obs</span>()</span>
<span id="cb518-24"><a href="mlm.html#cb518-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb518-25"><a href="mlm.html#cb518-25" aria-hidden="true" tabindex="-1"></a>D_CTT</span></code></pre></div>
<table>
<caption><span id="tab:ctt-1">Table 6.20: </span>Data set with 5 variables, showing 8 of 200 observations.</caption>
<thead>
<tr class="header">
<th align="right">Obs</th>
<th align="right">Part</th>
<th align="right">Trial</th>
<th align="right">true_score</th>
<th align="right">RT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">899</td>
<td align="right">952</td>
</tr>
<tr class="even">
<td align="right">182</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">984</td>
<td align="right">853</td>
</tr>
<tr class="odd">
<td align="right">93</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">985</td>
<td align="right">1040</td>
</tr>
<tr class="even">
<td align="right">25</td>
<td align="right">5</td>
<td align="right">3</td>
<td align="right">1021</td>
<td align="right">1003</td>
</tr>
<tr class="odd">
<td align="right">46</td>
<td align="right">6</td>
<td align="right">5</td>
<td align="right">809</td>
<td align="right">789</td>
</tr>
<tr class="even">
<td align="right">197</td>
<td align="right">7</td>
<td align="right">20</td>
<td align="right">797</td>
<td align="right">612</td>
</tr>
<tr class="odd">
<td align="right">29</td>
<td align="right">9</td>
<td align="right">3</td>
<td align="right">874</td>
<td align="right">911</td>
</tr>
<tr class="even">
<td align="right">109</td>
<td align="right">9</td>
<td align="right">11</td>
<td align="right">874</td>
<td align="right">925</td>
</tr>
</tbody>
</table>
<p>With that many measures at our hand, how can we arrive at a single score to compare participants. The approach known as <em>Classical Test Theory (CTT)</em> solves this by simply taking the average score as a measure for a person’s processing speed (Table <a href="mlm.html#tab:ctt-1a">6.21</a>).</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="mlm.html#cb519-1" aria-hidden="true" tabindex="-1"></a>D_CTT <span class="sc">%&gt;%</span></span>
<span id="cb519-2"><a href="mlm.html#cb519-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Part) <span class="sc">%&gt;%</span></span>
<span id="cb519-3"><a href="mlm.html#cb519-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">proc_speed =</span> <span class="fu">mean</span>(RT)) <span class="sc">%&gt;%</span></span>
<span id="cb519-4"><a href="mlm.html#cb519-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(proc_speed) </span></code></pre></div>
<table>
<caption><span id="tab:ctt-1a">Table 6.21: </span>CTT test scores for processing speed</caption>
<thead>
<tr class="header">
<th align="right">Part</th>
<th align="right">proc_speed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">7</td>
<td align="right">789</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">795</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">875</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">889</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">903</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">939</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">976</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">984</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">1018</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="right">1038</td>
</tr>
</tbody>
</table>
<p>The observed test score <span class="math inline">\(y_i\)</span> for participant <span class="math inline">\(i\)</span> is composed of the true score of participant <span class="math inline">\(i\)</span>, <span class="math inline">\(\mu_i\)</span>, and a Gaussian measurement error <span class="math inline">\(\epsilon_{ij}\)</span>. By adding more (exchangeable) trials to the test, the measurement error can be reduced.</p>
<p><span class="math display">\[
y_{ij} = \mu_i + \epsilon_{ij}
\]</span></p>
<p>The following model implements CTT as a multi-level absolute group means model <a href="lm.html#amm">4.3.4</a>, with the only difference that the participant-level means are estimated as random effects, i.e. it assumes a Gaussian distribution of person scores (Table <a href="mlm.html#tab:ctt-3">6.22</a>).</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="mlm.html#cb520-1" aria-hidden="true" tabindex="-1"></a>M_CTT <span class="ot">&lt;-</span> <span class="fu">brm</span>(RT <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Part), <span class="at">data =</span> D_CTT)</span></code></pre></div>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="mlm.html#cb521-1" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior</span>(M_CTT) <span class="sc">%&gt;%</span></span>
<span id="cb521-2"><a href="mlm.html#cb521-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">re_scores</span>() <span class="sc">%&gt;%</span></span>
<span id="cb521-3"><a href="mlm.html#cb521-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranef</span>() <span class="sc">%&gt;%</span></span>
<span id="cb521-4"><a href="mlm.html#cb521-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">Part =</span> re_entity) <span class="sc">%&gt;%</span></span>
<span id="cb521-5"><a href="mlm.html#cb521-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(center)</span></code></pre></div>
<table>
<caption><span id="tab:ctt-3">Table 6.22: </span>Coefficient estimates with 95% credibility limits</caption>
<thead>
<tr class="header">
<th align="left">Part</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">7</td>
<td align="right">796</td>
<td align="right">756</td>
<td align="right">838</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="right">802</td>
<td align="right">763</td>
<td align="right">842</td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="right">878</td>
<td align="right">838</td>
<td align="right">917</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="right">890</td>
<td align="right">850</td>
<td align="right">930</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="right">904</td>
<td align="right">864</td>
<td align="right">942</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="right">938</td>
<td align="right">898</td>
<td align="right">979</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="right">973</td>
<td align="right">933</td>
<td align="right">1013</td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="right">980</td>
<td align="right">939</td>
<td align="right">1023</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="right">1013</td>
<td align="right">974</td>
<td align="right">1053</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="right">1032</td>
<td align="right">991</td>
<td align="right">1072</td>
</tr>
</tbody>
</table>
<p>What makes CTT models too simplistic, is that they assume items to be completely exchangeable. For a set of experimental RTs it only sometimes is true that they are exchangeable. Actually, for a mental rotation task, they usually are not, because trials differ by rotation angle. For all rating scales, item equality is rarely the case, and also not desired. Two items from the same scale can differ in several aspects, one of which is how hard (or strong) an item is. Consider the following two items from a fictional user experience scale; most likely, the second item would get lower ratings on average, because it is stronger (“awesome” compared to “nice”):</p>
<ol style="list-style-type: decimal">
<li>The user interface is nice.</li>
<li>The user interface is awesome.</li>
</ol>
<p>One problem with CTT is that by averaging scores, the CTT swallows any information on item functioning. More advanced psychometric models are constructed based on either <em>Item Response Theory (IRT)</em> or <em>Factor Analysis (FA)</em>. With such models, different characteristics of items can be accounted for. As diverse and elaborated these models can be today, they all have in common, that items are modeled explicitly and get their own estimates. Discussing these models in more depth would require a separate book. Still, a simple item response model is nothing but an encounter of persons and test items, a simple two-way cross over (<a href="mlm.html#non-human-populations">6.5</a>).</p>
<p>Some years ago, I proposed a novel personality construct, <em>geekism</em>, which states that users differ in how enthusiastic they are about tinkering with computers. The hope was that we could explain differences in user behavior by using this scale, such as how they react when having to learn a new software application. A qualitative study with self-proclaimed geeks and several psychometric studies resulted in rating scale with 32 items. The Hugme case is one of the quantitative follow-up studies, where the Geekism scale was used together with the Need for Cognition scale (NCS), which assesses the tendency to enjoy intellectual puzzles in general. We were interested in</p>
<ol style="list-style-type: decimal">
<li>how the items function,</li>
<li>how reliable the scale is and</li>
<li>how Geekism correlates with Need-for-cognition.</li>
</ol>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="mlm.html#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Hugme)</span></code></pre></div>
<p>One important thing to note at this point is that psychometricians like to put things in participant-by-item matrices. And this is what most psychometric tools expect as input. For a multi-level model we need the long format, which can easily be accomplished by for the regression engine. Matrix form can be transformed into long form (Table <a href="mlm.html#tab:irt-long-form">6.23</a>) and vice versa (Table <a href="mlm.html#tab:irt-matrix-form">6.24</a>).</p>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb523-1"><a href="mlm.html#cb523-1" aria-hidden="true" tabindex="-1"></a>D_long <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb523-2"><a href="mlm.html#cb523-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Part =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>,</span>
<span id="cb523-3"><a href="mlm.html#cb523-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Item =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb523-4"><a href="mlm.html#cb523-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb523-5"><a href="mlm.html#cb523-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rating =</span> <span class="fu">rnorm</span>(<span class="dv">40</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb523-6"><a href="mlm.html#cb523-6" aria-hidden="true" tabindex="-1"></a>  mascutils<span class="sc">::</span><span class="fu">as_tbl_obs</span>()</span>
<span id="cb523-7"><a href="mlm.html#cb523-7" aria-hidden="true" tabindex="-1"></a>D_long</span></code></pre></div>
<table>
<caption><span id="tab:irt-long-form">Table 6.23: </span>Data set with 4 variables, showing 8 of 40 observations.</caption>
<thead>
<tr class="header">
<th align="right">Obs</th>
<th align="right">Part</th>
<th align="right">Item</th>
<th align="right">rating</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">33</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">-0.674</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">1.248</td>
</tr>
<tr class="odd">
<td align="right">19</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">0.078</td>
</tr>
<tr class="even">
<td align="right">28</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">0.766</td>
</tr>
<tr class="odd">
<td align="right">29</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">-0.495</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">6</td>
<td align="right">1</td>
<td align="right">-0.289</td>
</tr>
<tr class="odd">
<td align="right">31</td>
<td align="right">7</td>
<td align="right">4</td>
<td align="right">-0.133</td>
</tr>
<tr class="even">
<td align="right">39</td>
<td align="right">7</td>
<td align="right">5</td>
<td align="right">-0.702</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="mlm.html#cb524-1" aria-hidden="true" tabindex="-1"></a>D_long <span class="sc">%&gt;%</span></span>
<span id="cb524-2"><a href="mlm.html#cb524-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Part, Item, rating) <span class="sc">%&gt;%</span></span>
<span id="cb524-3"><a href="mlm.html#cb524-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(</span>
<span id="cb524-4"><a href="mlm.html#cb524-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_from =</span> Item,</span>
<span id="cb524-5"><a href="mlm.html#cb524-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_from =</span> rating</span>
<span id="cb524-6"><a href="mlm.html#cb524-6" aria-hidden="true" tabindex="-1"></a>  ) </span></code></pre></div>
<table>
<caption><span id="tab:irt-matrix-form">Table 6.24: </span>Psychometric data often comes in matrix form</caption>
<thead>
<tr class="header">
<th align="right">Part</th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.851</td>
<td align="right">0.526</td>
<td align="right">-1.156</td>
<td align="right">-0.642</td>
<td align="right">-0.674</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1.743</td>
<td align="right">1.438</td>
<td align="right">1.248</td>
<td align="right">-0.535</td>
<td align="right">-0.502</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1.893</td>
<td align="right">-0.713</td>
<td align="right">0.078</td>
<td align="right">0.184</td>
<td align="right">0.881</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">-0.473</td>
<td align="right">-0.275</td>
<td align="right">-0.516</td>
<td align="right">0.766</td>
<td align="right">1.780</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">-0.267</td>
<td align="right">-0.324</td>
<td align="right">1.355</td>
<td align="right">-0.495</td>
<td align="right">-0.193</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">-0.289</td>
<td align="right">0.262</td>
<td align="right">-1.587</td>
<td align="right">0.392</td>
<td align="right">-0.487</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">1.800</td>
<td align="right">-0.212</td>
<td align="right">1.513</td>
<td align="right">-0.133</td>
<td align="right">-0.702</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.107</td>
<td align="right">-1.188</td>
<td align="right">-0.223</td>
<td align="right">-0.912</td>
<td align="right">0.888</td>
</tr>
</tbody>
</table>
<p>Psychometric programs often require matrix data, but for a multi-level models we need the long format. IRT models regard items as populations, too, and the basic IRT model is a cross-classified intercept-only model <a href="mlm.html#non-human-populations">6.5</a>.</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="mlm.html#cb525-1" aria-hidden="true" tabindex="-1"></a>D_psymx_1 <span class="ot">&lt;-</span></span>
<span id="cb525-2"><a href="mlm.html#cb525-2" aria-hidden="true" tabindex="-1"></a>  D_quest <span class="sc">%&gt;%</span></span>
<span id="cb525-3"><a href="mlm.html#cb525-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Scale <span class="sc">==</span> <span class="st">&quot;Geek&quot;</span>, Session <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb525-4"><a href="mlm.html#cb525-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb525-5"><a href="mlm.html#cb525-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb525-6"><a href="mlm.html#cb525-6" aria-hidden="true" tabindex="-1"></a>M_psymx_1 <span class="ot">&lt;-</span></span>
<span id="cb525-7"><a href="mlm.html#cb525-7" aria-hidden="true" tabindex="-1"></a>  D_psymx_1 <span class="sc">%&gt;%</span></span>
<span id="cb525-8"><a href="mlm.html#cb525-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(rating <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Part) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Item), <span class="at">data =</span> .)</span></code></pre></div>
<p>Once a rating scale instrument is ready to use, the researcher will ultimately be interested in the person scores. However, during the process of constructing a psychometric instrument, items scores play an important role. In the following I will demonstrate three psychometric evaluations, using multi-level models:</p>
<ol style="list-style-type: decimal">
<li><em>Test coverage</em> of a scale can be assessed by comparing the distribution of item scores with the distribution of person scores</li>
<li><em>Test reliability</em> can be estimated by comparing scores across two sessions of testing.</li>
<li><em>Test validity</em> can be estimated as person score correlations between scales.</li>
</ol>
<div id="coverage" class="section level3" number="6.8.1">
<h3><span class="header-section-number">6.8.1</span> Coverage</h3>
<p>Geekism was assumed to vary widely in the population of users and we wanted to be able to cover the whole range with good precision. In IRT models, items and persons are actually scored on the same scale. The person-level coefficients represent the persons’ level of geekism. The item-level effects can best be called <em>item sensitivity</em>. A rule in the development of good psychometric instruments is that the range of interest has to be covered by items with a matching sensitivity. Any item with consistently high ratings is able to distinguish low levels of geekism, but is less useful for discriminating between high levels of geekism. Just think of how poorly a very simple arithmetic question, like “Which of the following numbers is divisible by 3? [2, 3, 5, 7, 9]” would be able to diagnose the math skills of you, the readers of this book. The inverse is also true: an item with a very strong proposition, like</p>
<blockquote>
<blockquote>
<p>I always build my own computers</p>
</blockquote>
</blockquote>
<p>may be great to distinguish between amateur and pro level geekism, but most average and below average persons will just say No.</p>
<p>We have a linear model, where the rating is weighted sums of person tendency and item sensitivity. A high rating can mean two things (or both): coming from a very geek person, indeed, or it was a very sensitive item. For a good test coverage we need sensitive items for levels of low geekism and strong, i.e. <em>less</em> sensitive, items for the pros. Because random effects are centered at zero, we can simply reverse the scale with <em>item strength</em> being the negative sensitivity. Now we can compare the distributions of person and item scores side-by-side and check how the person tendencies are covered by item strength. <em>Note</em> that for obtaining the absolute scores, we can use the Bayr function <code>re_scores</code>, but for psychometric analysis, the deviation from the population average is sufficient, hence <code>ranef</code>.</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="mlm.html#cb526-1" aria-hidden="true" tabindex="-1"></a>P_psymx_1 <span class="ot">&lt;-</span> <span class="fu">posterior</span>(M_psymx_1)</span>
<span id="cb526-2"><a href="mlm.html#cb526-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb526-3"><a href="mlm.html#cb526-3" aria-hidden="true" tabindex="-1"></a>T_ranef <span class="ot">&lt;-</span></span>
<span id="cb526-4"><a href="mlm.html#cb526-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranef</span>(P_psymx_1) <span class="sc">%&gt;%</span></span>
<span id="cb526-5"><a href="mlm.html#cb526-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">geekism =</span> center) <span class="sc">%&gt;%</span></span>
<span id="cb526-6"><a href="mlm.html#cb526-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">geekism =</span> <span class="fu">if_else</span>(re_factor <span class="sc">==</span> <span class="st">&quot;Item&quot;</span>,</span>
<span id="cb526-7"><a href="mlm.html#cb526-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span>geekism, geekism</span>
<span id="cb526-8"><a href="mlm.html#cb526-8" aria-hidden="true" tabindex="-1"></a>  )) <span class="co"># reversing</span></span></code></pre></div>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="mlm.html#cb527-1" aria-hidden="true" tabindex="-1"></a>T_ranef <span class="sc">%&gt;%</span></span>
<span id="cb527-2"><a href="mlm.html#cb527-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(</span>
<span id="cb527-3"><a href="mlm.html#cb527-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> re_factor,</span>
<span id="cb527-4"><a href="mlm.html#cb527-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> geekism,</span>
<span id="cb527-5"><a href="mlm.html#cb527-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> re_entity</span>
<span id="cb527-6"><a href="mlm.html#cb527-6" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">+</span></span>
<span id="cb527-7"><a href="mlm.html#cb527-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_violin</span>() <span class="sc">+</span></span>
<span id="cb527-8"><a href="mlm.html#cb527-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb527-9"><a href="mlm.html#cb527-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:hugme-3"></span>
<img src="Linear_mixed-effects_models_files/figure-html/hugme-3-1.png" alt="Comparing distributions of item-level and participant-level scores" width="90%" />
<p class="caption">
Figure 6.17: Comparing distributions of item-level and participant-level scores
</p>
</div>
<p>Figure <a href="mlm.html#fig:hugme-3">6.17</a> shows that the 32 items of the test cover the range of very low to moderately high geekism fairly well. The upper 20 percent are not represented so well, as it seems. If we were to use the scale to discriminate between geeks and super-geeks, more strong item should be added, such as: ‘I rather express myself in a programming language, rather than natural language.’</p>
</div>
<div id="reliability" class="section level3" number="6.8.2">
<h3><span class="header-section-number">6.8.2</span> Reliability</h3>
<p>Next, we examine the reliability of the Geekism scale. Reliability is originally a CTT concept and means that the measurement error is small. For example, a reliable personality scale produces almost exactly the same score when applied to a person on different occasions. Is the Geekism score reliable? In our study we asked participants to fill out the questionnaire twice, with an experimental session in-between. If reliability of Geekism is good, the correlation of scores between sessions should be very strong.</p>
<p>In order to obtain the scores per session, we add Session as a factor to the model. For reliability we are interested in correlation between person scores, so it would suffice to add the Session random effect to the participant level, only. However, the same model can be used to do assess <em>stability</em> of item scores, too. This is rarely practiced, but as we will see, there is an interesting pattern to observe.</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="mlm.html#cb528-1" aria-hidden="true" tabindex="-1"></a>D_psymx_2 <span class="ot">&lt;-</span></span>
<span id="cb528-2"><a href="mlm.html#cb528-2" aria-hidden="true" tabindex="-1"></a>  D_quest <span class="sc">%&gt;%</span> <span class="fu">filter</span>(Scale <span class="sc">==</span> <span class="st">&quot;Geek&quot;</span>)</span>
<span id="cb528-3"><a href="mlm.html#cb528-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb528-4"><a href="mlm.html#cb528-4" aria-hidden="true" tabindex="-1"></a>M_psymx_2 <span class="ot">&lt;-</span></span>
<span id="cb528-5"><a href="mlm.html#cb528-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(rating <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">+</span></span>
<span id="cb528-6"><a href="mlm.html#cb528-6" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">|</span> Part) <span class="sc">+</span></span>
<span id="cb528-7"><a href="mlm.html#cb528-7" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">|</span> Item),</span>
<span id="cb528-8"><a href="mlm.html#cb528-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> D_psymx_2</span>
<span id="cb528-9"><a href="mlm.html#cb528-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>We extract the random effects and plot test-retest scores for participants and items (Figure <a href="mlm.html#fig:hugme-6">6.18</a>). The indicated line would be ideal stability for comparison.</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="mlm.html#cb529-1" aria-hidden="true" tabindex="-1"></a>T_ranef <span class="ot">&lt;-</span></span>
<span id="cb529-2"><a href="mlm.html#cb529-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranef</span>(M_psymx_2) <span class="sc">%&gt;%</span></span>
<span id="cb529-3"><a href="mlm.html#cb529-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(re_factor, re_entity, <span class="at">Session =</span> fixef, <span class="at">score =</span> center) <span class="sc">%&gt;%</span></span>
<span id="cb529-4"><a href="mlm.html#cb529-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Session, <span class="at">values_from =</span> <span class="st">&quot;score&quot;</span>)</span>
<span id="cb529-5"><a href="mlm.html#cb529-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb529-6"><a href="mlm.html#cb529-6" aria-hidden="true" tabindex="-1"></a>T_ranef <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">8</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">re_factor</th>
<th align="left">re_entity</th>
<th align="right">Session1</th>
<th align="right">Session2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Part</td>
<td align="left">65</td>
<td align="right">1.012</td>
<td align="right">0.926</td>
</tr>
<tr class="even">
<td align="left">Part</td>
<td align="left">64</td>
<td align="right">-1.027</td>
<td align="right">-0.904</td>
</tr>
<tr class="odd">
<td align="left">Part</td>
<td align="left">8</td>
<td align="right">-1.007</td>
<td align="right">-0.912</td>
</tr>
<tr class="even">
<td align="left">Item</td>
<td align="left">Geek05</td>
<td align="right">-0.444</td>
<td align="right">-0.302</td>
</tr>
<tr class="odd">
<td align="left">Item</td>
<td align="left">Geek03</td>
<td align="right">0.765</td>
<td align="right">0.527</td>
</tr>
<tr class="even">
<td align="left">Item</td>
<td align="left">Geek32</td>
<td align="right">-0.688</td>
<td align="right">-0.534</td>
</tr>
<tr class="odd">
<td align="left">Part</td>
<td align="left">66</td>
<td align="right">-0.955</td>
<td align="right">-0.840</td>
</tr>
<tr class="even">
<td align="left">Part</td>
<td align="left">5</td>
<td align="right">-1.119</td>
<td align="right">-1.014</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="mlm.html#cb530-1" aria-hidden="true" tabindex="-1"></a>plot_stability <span class="ot">&lt;-</span></span>
<span id="cb530-2"><a href="mlm.html#cb530-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(ranef) {</span>
<span id="cb530-3"><a href="mlm.html#cb530-3" aria-hidden="true" tabindex="-1"></a>    ranef <span class="sc">%&gt;%</span></span>
<span id="cb530-4"><a href="mlm.html#cb530-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Session1, <span class="at">y =</span> Session2)) <span class="sc">+</span></span>
<span id="cb530-5"><a href="mlm.html#cb530-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">facet_grid</span>(re_factor <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb530-6"><a href="mlm.html#cb530-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb530-7"><a href="mlm.html#cb530-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">color =</span> <span class="st">&quot;observed&quot;</span>), <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb530-8"><a href="mlm.html#cb530-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_abline</span>(<span class="fu">aes</span>(</span>
<span id="cb530-9"><a href="mlm.html#cb530-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>,</span>
<span id="cb530-10"><a href="mlm.html#cb530-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">color =</span> <span class="st">&quot;ideal&quot;</span></span>
<span id="cb530-11"><a href="mlm.html#cb530-11" aria-hidden="true" tabindex="-1"></a>      )) <span class="sc">+</span></span>
<span id="cb530-12"><a href="mlm.html#cb530-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Stability&quot;</span>)</span>
<span id="cb530-13"><a href="mlm.html#cb530-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb530-14"><a href="mlm.html#cb530-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb530-15"><a href="mlm.html#cb530-15" aria-hidden="true" tabindex="-1"></a>T_ranef <span class="sc">%&gt;%</span> <span class="fu">plot_stability</span>()</span></code></pre></div>
<div class="figure"><span id="fig:hugme-6"></span>
<img src="Linear_mixed-effects_models_files/figure-html/hugme-6-1.png" alt="Test-retest stability for item and participant scores" width="90%" />
<p class="caption">
Figure 6.18: Test-retest stability for item and participant scores
</p>
</div>
<p>The participant scores are highly correlated, indicating a very good reliability. If you measure the score of a person, you almost precisely know the result of another measure a few hours later. At least in short terms, the Geekism construct - whatever it truly is - can be measured with almost no error. Only ever so slightly is there a trend that lower scores get higher the second time and higher get lower, which could be called a trend towards the average. Perhaps, some experience during the experiment has led participants to report a more mediocre image of themselves.</p>
<p>In psychometric analysis it is common to assess participant-level test-retest reliability, but rarely is that done on items. This is, in fact, easy because the psychometric model contains intercept and slope random effects for items, and we can examine test-retest patterns in the same way. We see the same trend towards the average, but much stronger. In the present case, we see that this can be a mistake. Here it seems that the trend towards mediocrity does not produce a bias on the population mean, because it is bi-directional and the item and participant scores are nicely symmetric around the center of the scale. Not every test may have these properties and any asymmetric wear-off effect of items would produce more serious biases.</p>
<p>Another situation where item stability matters is when a person doing the test is actually learning from it. Usually, it is not desired that a test can be learned, because that means people can train for it. This is unlikely to occur in a regular math or intelligence test, but when the items are real-world tasks, like operating medical infusion pumps or driving a car, every test is an exercise and participants will learn.</p>
<p>The example of test-retest stability shows one more time, how useful plots are for discovering patterns in data. More formally, test-retest stability is reported as a correlation. We can produce a correlation estimate by using the standard <code>cor</code> command on the participant-level random effects (Table <a href="mlm.html#tab:hugme-7">6.25</a>)</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="mlm.html#cb531-1" aria-hidden="true" tabindex="-1"></a>T_ranef <span class="sc">%&gt;%</span></span>
<span id="cb531-2"><a href="mlm.html#cb531-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(re_factor) <span class="sc">%&gt;%</span></span>
<span id="cb531-3"><a href="mlm.html#cb531-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">cor =</span> <span class="fu">cor</span>(Session1, Session2)) </span></code></pre></div>
<table>
<caption><span id="tab:hugme-7">Table 6.25: </span>Correlation of scores between session 1 and 2 (point estimates)</caption>
<thead>
<tr class="header">
<th align="left">re_factor</th>
<th align="right">cor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Item</td>
<td align="right">0.997</td>
</tr>
<tr class="even">
<td align="left">Part</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>Unfortunately, this lacks information about the degree of certainty. The better way is to let the regression engine estimate all correlations between random factors that are on the same level (Part, Item). The regression engine <code>brm</code> does that by default. The following code extracts the posterior distributions of all correlations in the model (Table <a href="mlm.html#tab:hugme-8">6.26</a>).</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="mlm.html#cb532-1" aria-hidden="true" tabindex="-1"></a>clu_cor <span class="ot">&lt;-</span></span>
<span id="cb532-2"><a href="mlm.html#cb532-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(model) {</span>
<span id="cb532-3"><a href="mlm.html#cb532-3" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span></span>
<span id="cb532-4"><a href="mlm.html#cb532-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">posterior</span>() <span class="sc">%&gt;%</span></span>
<span id="cb532-5"><a href="mlm.html#cb532-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(type <span class="sc">==</span> <span class="st">&quot;cor&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb532-6"><a href="mlm.html#cb532-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">parameter =</span> <span class="fu">str_remove_all</span>(parameter, <span class="st">&quot;cor_&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb532-7"><a href="mlm.html#cb532-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">group_by</span>(parameter) <span class="sc">%&gt;%</span></span>
<span id="cb532-8"><a href="mlm.html#cb532-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">summarize</span>(</span>
<span id="cb532-9"><a href="mlm.html#cb532-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">center =</span> <span class="fu">median</span>(value),</span>
<span id="cb532-10"><a href="mlm.html#cb532-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">lower =</span> <span class="fu">quantile</span>(value, .<span class="dv">025</span>),</span>
<span id="cb532-11"><a href="mlm.html#cb532-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">upper =</span> <span class="fu">quantile</span>(value, .<span class="dv">975</span>)</span>
<span id="cb532-12"><a href="mlm.html#cb532-12" aria-hidden="true" tabindex="-1"></a>      ) <span class="sc">%&gt;%</span></span>
<span id="cb532-13"><a href="mlm.html#cb532-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">separate</span>(parameter,</span>
<span id="cb532-14"><a href="mlm.html#cb532-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;re_factor&quot;</span>, <span class="st">&quot;between&quot;</span>, <span class="st">&quot;and&quot;</span>),</span>
<span id="cb532-15"><a href="mlm.html#cb532-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">sep =</span> <span class="st">&quot;__&quot;</span></span>
<span id="cb532-16"><a href="mlm.html#cb532-16" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb532-17"><a href="mlm.html#cb532-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb532-18"><a href="mlm.html#cb532-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb532-19"><a href="mlm.html#cb532-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb532-20"><a href="mlm.html#cb532-20" aria-hidden="true" tabindex="-1"></a>M_psymx_2 <span class="sc">%&gt;%</span></span>
<span id="cb532-21"><a href="mlm.html#cb532-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu_cor</span>() </span></code></pre></div>
<table>
<caption><span id="tab:hugme-8">Table 6.26: </span>Random effects correlations with 95 percent credibility limits</caption>
<thead>
<tr class="header">
<th align="left">re_factor</th>
<th align="left">between</th>
<th align="left">and</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Item</td>
<td align="left">Session1</td>
<td align="left">Session2</td>
<td align="right">0.983</td>
<td align="right">0.913</td>
<td align="right">0.999</td>
</tr>
<tr class="even">
<td align="left">Part</td>
<td align="left">Session1</td>
<td align="left">Session2</td>
<td align="right">0.994</td>
<td align="right">0.966</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>With random effects correlations assessing test-retest-stability is straight-forward. If test and retest random effects correlate strongly, we can be sure that the error of measurement is low and we can call it a reliable scale. Good reliability is necessary, but not sufficient to also call a scale valid.</p>
</div>
<div id="validity" class="section level3" number="6.8.3">
<h3><span class="header-section-number">6.8.3</span> Validity</h3>
<p>Reliability doesn’t say anything about what the scale actually measures. In psychometric studies, <em>validity</em> of a scale is routinely evaluated by comparing the scores to external criteria. In a perfect world, it would be assessed how scores are related to relevant real-world behavior, such as:</p>
<ol style="list-style-type: decimal">
<li>Are high-Geek persons more enthusiastic to learn a programming language?</li>
<li>Do high-Geek persons perform better in computer jobs?</li>
<li>Are high-Geek persons more likely to buy robot toys for their offsprings?</li>
</ol>
<p>In the real world, researchers in the field of personality are often content with relating a new rating scales to another, already validated personality scale. In the Hugme study, participants were also asked to rate themselves on the Need-for-Cognition scale (NCS). In very brief NCS measures how much a person enjoys intellectual puzzles. Since computers are intellectual puzzles, sometimes in a good way, often not, we thought that high-Geek persons must also score high on NCS. At the same time, a very strong correlation between Geek and NCS would indicate that the two scales render the same property, which would make one of them redundant, probably the newcomer. The following model estimates the person scores per scale and we can extract the correlations (Table <a href="mlm.html#tab:hugme-10">6.27</a>).</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="mlm.html#cb533-1" aria-hidden="true" tabindex="-1"></a>M_psymx_3 <span class="ot">&lt;-</span></span>
<span id="cb533-2"><a href="mlm.html#cb533-2" aria-hidden="true" tabindex="-1"></a>  D_quest <span class="sc">%&gt;%</span></span>
<span id="cb533-3"><a href="mlm.html#cb533-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(rating <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Scale <span class="sc">+</span> (<span class="dv">0</span> <span class="sc">+</span> Scale <span class="sc">|</span> Part), <span class="at">data =</span> .)</span></code></pre></div>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="mlm.html#cb534-1" aria-hidden="true" tabindex="-1"></a>M_psymx_3 <span class="sc">%&gt;%</span></span>
<span id="cb534-2"><a href="mlm.html#cb534-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu_cor</span>() </span></code></pre></div>
<table>
<caption><span id="tab:hugme-10">Table 6.27: </span>Random effects correlations with 95 percent credibility limits</caption>
<thead>
<tr class="header">
<th align="left">re_factor</th>
<th align="left">between</th>
<th align="left">and</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Part</td>
<td align="left">ScaleGeek</td>
<td align="left">ScaleNCS</td>
<td align="right">0.371</td>
<td align="right">0.098</td>
<td align="right">0.586</td>
</tr>
</tbody>
</table>
<p>Table <a href="mlm.html#tab:hugme-10">6.27</a> shows a weakly positive association between Geek and NCS, just as was hoped for. The two constructs are related, but not quite the same.</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
</div>
<div id="designometrix" class="section level3" number="6.8.4">
<h3><span class="header-section-number">6.8.4</span> Towards Design-o-metrix</h3>
<p>Psychometrics, as it was introduced above, deals with comparing human individuals. In Design Research, this may be of interest sometimes, but the real stake is to <em>compare designs</em>. As we will see in this section, psychometric concepts can well be transferred to <em>design-o-metric problems</em>. However, there is one twist, which has up til now been overlooked in most of Design Research: in design-o-metric studies the target population is designs, not humans. In a typical psychometric study, measurements are an encounter of humans with items, with the ultimate goal of measuring humans. A design-o-metric measurement is the encounter of three populations, humans, items and, ultimately, designs. Classic psychometric tools use a 2-dimensional matrix as input and cannot deal with a third dimension. Here it comes in very handy, that multi-level models use the long format, where more dimension can be added at will. All we have to do, is crossing in another non-human population <a href="mlm.html#non-human-populations">6.5</a>.</p>
<p>We revisit the Uncanny Valley data set (<a href="mpm.html#prm">5.5</a> and <a href="mlm.html#universality">6.4</a>). The experiment used eight items from the Eeriness scale <span class="citation">(Ho and MacDorman 2017)</span> to ask the judgment of participants on 82 stimuli showing robot faces. In one of our experiments (RK_1), participants simply rated all robots face in three separate session. Since we are only interested in a design-o-metric analysis regarding the Eeriness scale, not the Uncanny Valley curve, we omit the human-likeness score (Table <a href="mlm.html#tab:uncanny-9">6.28</a>).</p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="mlm.html#cb536-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Uncanny)</span></code></pre></div>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="mlm.html#cb537-1" aria-hidden="true" tabindex="-1"></a>UV_dsgmx <span class="ot">&lt;-</span></span>
<span id="cb537-2"><a href="mlm.html#cb537-2" aria-hidden="true" tabindex="-1"></a>  RK_1 <span class="sc">%&gt;%</span></span>
<span id="cb537-3"><a href="mlm.html#cb537-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Part, Item, <span class="at">Design =</span> Stimulus, Session, response) <span class="sc">%&gt;%</span></span>
<span id="cb537-4"><a href="mlm.html#cb537-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tbl_obs</span>()</span>
<span id="cb537-5"><a href="mlm.html#cb537-5" aria-hidden="true" tabindex="-1"></a>UV_dsgmx</span></code></pre></div>
<table>
<caption><span id="tab:uncanny-9">Table 6.28: </span>Data set with 6 variables, showing 8 of 7488 observations.</caption>
<thead>
<tr class="header">
<th align="right">Obs</th>
<th align="left">Part</th>
<th align="left">Item</th>
<th align="left">Design</th>
<th align="left">Session</th>
<th align="right">response</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1242</td>
<td align="left">p1_05</td>
<td align="left">nE2</td>
<td align="left">3</td>
<td align="left">1</td>
<td align="right">-0.967</td>
</tr>
<tr class="even">
<td align="right">4566</td>
<td align="left">p2_03</td>
<td align="left">nE6</td>
<td align="left">71</td>
<td align="left">3</td>
<td align="right">-0.740</td>
</tr>
<tr class="odd">
<td align="right">4589</td>
<td align="left">p2_03</td>
<td align="left">nE5</td>
<td align="left">8</td>
<td align="left">3</td>
<td align="right">-0.258</td>
</tr>
<tr class="even">
<td align="right">5252</td>
<td align="left">p2_06</td>
<td align="left">nE4</td>
<td align="left">72</td>
<td align="left">1</td>
<td align="right">-0.352</td>
</tr>
<tr class="odd">
<td align="right">5362</td>
<td align="left">p2_06</td>
<td align="left">nE2</td>
<td align="left">73</td>
<td align="left">2</td>
<td align="right">-0.705</td>
</tr>
<tr class="even">
<td align="right">6506</td>
<td align="left">p2_10</td>
<td align="left">nE2</td>
<td align="left">46</td>
<td align="left">2</td>
<td align="right">-0.670</td>
</tr>
<tr class="odd">
<td align="right">7035</td>
<td align="left">p2_12</td>
<td align="left">nE3</td>
<td align="left">14</td>
<td align="left">2</td>
<td align="right">-0.567</td>
</tr>
<tr class="even">
<td align="right">7345</td>
<td align="left">p2_13</td>
<td align="left">nE1</td>
<td align="left">69</td>
<td align="left">2</td>
<td align="right">-0.688</td>
</tr>
</tbody>
</table>
<p>With this data we seem to be standing on familiar psychometric grounds: Persons encounter items and we have three measures over time. We can calculate test-retest stability of items and persons using a multi-level model. Voila! Here are your correlations, person and item stability - with credibility limits. But, wait a second! What is being measured here? Persons? No, robot faces. The original question was, how human-likeness of robot faces is related to perceived eeriness of robot faces and the Eeriness scale intended purpose is the comparison of designs, not persons. For example, it could be used by robot designers to check that a design does not trigger undesirable emotional responses. Without knowing the human-likeness scores, robot faces become just a naked <em>population of designs</em> <a href="mlm.html#non-human-populations">6.5</a>.</p>
<p>Measures in the Uncanny experiment are an encounter of three samples: Part, Item and Design, and designs is what we ultimately want to compare. That means we need a model that produces design-level scores. For the user of multi-level models that just means adding a Design random effect to the psychometric model (Part, Item). Models, where a design random factor sits on top of a psychometric model, I call <em>design-o-metric models</em>. The most basic design-o-metric model is a three-way cross-classified, intercept-only model, from which design scores can be extracted. By extending the test-retest psychometric model <code>M_psymx_2</code>, we can estimate design-o-metric test-retest stability. We only have to add the Design random factor to the model and extract the correlations, like in the psychometric applications.</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="mlm.html#cb538-1" aria-hidden="true" tabindex="-1"></a>M_dsgmx_1 <span class="ot">&lt;-</span></span>
<span id="cb538-2"><a href="mlm.html#cb538-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(response <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">+</span></span>
<span id="cb538-3"><a href="mlm.html#cb538-3" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">|</span> Part) <span class="sc">+</span></span>
<span id="cb538-4"><a href="mlm.html#cb538-4" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">|</span> Item) <span class="sc">+</span></span>
<span id="cb538-5"><a href="mlm.html#cb538-5" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span> <span class="sc">+</span> Session <span class="sc">|</span> Design),</span>
<span id="cb538-6"><a href="mlm.html#cb538-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> UV_dsgmx</span>
<span id="cb538-7"><a href="mlm.html#cb538-7" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="mlm.html#cb539-1" aria-hidden="true" tabindex="-1"></a>M_dsgmx_1 <span class="sc">%&gt;%</span></span>
<span id="cb539-2"><a href="mlm.html#cb539-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clu_cor</span>() </span></code></pre></div>
<table>
<caption><span id="tab:uncanny-10">Table 6.29: </span>Random effects correlations of a design-o-metric model with 95 percent credibility limits</caption>
<thead>
<tr class="header">
<th align="left">re_factor</th>
<th align="left">between</th>
<th align="left">and</th>
<th align="right">center</th>
<th align="right">lower</th>
<th align="right">upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Design</td>
<td align="left">Session1</td>
<td align="left">Session2</td>
<td align="right">0.987</td>
<td align="right">0.945</td>
<td align="right">0.999</td>
</tr>
<tr class="even">
<td align="left">Design</td>
<td align="left">Session1</td>
<td align="left">Session3</td>
<td align="right">0.987</td>
<td align="right">0.946</td>
<td align="right">0.999</td>
</tr>
<tr class="odd">
<td align="left">Design</td>
<td align="left">Session2</td>
<td align="left">Session3</td>
<td align="right">0.991</td>
<td align="right">0.961</td>
<td align="right">0.999</td>
</tr>
<tr class="even">
<td align="left">Item</td>
<td align="left">Session1</td>
<td align="left">Session2</td>
<td align="right">0.849</td>
<td align="right">0.228</td>
<td align="right">0.989</td>
</tr>
<tr class="odd">
<td align="left">Item</td>
<td align="left">Session1</td>
<td align="left">Session3</td>
<td align="right">0.702</td>
<td align="right">-0.066</td>
<td align="right">0.958</td>
</tr>
<tr class="even">
<td align="left">Item</td>
<td align="left">Session2</td>
<td align="left">Session3</td>
<td align="right">0.841</td>
<td align="right">0.170</td>
<td align="right">0.988</td>
</tr>
<tr class="odd">
<td align="left">Part</td>
<td align="left">Session1</td>
<td align="left">Session2</td>
<td align="right">0.816</td>
<td align="right">0.557</td>
<td align="right">0.950</td>
</tr>
<tr class="even">
<td align="left">Part</td>
<td align="left">Session1</td>
<td align="left">Session3</td>
<td align="right">0.686</td>
<td align="right">0.377</td>
<td align="right">0.869</td>
</tr>
<tr class="odd">
<td align="left">Part</td>
<td align="left">Session2</td>
<td align="left">Session3</td>
<td align="right">0.815</td>
<td align="right">0.570</td>
<td align="right">0.930</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<p>Like in the psychometric situation, we extract the correlations (<a href="mlm.html#tab:uncanny-10">6.29</a>). Since we have three sessions, we even get three stability scores. In addition, the design-o-metric model provides test-retest correlations for all three levels. The test-retest stability for designs is very reassuring. Ratings on the Eeriness scale are highly reproducible and the error will be very small. To a lesser, but still sufficient degree are person and item scores stable.</p>
<p>But, what does the person score (and its stability) actually mean? It describes the tendency of a person to give high ratings on Eeriness. Should a researcher want to assess how sensitive a person is to the Uncanny Valley effect, the Eeriness scale is also reliable for measuring persons. Many scales in design research lend themselves to be looked at from a design-o-metric and psychometric perspective. For example, a hypothetical scale to measure comfort of sitting can be used to evaluate seats, but can also be used to measure how comfortable a person is with sitting.</p>
<p>No seat fits every person, or put differently: the comfort of a seat depends on the person sitting in it. This points us at one of many possible extensions to carry out deeper design-o-metric analysis. If the difficulty of an item in a psychometric test depends on who is being tested, this is called <em>differential item functioning</em>. For example, the large international student evaluations PISA and TIMMS routinely check their test items for cultural differences. The aim is to formulate test questions in such a way that they are equally comprehensible with all cultural backgrounds. This is a desirable property for design-o-metric scales, too. In a multi-level design-o-metric model, this could be incorporated as an interaction effect between cultural background and item-level coefficients.</p>
<p>That all being said about design-o-metric models, my observation is that practically all published rating scales in design research have been validated under a psychometric perspective, rather than a design-o-metric. This is a mistake! If the purpose of the scale is to compare designs, the scale’s reliability and validity must examined on the design level.</p>
<p>In many cases, a purportedly design-o-metric study has been conducted on a sample of participants and a sample of items, but only a single or a few designs. Isn’t it obvious that a scale’s capability to rank designs must be assessed on a sample of designs. This mindlessness in transfering psychometric concepts to design research is worrying and I call this the <em>psychometric fallacy</em>.</p>
</div>
</div>
<div id="further-readings-2" class="section level2" number="6.9">
<h2><span class="header-section-number">6.9</span> Further readings</h2>
<ol style="list-style-type: decimal">
<li>In psychometric models the population level is of lesser interest. One could build a single-level model, using fixed-effects factors for participants and items. <span class="citation">(Gelman, Hill, and Yajima 2012)</span> show that random-effects models are superior, because they allow multiple pairwise comparisons, which is problematic with fixed effects. For psychometric situations, comparison of individuals is essential.</li>
<li>An introduction to planned missing data designs, as we used it in cases Egan and Uncanny, is given by <span class="citation">(Graham et al. 2006)</span>.</li>
<li>Multi-level models for psycholinguistic studies have been used by <span class="citation">(Baayen, Davidson, and Bates 2008)</span>.</li>
<li>In <span class="citation">(Schmettow and Sommer 2016)</span>, we evaluated whether we can predict by the method of card sorting, how quickly users find a specific information on a website. A multi-level model showed that this is <em>not</em> so. This serves as an example, that you can prove the (practical) absence of effects with New Statistics, and publish.</li>
<li><span class="citation">(Ho and MacDorman 2017)</span> is one of many examples of falling for the psychometric fallacy.</li>
</ol>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
<!--[semantic Stroop]


Measuring participant performance is a useful application in some design research fields, such as human performance in  critical systems, e.g. identify persons with the best talent for being an airspace controller. However, in design research, it is frequently designs that are to be compared. For example, in the Egan case, one might be interested to select the best of the ten website designs, in order to use it as a blueprint. Such a research question is no longer psychometric, literally, but formally the only difference is that participants can be considered test items, rather than test objects. At least, when using ramdom effects for psychometric purposes, there is nothing special about the participant random effects compared to design random effects. Let's pretend we had conducted the study in order to identify a good template for university websites. The following code extracts design random effects posteriors, summarizes them in the usual way and makes a plot.


```r
attach(Egan)

ranef(P_1) %>%
  filter(re_factor == "Design") %>%
  rename(Design = re_entity) %>%
  ggplot(aes(x = Design, y = center, ymax = upper, ymin = lower)) +
  geom_point(size = 1) +
  geom_crossbar() +
  ylab("log ToT") +
  theme(axis.text.x = element_text(angle = 45))
```

<img src="Linear_mixed-effects_models_files/figure-html/unnamed-chunk-46-1.png" width="90%" />


The most simple form is the Rasch model in item response theory (IRT), where participants respond to a set of items and the response is either correct or incorrect. The outcome variable response is usually coded as 0 = incorrect and 1 = correct. Apparently, such a variable does nowhere near satisfy the assumption of linear models. It turns out that the Rasch model can be interpreted as cross-classified random effects in a *logistic regression* \@ref(logistic_regression). Logistic regression is a member of the General*ized* Linear family of models, which will be introduced in the next chapter.

As innocent as the Egan study seems, there is some psychometrics involved.  First, cognitive workload was measured using the NASA TLX questionnaire which has four items. With four items, we would hardly want to speak of a population. The trick is to view the four items as instantiations from all a virtual set of possible questions (on that matter). A typical question in psychometric research is that of *item consistency*, which for a small set of items can be measured by the correlation between items. High inter-item correlations indicate that a scale is reliable, which basically means it predicts well. Item correlations are mainly used during scale development, as a criterion to sort out renegade items, those that do not move in accordance with the others.





```r

```
-->
<!-- ## Average? Neverage! A pledoyer for within-subject research -->
<!-- Many studies in design research pretend that all users are alike. This idea is borrowed from experimental social science research. Seminal studies in cognitive psychology and social psychology claim mental structures or processes that hold for all humans. That is the very paradigm of fundamental psychology and many researchers ground their theorizing and experimentation on it. And indeed, several properties of human information processing have been replicated under such diverse conditions that one can assume that they are general. For example, the Stroop observation has been observed hundred of times in various populations subgroups [REF], situations [REF] and variations. -->
<!-- The treatments in such experiments can be simplistic to an extreme. Often, participants are asked to respond to colored geometric shapes that light up on a black background by simple key presses. This is called *reductionism* and it has led to at least some insights into how the human mind works. As much as  design researchers should draw upon psychological theory, as useless is the reductionist paradigm in most applied research. Designs must work in real world situations and often in many different ones, highly controlled lab experiments just bear too little resemblance to the real world. In particular, by no means can we expect all users to respond alike to one or more designs. Their minds are complex, obscure and unpredictable besides. -->
<!-- > Our minds are not run as top - down dictatorships; they are rambunctious parliaments, populated by squabbling factions and caucuses, with much more going on beneath the surface than our conscious awareness ever accesses. -->
<!-- (Carroll, Sean. The Big Picture (Kindle Locations 5029-5031). Oneworld Publications. Kindle Edition.) -->
<!-- Let me get it straight: People differ! If you plan to move from design A to B, or any other design choice, it is a good idea to also regard how much people vary. If your research question refers to any mental process or its change, the only solid way is to observe how one-and-the-same individuals behave on all conditions. That means within-subject designs should be the rule, not the exception. In some branches of experimental reseach it is still common to use between-subject designs, at the expense of statistical power and without the possibility to see "change of mind" actually happen. In contrast, between-subject experimental designs  is a potential mistake and requires good justification. The following case illustrates how things can go terribly wrong, when within-subject processes are examined in a between-subject manner: -->
<!-- Imagine you set out to determine the association between typing speed (as number of ke) and errors. It is common sense that quality decreases with speed, so a positive correlation is expected. During the experiment, participants get a number of texts to type. With the first trial they are instructed to type at a relaxed speed. With every further trial they were asked to type slightly faster than at the trial before. The expectation is that -->
<!-- > The faster a person types, the more errors occur -->
<!-- In terms of statistical skills, the researcher is familiar with linear models, and is aware of the fact, that these may not be applied for repeated measures. Therefore our researcher first averages the scores across participants and receives a data set with a neat 30 data points, one per trial. A first exploratory plot reveals a bizarre relation: it seems that the faster participants type, the less errors they make. That is completely against expectations, as there almost always is a trade-off between speed and accuracy. -->
<!-- ```{r Typing_average, opts.label = "fig.small"} -->
<!-- attach(Typing) -->
<!-- Type_1_avg %>%  -->
<!--   ggplot(aes(x = speed, -->
<!--              y = error)) + -->
<!--   geom_point() + -->
<!--   geom_smooth(se = F) -->
<!-- ``` -->
<!-- Could it be true that the faster a person types, the less errors happen? Of course not. The problem is how precisely we ask the question. When averaging over persons, we actually answer a different question, which is on a *population-level*: Do persons who can type faster make fewer errors? This question sees every person as one data point with two performance measures, speed and errors, both representing the ability to type. Now, the above results make more sense: people, who are trained in typing are at the same time fast and more accurate. But, what the experiment was out for is the trade-off between speed and accuracy *within a person*. The experiment provokes this trade-off by asking the same person to accelerate in typing. And, when we visualize the results on an individual level, the speed-accuracy trade-off becomes immediately visible. Now, every individual curve has an upward: with increased speed, the error goes up as well.  -->
<!-- ```{r Typing_individual, ops.label = "fig.small"} -->
<!-- Type_1 %>%  -->
<!--   ggplot(aes(x = speed, -->
<!--              y = error, -->
<!--              group = Part)) + -->
<!--   #geom_point() + -->
<!--   geom_smooth(se = F, method = "lm", aes(col = "within participant")) + -->
<!--   geom_smooth(data = Type_1_avg,  -->
<!--               aes(col = "between participant", x = speed, y = error, group = NA),  -->
<!--               se = F, method = "lm") -->
<!-- ``` -->
<!-- For the matter of simplicity let' us's ignore that the process is not linear, but takes a curved form. What is relevant is that there is a downwards trend on the population level (averaging over participants) that turns into a uniform upwards trend on participant level. Only a multi-level model will be able to uncover such a bizzare situation: -->
<!-- ```{r} -->
<!-- M_1 <- Type_1 %>%  -->
<!--   stan_glmer(error ~ 1 + speed + (1 + speed|Part), data = .) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- M_1 -->
<!-- ``` -->
<!-- ```{r} -->
<!-- detach(Typing) -->
<!-- ``` -->
<!-- ## Random effects correlations {#re_correlations} -->
<!-- Another feature of the Typing data is discernable in the figure above: Participants with initial high error countstend to have much steeper curves  -->
<!-- ###  -->
<!-- The example here is constructed to be extreme: the population-level effect has the opposite direction of individual level effects. However, the situation is fully plausible and points us to an important principle: Whenever a research question capitalizes on a change in mental state or behaviour, the only solid way to investigate is a within-subject design. Therefore again: treating averaged data as if it represents within-persons changes is a severe mistake. In the A/B case, for example, one must always be clear about the level. Is it true that  -->
<!-- + on average, users prefer B over A? -->
<!-- + or all users individually prefer B over A? -->
<!-- The bizzare situation with the Typing study will have to wait, because we will need all elements of multilevel modelling to resolve it. However, the figure above features the core elements of mutlilevel models: -->
<!-- + persons have different levels for errors at relaxed typing (varying intercepts) -->
<!-- + persons differ in how much the error frequency goes up with speed (varying slopes) -->
<!-- + the better a person performs at relaxed typing, the less the number of errors goes up when the person types faster (correlated random effects) -->
<!-- ## Exercises -->
<!-- 1. In the Egan study, cross-classified random effects capture the encounter of samples. Actually, we have not even taken this to an extreme, as the original study also measured mental workload with a scale of four items. Create and run a model that captures all samples, including the scale items. Interpret the results. -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mpm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsubsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
